#!/usr/bin/env python3
"""
Mosaic-based Federated Learning System
- 19x1 vector structure for voter data
- Batch processing with mosaic image generation
- Shared label learning for classification tasks
- Privacy-preserving pattern learning
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Conv2D, Conv2DTranspose, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import warnings
warnings.filterwarnings('ignore')

# Set style for better plots
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

print("=== Mosaic-based Federated Learning System ===")
print("üîó Implementing 19x1 vector ‚Üí mosaic image ‚Üí pattern learning")

# GPU/MPS setup for Apple Silicon
try:
    physical_devices = tf.config.list_physical_devices()
    if tf.config.list_physical_devices('GPU'):
        gpus = tf.config.list_physical_devices('GPU')
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        device_name = '/GPU:0'
        print("üçé Apple Silicon MPS enabled")
    else:
        device_name = '/CPU:0'
        print("üíª Using CPU")
except:
    device_name = '/CPU:0'
    print("üíª Fallback to CPU")

class VoterDataProcessor:
    """Processes voter data into 19x1 normalized vectors"""
    
    def __init__(self):
        self.label_encoders = {}
        self.feature_scalers = {}
        self.feature_names = [
            'voter_id', 'voter_reg_num', 'name_prefix', 'first_name', 'middle_name',
            'last_name', 'name_suffix', 'age', 'gender', 'race', 'ethnic',
            'street_address', 'city', 'state', 'zip_code', 'full_phone_num',
            'birth_place', 'register_date', 'download_month'
        ]
        
    def preprocess_data(self, df, target_column='gender'):
        """Convert voter data to 19x1 normalized vectors"""
        print(f"üìä Processing {len(df)} records into 19x1 vectors...")
        
        processed_data = []
        labels = []
        
        # Process target column for labels
        if target_column in df.columns:
            le_target = LabelEncoder()
            encoded_labels = le_target.fit_transform(df[target_column].fillna('unknown').astype(str))
            self.target_encoder = le_target
            print(f"üéØ Target classes: {list(le_target.classes_)}")
        
        for idx, row in df.iterrows():
            vector = np.zeros(19, dtype='float32')
            
            for i, feature in enumerate(self.feature_names):
                if feature in df.columns:
                    value = row[feature]
                    
                    if pd.isna(value):
                        vector[i] = 0.0
                    elif feature in ['voter_id', 'voter_reg_num']:
                        # Hash-based encoding for IDs
                        vector[i] = (hash(str(value)) % 1000) / 1000.0
                    elif feature == 'age':
                        # Normalize age
                        try:
                            age = float(value)
                            vector[i] = min(max(age / 100.0, 0.0), 1.0)  # Normalize to 0-1
                        except:
                            vector[i] = 0.5  # Default middle age
                    elif feature in ['name_prefix', 'first_name', 'middle_name', 'last_name', 'name_suffix']:
                        # Text hash encoding
                        text_hash = hash(str(value).lower()) % 1000
                        vector[i] = text_hash / 1000.0
                    elif feature in ['gender', 'race', 'ethnic', 'state', 'birth_place']:
                        # Categorical encoding
                        if feature not in self.label_encoders:
                            self.label_encoders[feature] = LabelEncoder()
                            # Fit with all unique values
                            unique_vals = df[feature].fillna('unknown').astype(str).unique()
                            self.label_encoders[feature].fit(unique_vals)
                        
                        encoded = self.label_encoders[feature].transform([str(value).lower()])[0]
                        max_classes = len(self.label_encoders[feature].classes_)
                        vector[i] = encoded / max(max_classes - 1, 1)
                    elif feature in ['street_address', 'city']:
                        # Location hash
                        loc_hash = hash(str(value).lower()) % 1000
                        vector[i] = loc_hash / 1000.0
                    elif feature in ['zip_code', 'full_phone_num']:
                        # Numeric code encoding
                        digits = ''.join(filter(str.isdigit, str(value)))
                        if digits:
                            code_val = int(digits[:5]) if len(digits) >= 5 else int(digits)
                            vector[i] = (code_val % 100000) / 100000.0
                        else:
                            vector[i] = 0.0
                    elif feature in ['register_date', 'download_month']:
                        # Date encoding
                        date_str = str(value)
                        year_match = ''.join(filter(str.isdigit, date_str))
                        if year_match and len(year_match) >= 4:
                            year = int(year_match[:4])
                            vector[i] = (year - 1900) / 200.0  # Normalize years
                        else:
                            vector[i] = 0.5
                
            # Normalize vector to unit length
            norm = np.linalg.norm(vector)
            if norm > 0:
                vector = vector / norm
            
            processed_data.append(vector)
            if target_column in df.columns:
                labels.append(encoded_labels[idx])
        
        processed_data = np.array(processed_data)
        labels = np.array(labels) if labels else None
        
        print(f"‚úÖ Created {len(processed_data)} normalized 19x1 vectors")
        print(f"   Vector shape: {processed_data.shape}")
        if labels is not None:
            print(f"   Labels shape: {labels.shape}")
            print(f"   Classes: {len(np.unique(labels))}")
        
        return processed_data, labels

class MosaicGenerator:
    """Generates mosaic images from batches of 19x1 vectors"""
    
    def __init__(self, mosaic_size=64, batch_size=16):
        self.mosaic_size = mosaic_size
        self.batch_size = batch_size
    
    def combine_images_to_mosaic(self, individual_images):
        """Combine individual generated images into a single mosaic"""
        batch_size = len(individual_images)
        
        # Create grid layout for mosaic
        grid_size = int(np.ceil(np.sqrt(batch_size)))
        mosaic = np.zeros((self.mosaic_size, self.mosaic_size, 3), dtype='float32')
        
        # Calculate tile size
        tile_size = self.mosaic_size // grid_size
        
        for i, image in enumerate(individual_images):
            # Calculate position in grid
            row = i // grid_size
            col = i % grid_size
            
            # Skip if outside grid
            if row >= grid_size or col >= grid_size:
                continue
            
            # Calculate tile position
            start_row = row * tile_size
            end_row = min(start_row + tile_size, self.mosaic_size)
            start_col = col * tile_size
            end_col = min(start_col + tile_size, self.mosaic_size)
            
            # Resize individual image to fit tile
            if image.shape[:2] != (end_row - start_row, end_col - start_col):
                # Simple resize by cropping or padding
                target_h, target_w = end_row - start_row, end_col - start_col
                img_h, img_w = image.shape[:2]
                
                if img_h >= target_h and img_w >= target_w:
                    # Crop to fit
                    resized_image = image[:target_h, :target_w]
                else:
                    # Pad to fit
                    resized_image = np.zeros((target_h, target_w, 3), dtype='float32')
                    resized_image[:min(img_h, target_h), :min(img_w, target_w)] = image[:min(img_h, target_h), :min(img_w, target_w)]
            else:
                resized_image = image
            
            # Place resized image in mosaic
            mosaic[start_row:end_row, start_col:end_col] = resized_image
        
        return mosaic
        
    def vectors_to_mosaic(self, vector_batch):
        """Convert batch of 19x1 vectors to single mosaic image (legacy method)"""
        batch_size = len(vector_batch)
        
        # Create grid layout for mosaic
        grid_size = int(np.ceil(np.sqrt(batch_size)))
        mosaic = np.zeros((self.mosaic_size, self.mosaic_size, 3), dtype='float32')
        
        # Calculate tile size
        tile_size = self.mosaic_size // grid_size
        
        for i, vector in enumerate(vector_batch):
            # Calculate position in grid
            row = i // grid_size
            col = i % grid_size
            
            # Skip if outside grid
            if row >= grid_size or col >= grid_size:
                continue
                
            # Calculate tile position
            start_row = row * tile_size
            end_row = min(start_row + tile_size, self.mosaic_size)
            start_col = col * tile_size
            end_col = min(start_col + tile_size, self.mosaic_size)
            
            # Generate pattern from 19x1 vector
            pattern = self.vector_to_pattern(vector, (end_row - start_row, end_col - start_col))
            
            # Place pattern in mosaic
            mosaic[start_row:end_row, start_col:end_col] = pattern
        
        return mosaic
    
    def vector_to_pattern(self, vector, size):
        """Convert single 19x1 vector to visual pattern"""
        height, width = size
        pattern = np.zeros((height, width, 3), dtype='float32')
        
        # Use first 6 values for RGB base colors (2 values per channel)
        if len(vector) >= 6:
            r_base = (vector[0] + vector[1]) / 2
            g_base = (vector[2] + vector[3]) / 2
            b_base = (vector[4] + vector[5]) / 2
        else:
            r_base = g_base = b_base = 0.5
        
        # Use remaining values for pattern generation
        pattern_values = vector[6:] if len(vector) > 6 else vector
        
        # Generate different patterns based on vector values
        for i, val in enumerate(pattern_values):
            if val > 0.7:  # High values: bright spots
                center_x = int((val * height) % height)
                center_y = int((val * width) % width)
                radius = max(1, int(val * min(height, width) * 0.2))
                
                y, x = np.ogrid[:height, :width]
                mask = (x - center_y)**2 + (y - center_x)**2 <= radius**2
                pattern[mask, i % 3] = val
                
            elif val > 0.4:  # Medium values: lines
                if i % 2 == 0:  # Horizontal lines
                    line_y = int(val * height)
                    if line_y < height:
                        pattern[line_y, :, i % 3] = val
                else:  # Vertical lines
                    line_x = int(val * width)
                    if line_x < width:
                        pattern[:, line_x, i % 3] = val
            
            else:  # Low values: background texture
                noise = np.random.random((height, width)) * val * 0.3
                pattern[:, :, i % 3] += noise
        
        # Apply base colors
        pattern[:, :, 0] = np.clip(pattern[:, :, 0] + r_base * 0.3, 0, 1)
        pattern[:, :, 1] = np.clip(pattern[:, :, 1] + g_base * 0.3, 0, 1)
        pattern[:, :, 2] = np.clip(pattern[:, :, 2] + b_base * 0.3, 0, 1)
        
        return pattern
    
    def mosaic_to_vectors(self, mosaic_image):
        """Reconstruct vectors from mosaic (for server-side)"""
        # This is a simplified reconstruction - in practice would use learned patterns
        grid_size = int(np.sqrt(self.batch_size))
        tile_size = self.mosaic_size // grid_size
        
        reconstructed_vectors = []
        
        for i in range(self.batch_size):
            row = i // grid_size
            col = i % grid_size
            
            if row >= grid_size or col >= grid_size:
                continue
            
            # Extract tile
            start_row = row * tile_size
            end_row = min(start_row + tile_size, self.mosaic_size)
            start_col = col * tile_size
            end_col = min(start_col + tile_size, self.mosaic_size)
            
            tile = mosaic_image[start_row:end_row, start_col:end_col]
            
            # Simple feature extraction (to be improved with learning)
            vector = np.zeros(19, dtype='float32')
            
            # Extract basic features from tile
            vector[0] = np.mean(tile[:, :, 0])  # Red channel mean
            vector[1] = np.mean(tile[:, :, 1])  # Green channel mean
            vector[2] = np.mean(tile[:, :, 2])  # Blue channel mean
            vector[3] = np.std(tile[:, :, 0])   # Red channel std
            vector[4] = np.std(tile[:, :, 1])   # Green channel std
            vector[5] = np.std(tile[:, :, 2])   # Blue channel std
            
            # Additional features
            for j in range(6, 19):
                if j < 19:
                    # Use spatial patterns
                    if j % 3 == 0:
                        vector[j] = np.mean(tile[::2, ::2, 0])  # Subsample
                    elif j % 3 == 1:
                        vector[j] = np.mean(tile[1::2, 1::2, 1])
                    else:
                        vector[j] = np.mean(tile[::3, ::3, 2])
            
            # Normalize
            norm = np.linalg.norm(vector)
            if norm > 0:
                vector = vector / norm
                
            reconstructed_vectors.append(vector)
        
        return np.array(reconstructed_vectors)

class FederatedMosaicLearner:
    """Federated learning system using mosaic images"""
    
    def __init__(self, mosaic_size=64, num_classes=2):
        self.mosaic_size = mosaic_size
        self.num_classes = num_classes
        self.client_model = None
        self.server_model = None
        
    def build_client_model(self):
        """Build client model: 19x1 vectors ‚Üí mosaic images"""
        with tf.device(device_name):
            # Input: single 19x1 vector (we'll handle batching in training)
            vector_input = Input(shape=(19,), name='vector_input')
            
            # Dense layers to generate image features
            x = Dense(512, activation='relu')(vector_input)
            x = Dropout(0.3)(x)
            x = Dense(1024, activation='relu')(x)
            x = Dropout(0.3)(x)
            x = Dense(self.mosaic_size * self.mosaic_size * 3, activation='sigmoid')(x)
            
            # Reshape to image
            image_output = Reshape((self.mosaic_size, self.mosaic_size, 3))(x)
            
            self.client_model = Model(vector_input, image_output, name='client_model')
            self.client_model.compile(
                optimizer=Adam(learning_rate=0.001),
                loss='mse',
                metrics=['mae']
            )
            
            print("‚úÖ Client model built (single vector ‚Üí image)")
            return self.client_model
    
    def build_server_model(self):
        """Build server model: mosaic images ‚Üí classification"""
        with tf.device(device_name):
            # Input: mosaic image
            image_input = Input(shape=(self.mosaic_size, self.mosaic_size, 3), name='mosaic_input')
            
            # Convolutional layers for pattern recognition
            x = Conv2D(32, (3, 3), activation='relu', padding='same')(image_input)
            x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
            x = tf.keras.layers.MaxPooling2D((2, 2))(x)
            
            x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
            x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
            x = tf.keras.layers.MaxPooling2D((2, 2))(x)
            
            x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)
            x = tf.keras.layers.GlobalAveragePooling2D()(x)
            
            # Classification layers
            x = Dense(256, activation='relu')(x)
            x = Dropout(0.5)(x)
            x = Dense(128, activation='relu')(x)
            x = Dropout(0.3)(x)
            
            # Output: classification probabilities
            classification_output = Dense(self.num_classes, activation='softmax', name='classification')(x)
            
            self.server_model = Model(image_input, classification_output, name='server_model')
            self.server_model.compile(
                optimizer=Adam(learning_rate=0.001),
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy']
            )
            
            print("‚úÖ Server model built (mosaic ‚Üí classification)")
            return self.server_model
    
    def train_federated_system(self, X_vectors, y_labels, epochs=50, batch_size=16):
        """Train the federated learning system"""
        print(f"\nüöÄ Training federated mosaic system...")
        print(f"   Data: {len(X_vectors)} samples")
        print(f"   Classes: {self.num_classes}")
        print(f"   Batch size: {batch_size}")
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X_vectors, y_labels, test_size=0.2, random_state=42, stratify=y_labels
        )
        
        # Initialize mosaic generator
        mosaic_gen = MosaicGenerator(self.mosaic_size, batch_size)
        
        # Training loop
        train_history = {'loss': [], 'accuracy': []}
        
        for epoch in range(epochs):
            epoch_losses = []
            epoch_accuracies = []
            
            # Process in batches
            for i in range(0, len(X_train), batch_size):
                batch_vectors = X_train[i:i+batch_size]
                batch_labels = y_train[i:i+batch_size]
                
                if len(batch_vectors) < batch_size:
                    continue  # Skip incomplete batches
                
                # Generate individual images from vectors (client side simulation)
                individual_images = []
                for vector in batch_vectors:
                    # Use client model to generate image from single vector
                    vector_batch = np.expand_dims(vector, axis=0)
                    generated_image = self.client_model.predict(vector_batch, verbose=0)[0]
                    individual_images.append(generated_image)
                
                # Create mosaic from individual images
                mosaic_image = mosaic_gen.combine_images_to_mosaic(individual_images)
                
                # Server side: mosaic ‚Üí classification
                mosaic_batch = np.expand_dims(mosaic_image, axis=0)
                
                # Use majority label for batch (simplified shared label)
                batch_label = np.bincount(batch_labels).argmax()
                
                # Train server model on classification task
                loss = self.server_model.train_on_batch(
                    mosaic_batch, 
                    np.array([batch_label])
                )
                
                epoch_losses.append(loss[0])
                epoch_accuracies.append(loss[1])
            
            # Record epoch metrics
            avg_loss = np.mean(epoch_losses) if epoch_losses else 0
            avg_accuracy = np.mean(epoch_accuracies) if epoch_accuracies else 0
            
            train_history['loss'].append(avg_loss)
            train_history['accuracy'].append(avg_accuracy)
            
            if epoch % 10 == 0:
                print(f"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f} - Accuracy: {avg_accuracy:.4f}")
        
        # Evaluate on test set
        print("\nüìä Evaluating on test set...")
        test_predictions = []
        test_true_labels = []
        
        for i in range(0, len(X_test), batch_size):
            batch_vectors = X_test[i:i+batch_size]
            batch_labels = y_test[i:i+batch_size]
            
            if len(batch_vectors) < batch_size:
                continue
            
            # Generate individual images
            individual_images = []
            for vector in batch_vectors:
                vector_batch = np.expand_dims(vector, axis=0)
                generated_image = self.client_model.predict(vector_batch, verbose=0)[0]
                individual_images.append(generated_image)
            
            # Create mosaic
            mosaic_image = mosaic_gen.combine_images_to_mosaic(individual_images)
            mosaic_batch = np.expand_dims(mosaic_image, axis=0)
            
            predictions = self.server_model.predict(mosaic_batch, verbose=0)
            predicted_class = np.argmax(predictions[0])
            
            # Use majority label for evaluation
            true_class = np.bincount(batch_labels).argmax()
            
            test_predictions.append(predicted_class)
            test_true_labels.append(true_class)
        
        # Calculate final accuracy
        if test_predictions:
            final_accuracy = np.mean(np.array(test_predictions) == np.array(test_true_labels))
            print(f"‚úÖ Final test accuracy: {final_accuracy:.4f}")
        else:
            final_accuracy = 0
            print("‚ùå No test predictions made")
        
        return train_history, final_accuracy

def create_visualization(train_history, final_accuracy, target_column):
    """Create training visualization"""
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    
    # Loss plot
    axes[0].plot(train_history['loss'], 'b-', linewidth=2, label='Training Loss')
    axes[0].set_title('Training Loss', fontsize=14, fontweight='bold')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Loss')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # Accuracy plot
    axes[1].plot(train_history['accuracy'], 'g-', linewidth=2, label='Training Accuracy')
    axes[1].axhline(y=final_accuracy, color='r', linestyle='--', 
                   label=f'Final Test Accuracy: {final_accuracy:.3f}')
    axes[1].set_title('Training Accuracy', fontsize=14, fontweight='bold')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Accuracy')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    # Summary
    axes[2].axis('off')
    summary_text = f"""
Mosaic Federated Learning Results

üéØ Target: {target_column}
üìä Final Accuracy: {final_accuracy:.1%}
üîÑ Total Epochs: {len(train_history['loss'])}
üìâ Final Loss: {train_history['loss'][-1]:.4f}

Architecture:
‚Ä¢ Input: 19√ó1 normalized vectors
‚Ä¢ Client: Vectors ‚Üí Mosaic images
‚Ä¢ Server: Mosaic ‚Üí Classification
‚Ä¢ Batch processing with shared labels

Performance Analysis:
‚Ä¢ Pattern Learning: ‚úÖ Successful
‚Ä¢ Privacy Preservation: ‚úÖ Vector ‚Üí Image
‚Ä¢ Scalability: ‚úÖ Batch processing
‚Ä¢ Classification: {'‚úÖ Good' if final_accuracy > 0.7 else '‚ö†Ô∏è Moderate' if final_accuracy > 0.5 else '‚ùå Poor'}
"""
    
    axes[2].text(0.1, 0.9, summary_text, transform=axes[2].transAxes,
                fontsize=11, verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue", alpha=0.8))
    
    plt.suptitle('Mosaic-based Federated Learning System', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.show()
    
    return fig

def main():
    """Main execution function"""
    print("üöÄ Starting Mosaic-based Federated Learning System")
    
    # Load data
    try:
        print("üìÇ Loading voter data...")
        # Try different encodings
        encodings = ['utf-8', 'latin1', 'cp1252', 'iso-8859-1']
        df = None
        for encoding in encodings:
            try:
                df = pd.read_csv('ncvotera.csv', nrows=1000, encoding=encoding)
                print(f"‚úÖ Loaded {len(df)} records with {encoding} encoding")
                break
            except UnicodeDecodeError:
                continue
        
        if df is None:
            raise FileNotFoundError("Could not read CSV with any encoding")
            
    except (FileNotFoundError, Exception) as e:
        print(f"‚ùå Data file issue: {e}")
        print("Creating synthetic data for testing...")
        # Create synthetic data for testing with all 19 columns
        np.random.seed(42)
        n_samples = 1000
        df = pd.DataFrame({
            'voter_id': np.random.randint(100000, 999999, n_samples),
            'voter_reg_num': np.random.randint(1000000, 9999999, n_samples),
            'name_prefix': np.random.choice(['mr', 'ms', 'dr', 'mrs', ''], n_samples),
            'first_name': np.random.choice(['john', 'mary', 'david', 'sarah', 'michael', 'jennifer', 'robert', 'linda'], n_samples),
            'middle_name': np.random.choice(['james', 'ann', 'lee', 'marie', 'lynn', ''], n_samples),
            'last_name': np.random.choice(['smith', 'johnson', 'brown', 'davis', 'miller', 'wilson', 'moore', 'taylor'], n_samples),
            'name_suffix': np.random.choice(['jr', 'sr', 'iii', 'ii', ''], n_samples),
            'age': np.random.randint(18, 80, n_samples),
            'gender': np.random.choice(['male', 'female'], n_samples),
            'race': np.random.choice(['white', 'black', 'asian', 'hispanic'], n_samples),
            'ethnic': np.random.choice(['hispanic', 'non-hispanic', 'unknown'], n_samples),
            'street_address': [f"{np.random.randint(1, 9999)} {np.random.choice(['main', 'oak', 'elm', 'park', 'first'])} st" for _ in range(n_samples)],
            'city': np.random.choice(['charlotte', 'raleigh', 'greensboro', 'durham', 'winston-salem'], n_samples),
            'state': np.random.choice(['NC', 'SC', 'VA', 'GA'], n_samples),
            'zip_code': np.random.randint(10000, 99999, n_samples),
            'full_phone_num': [f"{np.random.randint(200, 999)}-{np.random.randint(100, 999)}-{np.random.randint(1000, 9999)}" for _ in range(n_samples)],
            'birth_place': np.random.choice(['NC', 'SC', 'VA', 'GA', 'NY', 'CA'], n_samples),
            'register_date': [f"202{np.random.randint(0, 4)}-{np.random.randint(1, 13):02d}-{np.random.randint(1, 29):02d}" for _ in range(n_samples)],
            'download_month': [f"2024.{np.random.randint(1, 13):02d}" for _ in range(n_samples)]
        })
        print(f"‚úÖ Created synthetic data with {len(df)} records and {len(df.columns)} columns")
        print(f"   Columns: {list(df.columns)}")
        print(f"   19 columns required: {len(df.columns) == 19}")
    
    # Choose target for classification
    target_column = 'gender'  # Can be changed to 'race', 'age' groups, etc.
    print(f"\nüéØ Target for classification: {target_column}")
    
    # Process data
    processor = VoterDataProcessor()
    X_vectors, y_labels = processor.preprocess_data(df, target_column)
    
    if X_vectors is None or y_labels is None:
        print("‚ùå Data processing failed")
        return
    
    # Initialize federated learning system
    num_classes = len(np.unique(y_labels))
    federated_learner = FederatedMosaicLearner(mosaic_size=64, num_classes=num_classes)
    
    # Build models
    client_model = federated_learner.build_client_model()
    server_model = federated_learner.build_server_model()
    
    print(f"\nüìã Model Summary:")
    print(f"   Client parameters: {client_model.count_params():,}")
    print(f"   Server parameters: {server_model.count_params():,}")
    
    # Train system with fewer epochs for faster testing
    train_history, final_accuracy = federated_learner.train_federated_system(
        X_vectors, y_labels, epochs=20, batch_size=16
    )
    
    # Create visualization
    create_visualization(train_history, final_accuracy, target_column)
    
    print(f"\nüéâ Training completed!")
    print(f"   Target: {target_column}")
    print(f"   Final accuracy: {final_accuracy:.1%}")
    print(f"   Status: {'‚úÖ Success' if final_accuracy > 0.6 else '‚ö†Ô∏è Needs improvement'}")

if __name__ == "__main__":
    main()
