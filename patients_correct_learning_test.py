#!/usr/bin/env python3
"""
Patients.csv ë°ì´í„°ë¡œ ì˜¬ë°”ë¥¸ Word2Vec ëª¨ìì´í¬ í•™ìŠµ í…ŒìŠ¤íŠ¸
- 1ë‹¨ê³„: í…ìŠ¤íŠ¸ â†’ Word2Vec ë²¡í„° â†’ ëª¨ìì´í¬ ìƒì„±
- 2ë‹¨ê³„: ëª¨ìì´í¬ â†’ ë²¡í„° ë³µì› í•™ìŠµ (ì˜¬ë°”ë¥¸ í•™ìŠµ)
- 3ë‹¨ê³„: ë³µì›ëœ ë²¡í„° â†’ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from simple_word2vec_mosaic import *
import pandas as pd
from sklearn.metrics import cosine_similarity

def load_patients_data():
    """patients.csv ë°ì´í„° ë¡œë“œ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    print("ğŸ“Š Patients ë°ì´í„° ë¡œë”©...")
    
    # CSV íŒŒì¼ ì½ê¸°
    df = pd.read_csv('patients.csv')
    
    # ë¹ˆ í–‰ ì œê±°
    df = df.dropna(subset=['FIRST', 'LAST'])
    
    print(f"âœ… ì´ {len(df)}ê°œ í™˜ì ë°ì´í„° ë¡œë“œ")
    print(f"ğŸ“‹ ì»¬ëŸ¼: {list(df.columns)}")
    
    # í…ìŠ¤íŠ¸ ë°ì´í„° ì¡°í•© (ì´ë¦„, ì£¼ì†Œ, ì¸ì¢…, ì„±ë³„ ë“±)
    texts = []
    for _, row in df.iterrows():
        # ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ í•„ë“œë“¤ì„ ì¡°í•©
        text_parts = []
        
        # ì´ë¦„
        if pd.notna(row['PREFIX']): text_parts.append(str(row['PREFIX']))
        if pd.notna(row['FIRST']): text_parts.append(str(row['FIRST']))
        if pd.notna(row['LAST']): text_parts.append(str(row['LAST']))
        if pd.notna(row['SUFFIX']): text_parts.append(str(row['SUFFIX']))
        
        # ìœ„ì¹˜ ì •ë³´
        if pd.notna(row['CITY']): text_parts.append(str(row['CITY']))
        if pd.notna(row['STATE']): text_parts.append(str(row['STATE']))
        if pd.notna(row['COUNTY']): text_parts.append(str(row['COUNTY']))
        
        # ì¸êµ¬í†µê³„í•™ì  ì •ë³´
        if pd.notna(row['RACE']): text_parts.append(str(row['RACE']))
        if pd.notna(row['ETHNICITY']): text_parts.append(str(row['ETHNICITY']))
        if pd.notna(row['GENDER']): text_parts.append(str(row['GENDER']))
        if pd.notna(row['MARITAL']): text_parts.append(str(row['MARITAL']))
        
        # ì¶œìƒì§€
        if pd.notna(row['BIRTHPLACE']): 
            # ì¶œìƒì§€ ì •ë³´ ë¶„í•  ì¶”ê°€
            birthplace_parts = str(row['BIRTHPLACE']).split()
            text_parts.extend(birthplace_parts)
        
        # í…ìŠ¤íŠ¸ ì¡°í•©
        combined_text = ' '.join(text_parts).lower()
        texts.append(combined_text)
    
    # ì²˜ìŒ 5ê°œ ìƒ˜í”Œ í™•ì¸
    print("\nğŸ“ í…ìŠ¤íŠ¸ ìƒ˜í”Œ:")
    for i, text in enumerate(texts[:5]):
        print(f"  {i+1}: {text}")
    
    # í…ìŠ¤íŠ¸ ê¸¸ì´ í†µê³„
    text_lengths = [len(text.split()) for text in texts]
    print(f"\nğŸ“Š í…ìŠ¤íŠ¸ í†µê³„:")
    print(f"  í‰ê·  ë‹¨ì–´ ìˆ˜: {np.mean(text_lengths):.1f}")
    print(f"  ìµœì†Œ/ìµœëŒ€ ë‹¨ì–´ ìˆ˜: {min(text_lengths)}/{max(text_lengths)}")
    print(f"  ì¤‘ì•™ê°’ ë‹¨ì–´ ìˆ˜: {np.median(text_lengths):.1f}")
    
    return texts

class MosaicToVectorCNN:
    """ëª¨ìì´í¬ â†’ ë²¡í„° ë³µì› ì „ìš© CNN"""
    
    def __init__(self, mosaic_shape, vector_size):
        self.mosaic_shape = mosaic_shape  # (height, width, channels)
        self.vector_size = vector_size
        self.model = self._build_model()
    
    def _build_model(self):
        """ëª¨ìì´í¬ â†’ ë²¡í„° ë³µì› ëª¨ë¸ êµ¬ì¶•"""
        print(f"ğŸ—ï¸  ëª¨ìì´í¬â†’ë²¡í„° ë³µì› CNN êµ¬ì¶• ({self.mosaic_shape} â†’ {self.vector_size})")
        
        # ì…ë ¥: ëª¨ìì´í¬ ì´ë¯¸ì§€
        inputs = Input(shape=self.mosaic_shape)
        
        if len(self.mosaic_shape) == 3 and self.mosaic_shape[0] == self.mosaic_shape[1]:
            # ì •ì‚¬ê°í˜• ì´ë¯¸ì§€ (16x16 ë˜ëŠ” 32x32)
            x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
            x = tf.keras.layers.MaxPooling2D((2, 2))(x)
            x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
            x = tf.keras.layers.MaxPooling2D((2, 2))(x)
            x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
            x = tf.keras.layers.GlobalAveragePooling2D()(x)
        else:
            # ì§ì‚¬ê°í˜• ì´ë¯¸ì§€ (32x128)
            x = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
            x = tf.keras.layers.MaxPooling2D((2, 2))(x)
            x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
            x = tf.keras.layers.MaxPooling2D((2, 2))(x)
            x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)
            x = tf.keras.layers.GlobalAveragePooling2D()(x)
        
        # Dense ë ˆì´ì–´ë¡œ ë²¡í„° í¬ê¸°ì— ë§ì¶¤
        x = Dense(512, activation='relu')(x)
        x = Dense(256, activation='relu')(x)
        outputs = Dense(self.vector_size, activation='linear')(x)  # ë²¡í„° ë³µì›
        
        model = Model(inputs, outputs)
        model.compile(optimizer='adam', loss='mse', metrics=['mae'])
        
        print("âœ… ëª¨ìì´í¬â†’ë²¡í„° ë³µì› CNN êµ¬ì¶• ì™„ë£Œ")
        model.summary()
        
        return model
    
    def train(self, X_train, y_train, X_val, y_val, epochs=20):
        """í•™ìŠµ ì‹¤í–‰ (X: ëª¨ìì´í¬, y: ë²¡í„°)"""
        print(f"ğŸš€ ëª¨ìì´í¬â†’ë²¡í„° ë³µì› í•™ìŠµ ì‹œì‘...")
        print(f"   ì…ë ¥: {X_train.shape} (ëª¨ìì´í¬)")
        print(f"   ì¶œë ¥: {y_train.shape} (ë²¡í„°)")
        
        history = self.model.fit(X_train, y_train,
                                epochs=epochs,
                                batch_size=32,
                                validation_data=(X_val, y_val),
                                verbose=1)
        
        print("âœ… í•™ìŠµ ì™„ë£Œ")
        return history
    
    def evaluate(self, X_test, y_test):
        """í…ŒìŠ¤íŠ¸ í‰ê°€"""
        predictions = self.model.predict(X_test, verbose=0)
        
        # MAE ê³„ì‚°
        mae = np.mean(np.abs(y_test - predictions))
        
        # ìƒê´€ê´€ê³„ ê³„ì‚°
        correlation = np.corrcoef(y_test.flatten(), predictions.flatten())[0, 1]
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ë²¡í„°ë³„)
        cosine_similarities = []
        for i in range(len(y_test)):
            cos_sim = cosine_similarity([y_test[i]], [predictions[i]])[0, 0]
            cosine_similarities.append(cos_sim)
        avg_cosine_sim = np.mean(cosine_similarities)
        
        return mae, correlation, avg_cosine_sim, predictions

def test_correct_learning_with_patients():
    """í™˜ì ë°ì´í„°ë¡œ ì˜¬ë°”ë¥¸ í•™ìŠµ í…ŒìŠ¤íŠ¸"""
    
    # ë°ì´í„° ë¡œë“œ
    texts = load_patients_data()
    
    # ìƒ˜í”Œ ìˆ˜ ì œí•œ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´)
    sample_size = min(500, len(texts))
    texts = texts[:sample_size]
    print(f"\nğŸ¯ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(texts)}ê°œ")
    
    print("\n" + "="*70)
    print("ğŸ§ª PATIENTS ë°ì´í„° ì˜¬ë°”ë¥¸ Word2Vec ëª¨ìì´í¬ í•™ìŠµ í…ŒìŠ¤íŠ¸")
    print("="*70)
    
    results = {}
    
    # 1. ì§ì ‘ ë§¤í•‘ ë°©ì‹ ì˜¬ë°”ë¥¸ í•™ìŠµ
    print("\nğŸ”¹ 1. ì§ì ‘ ë§¤í•‘ ë°©ì‹ (ì˜¬ë°”ë¥¸ í•™ìŠµ)")
    print("-" * 50)
    try:
        # 1ë‹¨ê³„: í…ìŠ¤íŠ¸ â†’ ë²¡í„° â†’ ëª¨ìì´í¬
        print("1ë‹¨ê³„: í…ìŠ¤íŠ¸ â†’ ë²¡í„° â†’ ëª¨ìì´í¬ ìƒì„±")
        processor = SimpleWord2VecProcessor(vector_size=256)
        generator = DirectMosaicGenerator(vector_size=256)
        
        vectors = processor.train_and_vectorize(texts)
        mosaics = generator.vectors_to_mosaics(vectors)
        
        # 2ë‹¨ê³„: ëª¨ìì´í¬ â†’ ë²¡í„° ë³µì› í•™ìŠµ
        print("2ë‹¨ê³„: ëª¨ìì´í¬ â†’ ë²¡í„° ë³µì› í•™ìŠµ")
        X_train, X_test, y_train, y_test = train_test_split(mosaics, vectors, test_size=0.2, random_state=42)
        
        cnn = MosaicToVectorCNN(mosaic_shape=mosaics.shape[1:], vector_size=256)
        history = cnn.train(X_train, y_train, X_test, y_test, epochs=30)
        
        # 3ë‹¨ê³„: í‰ê°€
        print("3ë‹¨ê³„: ë³µì› ì„±ëŠ¥ í‰ê°€")
        mae, correlation, cosine_sim, predictions = cnn.evaluate(X_test, y_test)
        
        results['direct'] = {
            'mae': mae,
            'correlation': correlation,
            'cosine_similarity': cosine_sim,
            'mosaics': mosaics,
            'vectors': vectors,
            'predictions': predictions,
            'y_test': y_test,
            'history': history
        }
        
        print(f"âœ… ì§ì ‘ ë§¤í•‘ ì™„ë£Œ:")
        print(f"   ğŸ“Š MAE: {mae:.4f}")
        print(f"   ğŸ“Š ìƒê´€ê´€ê³„: {correlation:.4f}")
        print(f"   ğŸ“Š í‰ê·  ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {cosine_sim:.4f}")
        
    except Exception as e:
        print(f"âŒ ì§ì ‘ ë§¤í•‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        results['direct'] = None
    
    # 2. ì»¨ë³¼ë£¨ì…˜ ë°©ì‹ ì˜¬ë°”ë¥¸ í•™ìŠµ
    print("\nğŸ”¹ 2. ì»¨ë³¼ë£¨ì…˜ ë°©ì‹ (ì˜¬ë°”ë¥¸ í•™ìŠµ)")
    print("-" * 50)
    try:
        # 1ë‹¨ê³„: í…ìŠ¤íŠ¸ â†’ ë²¡í„° â†’ ëª¨ìì´í¬
        print("1ë‹¨ê³„: í…ìŠ¤íŠ¸ â†’ ë²¡í„° â†’ ëª¨ìì´í¬ ìƒì„±")
        processor = SimpleWord2VecProcessor(vector_size=256)
        generator = ConvolutionalMosaicGenerator(vector_size=256, final_image_size=32)
        
        vectors = processor.train_and_vectorize(texts)
        mosaics = generator.vectors_to_mosaics(vectors)
        
        # 2ë‹¨ê³„: ëª¨ìì´í¬ â†’ ë²¡í„° ë³µì› í•™ìŠµ
        print("2ë‹¨ê³„: ëª¨ìì´í¬ â†’ ë²¡í„° ë³µì› í•™ìŠµ")
        X_train, X_test, y_train, y_test = train_test_split(mosaics, vectors, test_size=0.2, random_state=42)
        
        cnn = MosaicToVectorCNN(mosaic_shape=mosaics.shape[1:], vector_size=256)
        history = cnn.train(X_train, y_train, X_test, y_test, epochs=30)
        
        # 3ë‹¨ê³„: í‰ê°€
        print("3ë‹¨ê³„: ë³µì› ì„±ëŠ¥ í‰ê°€")
        mae, correlation, cosine_sim, predictions = cnn.evaluate(X_test, y_test)
        
        results['convolutional'] = {
            'mae': mae,
            'correlation': correlation,
            'cosine_similarity': cosine_sim,
            'mosaics': mosaics,
            'vectors': vectors,
            'predictions': predictions,
            'y_test': y_test,
            'history': history
        }
        
        print(f"âœ… ì»¨ë³¼ë£¨ì…˜ ë°©ì‹ ì™„ë£Œ:")
        print(f"   ğŸ“Š MAE: {mae:.4f}")
        print(f"   ğŸ“Š ìƒê´€ê´€ê³„: {correlation:.4f}")
        print(f"   ğŸ“Š í‰ê·  ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {cosine_sim:.4f}")
        
    except Exception as e:
        print(f"âŒ ì»¨ë³¼ë£¨ì…˜ ë°©ì‹ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        results['convolutional'] = None
    
    # 3. í–‰ë ¬ ë°©ì‹ ì˜¬ë°”ë¥¸ í•™ìŠµ
    print("\nğŸ”¹ 3. í–‰ë ¬ ë°©ì‹ (Yoon Kim ìŠ¤íƒ€ì¼, ì˜¬ë°”ë¥¸ í•™ìŠµ)")
    print("-" * 50)
    try:
        # 1ë‹¨ê³„: í…ìŠ¤íŠ¸ â†’ í–‰ë ¬ â†’ ëª¨ìì´í¬
        print("1ë‹¨ê³„: í…ìŠ¤íŠ¸ â†’ í–‰ë ¬ â†’ ëª¨ìì´í¬ ìƒì„±")
        processor = SentenceMatrixProcessor(vector_size=128, max_words=32)
        generator = MatrixMosaicGenerator(matrix_shape=(32, 128))
        
        sentence_matrices = processor.train_and_vectorize(texts)
        mosaics = generator.matrices_to_mosaics(sentence_matrices)
        
        # í‰ê·  ë²¡í„° ê³„ì‚° (ë¹„êµìš©)
        avg_vectors = np.mean(sentence_matrices, axis=1)  # (N, 128)
        
        # 2ë‹¨ê³„: ëª¨ìì´í¬ â†’ í‰ê· ë²¡í„° ë³µì› í•™ìŠµ
        print("2ë‹¨ê³„: ëª¨ìì´í¬ â†’ í‰ê· ë²¡í„° ë³µì› í•™ìŠµ")
        X_train, X_test, y_train, y_test = train_test_split(mosaics, avg_vectors, test_size=0.2, random_state=42)
        
        cnn = MosaicToVectorCNN(mosaic_shape=mosaics.shape[1:], vector_size=128)
        history = cnn.train(X_train, y_train, X_test, y_test, epochs=30)
        
        # 3ë‹¨ê³„: í‰ê°€
        print("3ë‹¨ê³„: ë³µì› ì„±ëŠ¥ í‰ê°€")
        mae, correlation, cosine_sim, predictions = cnn.evaluate(X_test, y_test)
        
        results['matrix'] = {
            'mae': mae,
            'correlation': correlation,
            'cosine_similarity': cosine_sim,
            'mosaics': mosaics,
            'vectors': avg_vectors,
            'predictions': predictions,
            'y_test': y_test,
            'history': history
        }
        
        print(f"âœ… í–‰ë ¬ ë°©ì‹ ì™„ë£Œ:")
        print(f"   ğŸ“Š MAE: {mae:.4f}")
        print(f"   ğŸ“Š ìƒê´€ê´€ê³„: {correlation:.4f}")
        print(f"   ğŸ“Š í‰ê·  ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {cosine_sim:.4f}")
        
    except Exception as e:
        print(f"âŒ í–‰ë ¬ ë°©ì‹ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        results['matrix'] = None
    
    # ê²°ê³¼ ë¹„êµ ë° ì‹œê°í™”
    print("\n" + "="*70)
    print("ğŸ“Š PATIENTS ë°ì´í„° ì˜¬ë°”ë¥¸ í•™ìŠµ ê²°ê³¼ ë¹„êµ")
    print("="*70)
    
    # ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸”
    print("\nğŸ† ë²¡í„° ë³µì› ì„±ëŠ¥ ë¹„êµ:")
    print(f"{'ë°©ë²•':<15} {'MAE':<10} {'ìƒê´€ê´€ê³„':<10} {'ì½”ì‚¬ì¸ìœ ì‚¬ë„':<12} {'ì´ë¯¸ì§€í¬ê¸°':<12}")
    print("-" * 65)
    
    if results['direct']:
        r = results['direct']
        print(f"{'ì§ì ‘ ë§¤í•‘':<15} {r['mae']:<10.4f} {r['correlation']:<10.4f} {r['cosine_similarity']:<12.4f} {'16x16':<12}")
    
    if results['convolutional']:
        r = results['convolutional']
        print(f"{'ì»¨ë³¼ë£¨ì…˜':<15} {r['mae']:<10.4f} {r['correlation']:<10.4f} {r['cosine_similarity']:<12.4f} {'32x32':<12}")
    
    if results['matrix']:
        r = results['matrix']
        print(f"{'í–‰ë ¬(Yoon Kim)':<15} {r['mae']:<10.4f} {r['correlation']:<10.4f} {r['cosine_similarity']:<12.4f} {'32x128':<12}")
    
    # í•™ìŠµ ê°€ëŠ¥ì„± íŒì •
    print("\nğŸ” í•™ìŠµ ê°€ëŠ¥ì„± ë¶„ì„:")
    for method_name, result in results.items():
        if result is not None:
            mae = result['mae']
            cosine_sim = result['cosine_similarity']
            
            method_display = {'direct': 'ì§ì ‘ ë§¤í•‘', 'convolutional': 'ì»¨ë³¼ë£¨ì…˜', 'matrix': 'í–‰ë ¬(Yoon Kim)'}[method_name]
            
            if mae < 0.1 and cosine_sim > 0.8:
                status = "âœ… ìš°ìˆ˜í•œ í•™ìŠµ"
                explanation = "ëª¨ìì´í¬ì—ì„œ ë²¡í„°ë¥¼ ì •í™•íˆ ë³µì›"
            elif mae < 0.2 and cosine_sim > 0.6:
                status = "ğŸ”„ ì–‘í˜¸í•œ í•™ìŠµ"
                explanation = "ëª¨ìì´í¬ì—ì„œ ë²¡í„°ë¥¼ ì–´ëŠì •ë„ ë³µì›"
            elif mae < 0.5 and cosine_sim > 0.3:
                status = "âš ï¸  ê¸°ë³¸ í•™ìŠµ"
                explanation = "ê¸°ë³¸ì ì¸ íŒ¨í„´ í•™ìŠµ"
            else:
                status = "âŒ í•™ìŠµ ë¶€ì¡±"
                explanation = "ë” ë§ì€ ë°ì´í„°ë‚˜ ë‹¤ë¥¸ ì ‘ê·¼ í•„ìš”"
            
            print(f"  {method_display}: {status} ({explanation})")
    
    # ì‹œê°í™”
    visualize_correct_learning_results(results, texts[:3])
    
    return results

def visualize_correct_learning_results(results, sample_texts):
    """ì˜¬ë°”ë¥¸ í•™ìŠµ ê²°ê³¼ ì‹œê°í™”"""
    
    # ìœ íš¨í•œ ê²°ê³¼ë§Œ ì¶”ì¶œ
    valid_results = {k: v for k, v in results.items() if v is not None}
    
    if not valid_results:
        print("âŒ ì‹œê°í™”í•  ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê·¸ë˜í”„ ì„¤ì •
    n_methods = len(valid_results)
    n_samples = min(3, len(sample_texts))
    
    fig, axes = plt.subplots(n_samples * 3, n_methods, figsize=(5*n_methods, 4*n_samples*3))
    if n_methods == 1:
        axes = axes.reshape(-1, 1)
    if n_samples == 1:
        axes = axes.reshape(3, -1)
    
    fig.suptitle('Patients ë°ì´í„° ì˜¬ë°”ë¥¸ Word2Vec ëª¨ìì´í¬ í•™ìŠµ ê²°ê³¼', fontsize=16, fontweight='bold')
    
    method_names = {'direct': 'ì§ì ‘ ë§¤í•‘', 'convolutional': 'ì»¨ë³¼ë£¨ì…˜', 'matrix': 'í–‰ë ¬(Yoon Kim)'}
    
    for j, (method_key, result) in enumerate(valid_results.items()):
        method_name = method_names.get(method_key, method_key)
        
        for i in range(n_samples):
            # 1í–‰: ì›ë³¸ ëª¨ìì´í¬
            axes[i*3, j].imshow(result['mosaics'][i].squeeze(), cmap='viridis', aspect='auto')
            axes[i*3, j].set_title(f'{method_name}\nMosaic {i+1}', fontsize=10)
            axes[i*3, j].axis('off')
            
            # 2í–‰: ë²¡í„° ë¹„êµ (ì›ë³¸ vs ë³µì›)
            if i < len(result['y_test']):
                original_vec = result['y_test'][i]
                predicted_vec = result['predictions'][i]
                
                x_pos = np.arange(min(20, len(original_vec)))  # ì²˜ìŒ 20ê°œ ì°¨ì›ë§Œ í‘œì‹œ
                axes[i*3+1, j].plot(x_pos, original_vec[:len(x_pos)], 'b-', label='Original', alpha=0.7)
                axes[i*3+1, j].plot(x_pos, predicted_vec[:len(x_pos)], 'r--', label='Predicted', alpha=0.7)
                axes[i*3+1, j].set_title(f'Vector Comparison {i+1}', fontsize=10)
                axes[i*3+1, j].legend()
                axes[i*3+1, j].grid(True, alpha=0.3)
            
            # 3í–‰: ì„±ëŠ¥ ì •ë³´
            axes[i*3+2, j].text(0.1, 0.8, f"Text: {sample_texts[i][:40]}...", 
                               fontsize=8, wrap=True, transform=axes[i*3+2, j].transAxes)
            axes[i*3+2, j].text(0.1, 0.6, f"MAE: {result['mae']:.4f}", 
                               fontsize=10, fontweight='bold', transform=axes[i*3+2, j].transAxes)
            axes[i*3+2, j].text(0.1, 0.4, f"Correlation: {result['correlation']:.4f}", 
                               fontsize=10, fontweight='bold', transform=axes[i*3+2, j].transAxes)
            axes[i*3+2, j].text(0.1, 0.2, f"Cosine Sim: {result['cosine_similarity']:.4f}", 
                               fontsize=10, fontweight='bold', transform=axes[i*3+2, j].transAxes)
            axes[i*3+2, j].set_title(f'Performance {i+1}', fontsize=10)
            axes[i*3+2, j].axis('off')
    
    plt.tight_layout()
    plt.savefig('patients_correct_learning_results.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"âœ… ì‹œê°í™” ì™„ë£Œ: patients_correct_learning_results.png ì €ì¥")

if __name__ == "__main__":
    # í™˜ì ë°ì´í„°ë¡œ ì˜¬ë°”ë¥¸ í•™ìŠµ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = test_correct_learning_with_patients()
    
    print("\nğŸ‰ Patients ë°ì´í„° ì˜¬ë°”ë¥¸ Word2Vec ëª¨ìì´í¬ í•™ìŠµ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("ì´ì œ ëª¨ìì´í¬ì—ì„œ ì›ë³¸ ë²¡í„°ë¥¼ ì •í™•íˆ ë³µì›í•˜ëŠ” ëŠ¥ë ¥ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤.")
    print("ê° ë°©ë²•ì˜ ëª¨ìì´í¬ â†’ ë²¡í„° ë³µì› ì„±ëŠ¥ì„ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
