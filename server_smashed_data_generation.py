# ì„œë²„ì¸¡ smashed data ìƒì„± (ìœ ê¶Œì ë°ì´í„° ê¸°ë°˜) - ìˆœí™˜ ì€í êµ¬ì¡° ì ìš©
# ì—°êµ¬ ì•„ì´ë””ì–´: Vectorâ†’Imageâ†’Text ë³µì›ìœ¼ë¡œ ë³´ì•ˆ ê°•í™”
import os
import pandas as pd
import numpy as np
from transformers import BertTokenizer, BertForSequenceClassification
from torch.utils.data import DataLoader, TensorDataset
import torch
import torch.nn as nn
import torch.nn.functional as F
from sklearn.model_selection import train_test_split
from circular_obfuscation import CircularObfuscationModel

# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
print("ğŸ”„ Loading voter data for server-side smashed data generation...")
data = pd.read_csv("ncvoterb.csv", encoding='latin-1')

# ë°ì´í„° í¬ê¸° ì œí•œ: ì‹¤í—˜ì„ ìœ„í•´ 1,000ê°œë¡œ ì œí•œ
# ì „ì²´ ë°ì´í„°: ì•½ 224,061ê°œ â†’ ì‹¤í—˜ìš©: 1,000ê°œ (ì•½ 0.4% ì‚¬ìš©)
SAMPLE_SIZE = 1000
if len(data) > SAMPLE_SIZE:
    print(f"ğŸ“Š Reducing data size from {len(data):,} to {SAMPLE_SIZE:,} for faster experimentation")
    data = data.sample(n=SAMPLE_SIZE, random_state=42)
    print(f"âœ… Data reduced successfully! Working with {len(data):,} records")

print(f"âœ… Data loaded successfully! Total records: {len(data)}")

# ì„œë²„ì¸¡ ë°ì´í„°ë¡œ ì‚¬ìš©í•  ìƒ˜í”Œ ìˆ˜ (ì „ì²´ì˜ 70%)
# ì‹¤í—˜ìš© ë°ì´í„°ì—ì„œ 70% = 14,000ê°œ ì‚¬ìš©
server_sample_size = int(len(data) * 0.7)
server_data = data.sample(n=server_sample_size, random_state=42)
print(f"ğŸ“Š Server-side data size: {len(server_data)} (70% of {len(data)} = {len(server_data):,})")

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ê²½ë¡œ (Pre-trained ëª¨ë¸)
model_path = "Pre-trained_voter_final.pt"

# X_train ìƒì„± (ë ˆì´ë¸”ì€ smashed data ìƒì„±ì— í•„ìš” ì—†ìŒ)
X_train = []

for index, row in server_data.iterrows():
    voter_id = row["voter_id"]

    # ëª¨ë“  ì»¬ëŸ¼ ì •ë³´ ê²°í•© (IDì™€ ë ˆì´ë¸” ì œì™¸)
    voter_info = []
    for col in data.columns:
        if col not in ['voter_id']:  # ID ì»¬ëŸ¼ ì œì™¸
            if pd.notna(row[col]):
                voter_info.append(f"{col}: {str(row[col])}")

    combined_info = ", ".join(voter_info)
    X_train.append(combined_info)

print(f"Generated {len(X_train)} training samples for server-side")

# BERT í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¡œë“œ
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# ëª¨ë¸ì´ ì´ë¯¸ ì €ì¥ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì €ì¥ëœ ëª¨ë¸ì´ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê³  ì—†ìœ¼ë©´ ìƒˆë¡œìš´ ëª¨ë¸ ìƒì„±
if os.path.exists(model_path):
    # ì €ì¥ëœ ëª¨ë¸ì´ ìˆì„ ê²½ìš° ë¶ˆëŸ¬ì˜¤ê¸°
    model = CircularObfuscationModel(num_classes=2, use_bert=False)
    try:
        checkpoint = torch.load(model_path)
        # Pre-trained ëª¨ë¸ì€ model_state_dict í‚¤ë¡œ ì €ì¥ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            # ì§ì ‘ state_dictë¡œ ì €ì¥ëœ ê²½ìš°
            model.load_state_dict(checkpoint)
        print("Pre-trained CircularObfuscationModel loaded for server-side.")
    except Exception as e:
        print(f"Warning: Could not load pre-trained model ({str(e)[:100]}...), using new model...")
        model = CircularObfuscationModel(num_classes=2, use_bert=False)
else:
    # ì €ì¥ëœ ëª¨ë¸ì´ ì—†ì„ ê²½ìš° ìƒˆë¡œìš´ ëª¨ë¸ ìƒì„±
    model = CircularObfuscationModel(num_classes=2, use_bert=False)
    print("New CircularObfuscationModel generated for server-side.")

# ServerCircularModelì€ smashed vectorë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìœ¼ë¯€ë¡œ í† í¬ë‚˜ì´ì§• ë¶ˆí•„ìš”
# ì‹¤ì œë¡œëŠ” clientì—ì„œ ìƒì„±ëœ smashed vectorë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
# í˜„ì¬ëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë”ë¯¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  ìˆì§€ë§Œ,
# ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Client_smashed_data.csvì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•´ì•¼ í•¨

print("ğŸ”„ Loading actual smashed vectors from client...")
try:
    # Clientê°€ ìƒì„±í•œ ì‹¤ì œ smashed data ë¡œë“œ
    client_smashed_df = pd.read_csv("Client_smashed_data.csv")
    smashed_vectors = torch.tensor(client_smashed_df.values, dtype=torch.float32)
    print(f"âœ… Loaded {len(smashed_vectors)} smashed vectors from Client_smashed_data.csv")
    print(f"ğŸ“Š Smashed vector shape: {smashed_vectors.shape}")
except FileNotFoundError:
    print("âš ï¸  Client_smashed_data.csv not found, using dummy data for testing...")
    # ë”ë¯¸ smashed vector ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
    dummy_smashed_vectors = []
    for i in range(len(X_train)):
        dummy_vector = torch.randn(768)  # 768ì°¨ì› ë²¡í„°
        dummy_smashed_vectors.append(dummy_vector)
    smashed_vectors = torch.stack(dummy_smashed_vectors)

# ì‹¤ì œ ë°ì´í„° ìˆ˜ì— ë§ëŠ” ë”ë¯¸ ë¼ë²¨ ìƒì„±
dummy_labels = torch.zeros(len(smashed_vectors), dtype=torch.long)

# ë°ì´í„°ì…‹ ìƒì„±
dataset = TensorDataset(smashed_vectors, dummy_labels)

# ë°ì´í„°ë¡œë” ìƒì„±
dataloader = DataLoader(dataset, batch_size=16, shuffle=False)

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ (Apple M4ìš© MPS)
device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
print(f"Using device for server-side: {device}")

# ëª¨ë¸ì„ GPUë¡œ ì´ë™
model.to(device)

# ëª¨ë¸ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
model.eval()

# ëª¨ë¸ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
model.eval()
hidden_states_list = []  # í‰ê°€í•  ë•Œ hidden stateë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

print("ğŸ”„ Generating smashed data for server-side...")
import time
start_time = time.time()

for batch_idx, batch in enumerate(dataloader):
    if batch_idx % 10 == 0:  # 10ë°°ì¹˜ë§ˆë‹¤ ì§„í–‰ ìƒí™© ì¶œë ¥
        print(f"  Processing batch {batch_idx}/{len(dataloader)}...")
    
    batch = tuple(t.to(device) for t in batch)
    smashed_vector = batch[0]  # smashed vector
    labels = batch[1]          # labels
    
    with torch.no_grad():
        outputs = model(smashed_vector, None, labels)  # attention_mask=None for server mode

    # ServerCircularModelì€ (classification_logits, loss, text_logits) ë˜ëŠ” (classification_logits, text_logits)ë¥¼ ë°˜í™˜
    if len(outputs) == 3:
        classification_logits, loss, smashed_vector = outputs
    else:
        classification_logits, smashed_vector = outputs

    # ì‹¤ì œ smashed vectorë¥¼ ì €ì¥ (768ì°¨ì›)
    hidden_states_list.append(smashed_vector.cpu())

generation_time = time.time() - start_time
print(f"âœ… Smashed data generation completed in {generation_time:.2f}s")

# hidden statesë¥¼ í•˜ë‚˜ì˜ í…ì„œë¡œ ê²°í•©
hidden_states_concat = torch.cat(hidden_states_list, dim=0)

# classification_logitsëŠ” (batch_size, num_classes) í˜•íƒœì´ë¯€ë¡œ [:, 0, :] ëŒ€ì‹  ê·¸ëŒ€ë¡œ ì‚¬ìš©
# BERT hidden statesê°€ ì•„ë‹ˆë¯€ë¡œ ì°¨ì› ì¡°ì • ë¶ˆí•„ìš”
hidden_states_concat = hidden_states_concat.cpu().detach().numpy()

# DataFrameìœ¼ë¡œ ë³€í™˜ ë° CSV ì €ì¥ (voter_id í¬í•¨)
# Client ë°ì´í„°ì—ì„œ voter_id ì¶”ì¶œ
client_df = pd.read_csv("Client_smashed_data.csv")
server_voter_ids = client_df['voter_id'].tolist()
hidden_states_df = pd.DataFrame(hidden_states_concat)
hidden_states_df.insert(0, 'voter_id', server_voter_ids[:len(hidden_states_df)])  # voter_id ì¶”ê°€
hidden_states_df.to_csv("Dictionary_smashed_data.csv", index=False)

print(f"ğŸ’¾ Server-side smashed data saved to 'Dictionary_smashed_data.csv'")
print(f"ğŸ“Š Shape: {hidden_states_concat.shape}")
print("ğŸ‰ Server-side smashed data generation completed successfully!")
