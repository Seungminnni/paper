#!/usr/bin/env python3
"""
Simple Word2Vec to Mosaic Learning Test
ëª©ì : Word2Vec ë²¡í„° â†’ í”½ì…€ë³„ ì§ì ‘ ë§¤í•‘ â†’ í•™ìŠµ ê°€ëŠ¥ì„± í™•ì¸
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Reshape, Conv2D, Flatten, Conv2DTranspose
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from gensim.models import Word2Vec
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# GPU ì„¤ì •
print("=== GPU ì„¤ì • í™•ì¸ ===")
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"âœ… GPU ê°ì§€: {len(gpus)}ê°œ")
    except RuntimeError as e:
        print(f"âŒ GPU ì„¤ì • ì˜¤ë¥˜: {e}")
else:
    print("âš ï¸  CPU ì‚¬ìš©")

class SentenceMatrixProcessor:
    """Yoon Kim ë…¼ë¬¸ ìŠ¤íƒ€ì¼: ë¬¸ì¥ì„ Word2Vec í–‰ë ¬ë¡œ ì²˜ë¦¬"""
    
    def __init__(self, vector_size=128, max_words=32):
        self.vector_size = vector_size
        self.max_words = max_words  # ìµœëŒ€ ë‹¨ì–´ ìˆ˜ (íŒ¨ë”© ê¸°ì¤€)
        self.model = None
        print(f"ğŸ“„ ë¬¸ì¥ í–‰ë ¬ ì²˜ë¦¬: {max_words} ë‹¨ì–´ Ã— {vector_size} ì°¨ì› = [{max_words}x{vector_size}] í–‰ë ¬")
    
    def train_and_vectorize(self, texts):
        """í…ìŠ¤íŠ¸ë¥¼ Word2Vec í•™ìŠµ í›„ í–‰ë ¬ í˜•íƒœë¡œ ë³€í™˜"""
        print(f"ğŸ§  Word2Vec í•™ìŠµ ì‹œì‘ (í–‰ë ¬ ë°©ì‹, ë²¡í„° í¬ê¸°: {self.vector_size})...")
        
        # ë¬¸ì¥ì„ ë‹¨ì–´ë¡œ ë¶„í• 
        sentences = [text.split() for text in texts]
        
        # Word2Vec í•™ìŠµ
        self.model = Word2Vec(sentences, 
                             vector_size=self.vector_size, 
                             window=5, 
                             min_count=1, 
                             workers=4)
        
        print(f"âœ… Word2Vec í•™ìŠµ ì™„ë£Œ - ì–´íœ˜ ìˆ˜: {len(self.model.wv.key_to_index)}")
        
        # ê° ë¬¸ì¥ì„ í–‰ë ¬ë¡œ ë³€í™˜
        sentence_matrices = []
        for sentence in sentences:
            matrix = self._sentence_to_matrix(sentence)
            sentence_matrices.append(matrix)
        
        sentence_matrices = np.array(sentence_matrices)
        print(f"âœ… ë¬¸ì¥ í–‰ë ¬ ë³€í™˜ ì™„ë£Œ: {sentence_matrices.shape}")
        return sentence_matrices
    
    def _sentence_to_matrix(self, sentence):
        """ê°œë³„ ë¬¸ì¥ì„ [max_words x vector_size] í–‰ë ¬ë¡œ ë³€í™˜"""
        # ë¹ˆ í–‰ë ¬ ì´ˆê¸°í™”
        matrix = np.zeros((self.max_words, self.vector_size))
        
        # ë¬¸ì¥ì˜ ê° ë‹¨ì–´ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ í–‰ë ¬ì— ì±„ì›€
        for i, word in enumerate(sentence[:self.max_words]):  # max_words ì œí•œ
            if word in self.model.wv:
                matrix[i] = self.model.wv[word]
            # ì—†ëŠ” ë‹¨ì–´ëŠ” 0 ë²¡í„°ë¡œ ìœ ì§€ (íŒ¨ë”©)
        
        return matrix

class MatrixMosaicGenerator:
    """ë¬¸ì¥ í–‰ë ¬ì„ ëª¨ìì´í¬ ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
    
    def __init__(self, matrix_shape=(32, 128)):
        self.matrix_shape = matrix_shape  # (max_words, vector_size)
        self.max_words, self.vector_size = matrix_shape
        print(f"ğŸ–¼ï¸  í–‰ë ¬â†’ëª¨ìì´í¬: {self.max_words}x{self.vector_size} í–‰ë ¬ â†’ {self.max_words}x{self.vector_size} ì´ë¯¸ì§€")
    
    def matrices_to_mosaics(self, matrices):
        """ë¬¸ì¥ í–‰ë ¬ë“¤ì„ ëª¨ìì´í¬ ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        print(f"ğŸ¨ í–‰ë ¬ â†’ ëª¨ìì´í¬ ë³€í™˜ ì¤‘...")
        
        mosaics = []
        for i, matrix in enumerate(matrices):
            mosaic = self._matrix_to_mosaic(matrix)
            mosaics.append(mosaic)
            
            # ì²˜ìŒ 5ê°œ ìƒ˜í”Œ ì •ë³´ ì¶œë ¥
            if i < 5:
                non_zero_words = np.count_nonzero(np.sum(matrix, axis=1))  # ì‹¤ì œ ë‹¨ì–´ ìˆ˜
                print(f"  ìƒ˜í”Œ {i+1}: {non_zero_words}ê°œ ë‹¨ì–´, í–‰ë ¬ ë²”ìœ„ [{matrix.min():.3f}, {matrix.max():.3f}] â†’ ëª¨ìì´í¬ ë²”ìœ„ [{mosaic.min():.3f}, {mosaic.max():.3f}]")
        
        mosaics = np.array(mosaics)
        print(f"âœ… í–‰ë ¬ ëª¨ìì´í¬ ìƒì„± ì™„ë£Œ: {mosaics.shape}")
        return mosaics
    
    def _matrix_to_mosaic(self, matrix):
        """ê°œë³„ í–‰ë ¬ì„ ëª¨ìì´í¬ ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        # ì •ê·œí™”
        if matrix.std() > 0:
            normalized_matrix = (matrix - matrix.mean()) / matrix.std()
            # -3~3 ë²”ìœ„ë¡œ í´ë¦¬í•‘ í›„ 0~1ë¡œ ìŠ¤ì¼€ì¼ë§
            normalized_matrix = np.clip(normalized_matrix, -3, 3)
            normalized_matrix = (normalized_matrix + 3) / 6
        else:
            normalized_matrix = matrix
        
        # ì±„ë„ ì°¨ì› ì¶”ê°€ (32, 128, 1)
        mosaic = np.expand_dims(normalized_matrix, axis=-1)
        return mosaic

class SimpleWord2VecProcessor:
    """ê°„ë‹¨í•œ Word2Vec ì²˜ë¦¬ê¸° (í‰ê·  ë°©ì‹)"""
    
    def __init__(self, vector_size=256):
        self.vector_size = vector_size
        self.model = None
    
    def train_and_vectorize(self, texts):
        """í…ìŠ¤íŠ¸ í•™ìŠµ ë° ë²¡í„°í™”"""
        print(f"ğŸ§  Word2Vec í•™ìŠµ ì‹œì‘ (ë²¡í„° í¬ê¸°: {self.vector_size})...")
        
        # ë¬¸ì¥ì„ ë‹¨ì–´ë¡œ ë¶„í• 
        sentences = [text.split() for text in texts]
        
        # Word2Vec í•™ìŠµ
        self.model = Word2Vec(sentences, 
                             vector_size=self.vector_size, 
                             window=5, 
                             min_count=1, 
                             workers=4)
        
        print(f"âœ… Word2Vec í•™ìŠµ ì™„ë£Œ - ì–´íœ˜ ìˆ˜: {len(self.model.wv.key_to_index)}")
        
        # ê° ë¬¸ì¥ì„ ë²¡í„°ë¡œ ë³€í™˜ (í‰ê·  ë°©ì‹)
        vectors = []
        for sentence in sentences:
            word_vectors = [self.model.wv[word] for word in sentence if word in self.model.wv]
            if word_vectors:
                # ë¬¸ì¥ì˜ í‰ê·  ë²¡í„°
                sentence_vector = np.mean(word_vectors, axis=0)
            else:
                # ë¹ˆ ë²¡í„°
                sentence_vector = np.zeros(self.vector_size)
            vectors.append(sentence_vector)
        
        vectors = np.array(vectors)
        print(f"âœ… ë²¡í„°í™” ì™„ë£Œ: {vectors.shape}")
        return vectors

class ConvolutionalMosaicGenerator:
    """ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•œ ë‹¨ê³„ì  ë²¡í„°â†’ì´ë¯¸ì§€ ë§¤í•‘"""
    
    def __init__(self, vector_size=256, final_image_size=32):
        self.vector_size = vector_size
        self.final_image_size = final_image_size
        self.model = self._build_vector_to_image_model()
        print(f"ğŸ–¼ï¸  ì»¨ë³¼ë£¨ì…˜ ë§¤í•‘: {vector_size}ì°¨ì› â†’ {final_image_size}x{final_image_size} ì´ë¯¸ì§€")
    
    def _build_vector_to_image_model(self):
        """ë²¡í„°ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ëŠ” ì»¨ë³¼ë£¨ì…˜ ë„¤íŠ¸ì›Œí¬ êµ¬ì¶•"""
        print("ğŸ—ï¸  ë²¡í„°â†’ì´ë¯¸ì§€ ë³€í™˜ ë„¤íŠ¸ì›Œí¬ êµ¬ì¶•...")
        
        # ì…ë ¥: 256ì°¨ì› ë²¡í„°
        inputs = Input(shape=(self.vector_size,))
        
        # 1ë‹¨ê³„: Dense â†’ 2D êµ¬ì¡° ìƒì„± (4x4x16)
        x = Dense(256, activation='relu')(inputs)
        x = Dense(256, activation='relu')(x)  # ì¤‘ê°„ Dense ë ˆì´ì–´
        x = Reshape((4, 4, 16))(x)  # 4x4 ì´ë¯¸ì§€, 16ì±„ë„
        
        # 2ë‹¨ê³„: Conv2DTransposeë¡œ ì ì§„ì  í™•ì¥
        # 4x4x16 â†’ 8x8x32
        x = Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)
        
        # 8x8x32 â†’ 16x16x16
        x = Conv2DTranspose(16, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)
        
        # 16x16x16 â†’ 32x32x8
        x = Conv2DTranspose(8, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)
        
        # ìµœì¢…: 32x32x1 (ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€)
        outputs = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)
        
        model = Model(inputs, outputs, name='vector_to_image')
        print("âœ… ë²¡í„°â†’ì´ë¯¸ì§€ ë³€í™˜ ë„¤íŠ¸ì›Œí¬ êµ¬ì¶• ì™„ë£Œ")
        model.summary()
        
        return model
    
    def vectors_to_mosaics(self, vectors):
        """ë²¡í„°ë¥¼ ì»¨ë³¼ë£¨ì…˜ì„ í†µí•´ ëª¨ìì´í¬ ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        print(f"ğŸ¨ ì»¨ë³¼ë£¨ì…˜ ë²¡í„° â†’ ëª¨ìì´í¬ ë³€í™˜ ì¤‘...")
        
        # ë²¡í„° ì •ê·œí™”
        normalized_vectors = []
        for vector in vectors:
            # ë²¡í„°ë¥¼ -1~1 ë²”ìœ„ë¡œ ì •ê·œí™”
            if vector.std() > 0:
                norm_vector = (vector - vector.mean()) / vector.std()
                norm_vector = np.tanh(norm_vector)  # -1~1 ë²”ìœ„ë¡œ ì œí•œ
            else:
                norm_vector = vector
            normalized_vectors.append(norm_vector)
        
        normalized_vectors = np.array(normalized_vectors)
        
        # ì»¨ë³¼ë£¨ì…˜ ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ ì´ë¯¸ì§€ ìƒì„±
        mosaics = self.model.predict(normalized_vectors, verbose=0)
        
        # ì²˜ìŒ 5ê°œ ìƒ˜í”Œ ì •ë³´ ì¶œë ¥
        for i in range(min(5, len(vectors))):
            print(f"  ìƒ˜í”Œ {i+1}: ë²¡í„° ë²”ìœ„ [{vectors[i].min():.3f}, {vectors[i].max():.3f}] â†’ ëª¨ìì´í¬ ë²”ìœ„ [{mosaics[i].min():.3f}, {mosaics[i].max():.3f}]")
        
        print(f"âœ… ì»¨ë³¼ë£¨ì…˜ ëª¨ìì´í¬ ìƒì„± ì™„ë£Œ: {mosaics.shape}")
        return mosaics

class DirectMosaicGenerator:
    """ë²¡í„°ë¥¼ í”½ì…€ì— ì§ì ‘ ë§¤í•‘í•˜ëŠ” ëª¨ìì´í¬ ìƒì„±ê¸° (ë¹„êµìš©)"""
    
    def __init__(self, vector_size=256):
        self.vector_size = vector_size
        # 256ì°¨ì› â†’ 16x16 ì´ë¯¸ì§€ë¡œ ë§¤í•‘
        self.image_size = int(np.sqrt(vector_size))
        print(f"ğŸ–¼ï¸  ì§ì ‘ ë§¤í•‘ í¬ê¸°: {self.image_size}x{self.image_size} = {self.image_size**2}ì°¨ì›")
    
    def vectors_to_mosaics(self, vectors):
        """ë²¡í„°ë¥¼ ëª¨ìì´í¬ ì´ë¯¸ì§€ë¡œ ì§ì ‘ ë³€í™˜"""
        print(f"ğŸ¨ ì§ì ‘ ë²¡í„° â†’ ëª¨ìì´í¬ ë³€í™˜ ì¤‘...")
        
        mosaics = []
        for i, vector in enumerate(vectors):
            mosaic = self.vector_to_mosaic(vector)
            mosaics.append(mosaic)
            
            # ì²˜ìŒ 5ê°œ ìƒ˜í”Œ ì •ë³´ ì¶œë ¥
            if i < 5:
                print(f"  ìƒ˜í”Œ {i+1}: ë²¡í„° ë²”ìœ„ [{vector.min():.3f}, {vector.max():.3f}] â†’ ëª¨ìì´í¬ ë²”ìœ„ [{mosaic.min():.3f}, {mosaic.max():.3f}]")
        
        mosaics = np.array(mosaics)
        print(f"âœ… ì§ì ‘ ëª¨ìì´í¬ ìƒì„± ì™„ë£Œ: {mosaics.shape}")
        return mosaics
    
    def vector_to_mosaic(self, vector):
        """ë²¡í„° í•œ ê°œë¥¼ ëª¨ìì´í¬ ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        # ë²¡í„°ë¥¼ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
        if len(vector) != self.image_size**2:
            if len(vector) > self.image_size**2:
                # ë²¡í„°ê°€ ë” í¬ë©´ ìë¥´ê¸°
                vector = vector[:self.image_size**2]
            else:
                # ë²¡í„°ê°€ ë” ì‘ìœ¼ë©´ íŒ¨ë”©
                vector = np.pad(vector, (0, self.image_size**2 - len(vector)), 'constant')
        
        # ì •ê·œí™”: 0~1 ë²”ìœ„ë¡œ ë³€í™˜ (ì´ë¯¸ì§€ í”½ì…€ê°’ì²˜ëŸ¼)
        vector_min = vector.min()
        vector_max = vector.max()
        if vector_max > vector_min:
            normalized_vector = (vector - vector_min) / (vector_max - vector_min)
        else:
            normalized_vector = vector
        
        # ì´ë¯¸ì§€ í˜•íƒœë¡œ reshape
        mosaic = normalized_vector.reshape(self.image_size, self.image_size, 1)
        return mosaic

class MatrixCNN:
    """í–‰ë ¬ ì…ë ¥ì„ ìœ„í•œ CNN (Yoon Kim ìŠ¤íƒ€ì¼)"""
    
    def __init__(self, input_shape=(32, 128, 1)):
        self.input_shape = input_shape
        self.model = self._build_model()
    
    def _build_model(self):
        """Yoon Kim ë…¼ë¬¸ ìŠ¤íƒ€ì¼ì˜ CNN êµ¬ì¶•"""
        print("ğŸ—ï¸  í–‰ë ¬ CNN ì˜¤í† ì¸ì½”ë” êµ¬ì¶• (Yoon Kim ìŠ¤íƒ€ì¼)...")
        
        inputs = Input(shape=self.input_shape)  # (32, 128, 1)
        
        # ì¸ì½”ë”: ì—¬ëŸ¬ í•„í„° í¬ê¸°ë¡œ íŠ¹ì§• ì¶”ì¶œ
        # í•„í„° í¬ê¸°ë³„ ì»¨ë³¼ë£¨ì…˜ (3, 4, 5 ë‹¨ì–´ ê·¸ë£¹)
        conv_3 = Conv2D(64, (3, self.input_shape[1]), activation='relu', padding='valid')(inputs)  # (30, 1, 64)
        conv_4 = Conv2D(64, (4, self.input_shape[1]), activation='relu', padding='valid')(inputs)  # (29, 1, 64)  
        conv_5 = Conv2D(64, (5, self.input_shape[1]), activation='relu', padding='valid')(inputs)  # (28, 1, 64)
        
        # GlobalMaxPoolingìœ¼ë¡œ ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì§• ì¶”ì¶œ
        pool_3 = tf.keras.layers.GlobalMaxPooling2D()(conv_3)  # (64,)
        pool_4 = tf.keras.layers.GlobalMaxPooling2D()(conv_4)  # (64,)
        pool_5 = tf.keras.layers.GlobalMaxPooling2D()(conv_5)  # (64,)
        
        # íŠ¹ì§• ì—°ê²°
        merged = tf.keras.layers.concatenate([pool_3, pool_4, pool_5])  # (192,)
        
        # ì ì¬ ê³µê°„
        encoded = Dense(256, activation='relu')(merged)
        
        # ë””ì½”ë”: ì ì¬ ê³µê°„ì—ì„œ ì›ë³¸ í–‰ë ¬ ë³µì›
        x = Dense(512, activation='relu')(encoded)
        x = Dense(1024, activation='relu')(x)
        x = Dense(self.input_shape[0] * self.input_shape[1], activation='linear')(x)  # 32*128
        decoded = Reshape(self.input_shape)(x)
        
        # ëª¨ë¸ êµ¬ì„±
        autoencoder = Model(inputs, decoded)
        autoencoder.compile(optimizer='adam', loss='mse', metrics=['mae'])
        
        print("âœ… í–‰ë ¬ CNN êµ¬ì¶• ì™„ë£Œ")
        autoencoder.summary()
        return autoencoder
    
    def train(self, X_train, X_val, epochs=20):
        """í•™ìŠµ ì‹¤í–‰"""
        print("ğŸš€ í–‰ë ¬ CNN í•™ìŠµ ì‹œì‘...")
        
        history = self.model.fit(X_train, X_train,
                                epochs=epochs,
                                batch_size=32,
                                validation_data=(X_val, X_val),
                                verbose=1)
        
        print("âœ… í•™ìŠµ ì™„ë£Œ")
        return history

class SimpleCNN:
    """ê°„ë‹¨í•œ CNN í•™ìŠµê¸° (ê¸°ì¡´ ë°©ì‹)"""
    
    def __init__(self, image_size=32):  # 32x32ë¡œ ë³€ê²½
        self.image_size = image_size
        self.model = self._build_model()
    
    def _build_model(self):
        """ê°„ë‹¨í•œ ì˜¤í† ì¸ì½”ë” CNN êµ¬ì¶•"""
        print("ğŸ—ï¸  ê°„ë‹¨í•œ CNN ì˜¤í† ì¸ì½”ë” êµ¬ì¶•...")
        
        # ì¸ì½”ë” (32x32 â†’ 4x4)
        inputs = Input(shape=(self.image_size, self.image_size, 1))
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
        x = tf.keras.layers.MaxPooling2D((2, 2))(x)  # 32x32 â†’ 16x16
        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
        x = tf.keras.layers.MaxPooling2D((2, 2))(x)  # 16x16 â†’ 8x8
        x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
        encoded = tf.keras.layers.MaxPooling2D((2, 2))(x)  # 8x8 â†’ 4x4
        
        # ë””ì½”ë” (4x4 â†’ 32x32)
        x = Conv2D(128, (3, 3), activation='relu', padding='same')(encoded)
        x = tf.keras.layers.UpSampling2D((2, 2))(x)  # 4x4 â†’ 8x8
        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
        x = tf.keras.layers.UpSampling2D((2, 2))(x)  # 8x8 â†’ 16x16
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
        x = tf.keras.layers.UpSampling2D((2, 2))(x)  # 16x16 â†’ 32x32
        decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)
        
        # ëª¨ë¸ êµ¬ì„±
        autoencoder = Model(inputs, decoded)
        autoencoder.compile(optimizer='adam', loss='mse', metrics=['mae'])
        
        print("âœ… CNN êµ¬ì¶• ì™„ë£Œ")
        autoencoder.summary()
        return autoencoder
    
    def train(self, X_train, X_val, epochs=20):
        """í•™ìŠµ ì‹¤í–‰"""
        print("ğŸš€ CNN í•™ìŠµ ì‹œì‘...")
        
        history = self.model.fit(X_train, X_train,  # ì˜¤í† ì¸ì½”ë”: ì…ë ¥=ì¶œë ¥
                                epochs=epochs,
                                batch_size=32,
                                validation_data=(X_val, X_val),
                                verbose=1)
        
        print("âœ… í•™ìŠµ ì™„ë£Œ")
        return history

def compare_all_methods(vectors_avg, matrices, mosaics_conv, mosaics_direct, mosaics_matrix, num_samples=3):
    """ëª¨ë“  ë§¤í•‘ ë°©ë²• ë¹„êµ"""
    print(f"ğŸ” ì „ì²´ ë§¤í•‘ ë°©ë²• ë¹„êµ ì‹œê°í™” ({num_samples}ê°œ ìƒ˜í”Œ)...")
    
    fig, axes = plt.subplots(5, num_samples, figsize=(15, 20))
    
    for i in range(num_samples):
        # 1. ì›ë³¸ ë²¡í„° (í‰ê·  ë°©ì‹)
        axes[0, i].hist(vectors_avg[i], bins=30, alpha=0.7, color='blue')
        axes[0, i].set_title(f'Avg Vector {i+1}\n(min:{vectors_avg[i].min():.3f}, max:{vectors_avg[i].max():.3f})')
        axes[0, i].set_xlabel('Value')
        axes[0, i].set_ylabel('Count')
        
        # 2. ë¬¸ì¥ í–‰ë ¬ (Yoon Kim ë°©ì‹)
        im1 = axes[1, i].imshow(matrices[i].squeeze(), cmap='viridis', aspect='auto')
        axes[1, i].set_title(f'Sentence Matrix {i+1}\n32 words Ã— 128 dims')
        axes[1, i].set_xlabel('Vector Dimensions')
        axes[1, i].set_ylabel('Word Position')
        plt.colorbar(im1, ax=axes[1, i], fraction=0.046, pad=0.04)
        
        # 3. ì»¨ë³¼ë£¨ì…˜ ë§¤í•‘ (32x32)
        im2 = axes[2, i].imshow(mosaics_conv[i].squeeze(), cmap='gray')
        axes[2, i].set_title(f'Conv Mapping {i+1}\n32x32')
        axes[2, i].axis('off')
        plt.colorbar(im2, ax=axes[2, i], fraction=0.046, pad=0.04)
        
        # 4. ì§ì ‘ ë§¤í•‘ (16x16)
        im3 = axes[3, i].imshow(mosaics_direct[i].squeeze(), cmap='gray')
        axes[3, i].set_title(f'Direct Mapping {i+1}\n16x16')
        axes[3, i].axis('off')
        plt.colorbar(im3, ax=axes[3, i], fraction=0.046, pad=0.04)
        
        # 5. í–‰ë ¬ ëª¨ìì´í¬ (32x128)
        im4 = axes[4, i].imshow(mosaics_matrix[i].squeeze(), cmap='gray', aspect='auto')
        axes[4, i].set_title(f'Matrix Mosaic {i+1}\n32x128')
        axes[4, i].set_xlabel('Vector Dimensions')
        axes[4, i].set_ylabel('Word Position')
        plt.colorbar(im4, ax=axes[4, i], fraction=0.046, pad=0.04)
    
    plt.suptitle('All Vector â†’ Mosaic Mapping Methods Comparison', fontsize=16)
    plt.tight_layout()
    plt.show()

def compare_mosaic_methods(vectors, mosaics_conv, mosaics_direct, num_samples=5):
    """ì»¨ë³¼ë£¨ì…˜ vs ì§ì ‘ ë§¤í•‘ ë°©ë²• ë¹„êµ"""
    print(f"ğŸ” ë§¤í•‘ ë°©ë²• ë¹„êµ ì‹œê°í™” ({num_samples}ê°œ ìƒ˜í”Œ)...")
    
    fig, axes = plt.subplots(3, num_samples, figsize=(20, 12))
    
    for i in range(num_samples):
        # ì›ë³¸ ë²¡í„° íˆìŠ¤í† ê·¸ë¨
        axes[0, i].hist(vectors[i], bins=30, alpha=0.7, color='blue')
        axes[0, i].set_title(f'Vector {i+1}\n(min:{vectors[i].min():.3f}, max:{vectors[i].max():.3f})')
        axes[0, i].set_xlabel('Value')
        axes[0, i].set_ylabel('Count')
        
        # ì»¨ë³¼ë£¨ì…˜ ë§¤í•‘ ê²°ê³¼ (32x32)
        im1 = axes[1, i].imshow(mosaics_conv[i].squeeze(), cmap='gray')
        axes[1, i].set_title(f'Conv Mapping {i+1}\n32x32')
        axes[1, i].axis('off')
        plt.colorbar(im1, ax=axes[1, i], fraction=0.046, pad=0.04)
        
        # ì§ì ‘ ë§¤í•‘ ê²°ê³¼ (16x16)
        im2 = axes[2, i].imshow(mosaics_direct[i].squeeze(), cmap='gray')
        axes[2, i].set_title(f'Direct Mapping {i+1}\n16x16')
        axes[2, i].axis('off')
        plt.colorbar(im2, ax=axes[2, i], fraction=0.046, pad=0.04)
    
    plt.suptitle('Vector â†’ Mosaic Mapping Methods Comparison', fontsize=16)
    plt.tight_layout()
    plt.show()

def visualize_mosaics(vectors, mosaics, num_samples=5):
    """ë²¡í„°ì™€ ëª¨ìì´í¬ ì‹œê°í™”"""
    print(f"ğŸ¨ ë²¡í„° â†’ ëª¨ìì´í¬ ì‹œê°í™” ({num_samples}ê°œ ìƒ˜í”Œ)...")
    
    fig, axes = plt.subplots(2, num_samples, figsize=(15, 6))
    
    for i in range(num_samples):
        # ì›ë³¸ ë²¡í„° íˆìŠ¤í† ê·¸ë¨
        axes[0, i].hist(vectors[i], bins=30, alpha=0.7, color='blue')
        axes[0, i].set_title(f'Vector {i+1}\n(min:{vectors[i].min():.3f}, max:{vectors[i].max():.3f})')
        axes[0, i].set_xlabel('Value')
        axes[0, i].set_ylabel('Count')
        
        # ëª¨ìì´í¬ ì´ë¯¸ì§€
        im = axes[1, i].imshow(mosaics[i].squeeze(), cmap='gray')
        axes[1, i].set_title(f'Mosaic {i+1}')
        axes[1, i].axis('off')
        plt.colorbar(im, ax=axes[1, i], fraction=0.046, pad=0.04)
    
    plt.tight_layout()
    plt.show()

def visualize_reconstruction(original, reconstructed, num_samples=5):
    """ë³µì› ê²°ê³¼ ì‹œê°í™”"""
    print(f"ğŸ¨ ë³µì› ê²°ê³¼ ì‹œê°í™” ({num_samples}ê°œ ìƒ˜í”Œ)...")
    
    fig, axes = plt.subplots(2, num_samples, figsize=(15, 6))
    
    for i in range(num_samples):
        # ì›ë³¸
        im1 = axes[0, i].imshow(original[i].squeeze(), cmap='gray')
        axes[0, i].set_title(f'Original {i+1}')
        axes[0, i].axis('off')
        plt.colorbar(im1, ax=axes[0, i], fraction=0.046, pad=0.04)
        
        # ë³µì›
        im2 = axes[1, i].imshow(reconstructed[i].squeeze(), cmap='gray')
        axes[1, i].set_title(f'Reconstructed {i+1}')
        axes[1, i].axis('off')
        plt.colorbar(im2, ax=axes[1, i], fraction=0.046, pad=0.04)
    
    plt.tight_layout()
    plt.show()

def analyze_learning_quality(original, reconstructed):
    """í•™ìŠµ í’ˆì§ˆ ë¶„ì„"""
    print("\nğŸ” í•™ìŠµ í’ˆì§ˆ ë¶„ì„:")
    
    # MSE, MAE ê³„ì‚°
    mse = np.mean((original - reconstructed) ** 2)
    mae = np.mean(np.abs(original - reconstructed))
    
    # ìƒê´€ê´€ê³„
    corr = np.corrcoef(original.flatten(), reconstructed.flatten())[0, 1]
    
    print(f"  ğŸ“Š MSE (í‰ê·  ì œê³± ì˜¤ì°¨): {mse:.6f}")
    print(f"  ğŸ“Š MAE (í‰ê·  ì ˆëŒ€ ì˜¤ì°¨): {mae:.6f}")
    print(f"  ğŸ“Š ìƒê´€ê´€ê³„: {corr:.4f}")
    
    # í•™ìŠµ ê°€ëŠ¥ì„± íŒì •
    if mae < 0.1 and corr > 0.7:
        print("  âœ… í•™ìŠµ ê°€ëŠ¥: ëª¨ë¸ì´ íŒ¨í„´ì„ ì„±ê³µì ìœ¼ë¡œ í•™ìŠµí–ˆìŠµë‹ˆë‹¤!")
    elif mae < 0.2 and corr > 0.5:
        print("  ğŸ”„ ë¶€ë¶„ í•™ìŠµ: ëª¨ë¸ì´ ì¼ë¶€ íŒ¨í„´ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.")
    else:
        print("  âŒ í•™ìŠµ ë¶€ì¡±: ë” ë§ì€ í•™ìŠµì´ë‚˜ ë‹¤ë¥¸ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

def main():
    print("\n=== Enhanced Word2Vec â†’ Mosaic Learning Test ===")
    print("ëª©ì : ë‹¤ì–‘í•œ ë²¡í„°â†’ì´ë¯¸ì§€ ë§¤í•‘ ë°©ë²• ë¹„êµ ë° í•™ìŠµ ê°€ëŠ¥ì„± í™•ì¸\n")
    
    # 1. ë°ì´í„° ë¡œë”©
    print("--- 1ë‹¨ê³„: ë°ì´í„° ë¡œë”© ---")
    df = pd.read_csv('ncvotera.csv', nrows=1000, encoding='latin1')
    
    # ëª¨ë“  ì»¬ëŸ¼ì„ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
    df['combined_text'] = df.astype(str).agg(' '.join, axis=1)
    texts = df['combined_text'].tolist()
    
    print(f"âœ… {len(texts)}ê°œ í…ìŠ¤íŠ¸ ë¡œë“œ")
    print(f"ğŸ“ ìƒ˜í”Œ í…ìŠ¤íŠ¸: {texts[0][:100]}...")
    
    # 2-1. í‰ê·  ë²¡í„° ë°©ì‹ (ê¸°ì¡´)
    print("\n--- 2-1ë‹¨ê³„: í‰ê·  ë²¡í„° ë°©ì‹ ---")
    processor_avg = SimpleWord2VecProcessor(vector_size=256)
    vectors_avg = processor_avg.train_and_vectorize(texts)
    
    # 2-2. í–‰ë ¬ ë°©ì‹ (Yoon Kim ìŠ¤íƒ€ì¼)
    print("\n--- 2-2ë‹¨ê³„: ë¬¸ì¥ í–‰ë ¬ ë°©ì‹ (Yoon Kim ìŠ¤íƒ€ì¼) ---")
    processor_matrix = SentenceMatrixProcessor(vector_size=128, max_words=32)
    sentence_matrices = processor_matrix.train_and_vectorize(texts)
    
    # 3-1. ì»¨ë³¼ë£¨ì…˜ ë§¤í•‘ (256 â†’ 32x32)
    print("\n--- 3-1ë‹¨ê³„: ì»¨ë³¼ë£¨ì…˜ ë§¤í•‘ ---")
    conv_mosaic_gen = ConvolutionalMosaicGenerator(vector_size=256, final_image_size=32)
    mosaics_conv = conv_mosaic_gen.vectors_to_mosaics(vectors_avg)
    
    # 3-2. ì§ì ‘ ë§¤í•‘ (256 â†’ 16x16)
    print("\n--- 3-2ë‹¨ê³„: ì§ì ‘ ë§¤í•‘ ---")
    direct_mosaic_gen = DirectMosaicGenerator(vector_size=256)
    mosaics_direct = direct_mosaic_gen.vectors_to_mosaics(vectors_avg)
    
    # 3-3. í–‰ë ¬ ëª¨ìì´í¬ (32x128 í–‰ë ¬ ê·¸ëŒ€ë¡œ)
    print("\n--- 3-3ë‹¨ê³„: í–‰ë ¬ ëª¨ìì´í¬ ---")
    matrix_mosaic_gen = MatrixMosaicGenerator(matrix_shape=(32, 128))
    mosaics_matrix = matrix_mosaic_gen.matrices_to_mosaics(sentence_matrices)
    
    # 4. ì „ì²´ ë°©ë²• ë¹„êµ ì‹œê°í™”
    print("\n--- 4ë‹¨ê³„: ì „ì²´ ë°©ë²• ë¹„êµ ì‹œê°í™” ---")
    compare_all_methods(vectors_avg, sentence_matrices, mosaics_conv, mosaics_direct, mosaics_matrix, num_samples=3)
    
    # 5. í–‰ë ¬ ë°©ì‹ í•™ìŠµ í…ŒìŠ¤íŠ¸ (Yoon Kim ìŠ¤íƒ€ì¼)
    print("\n--- 5ë‹¨ê³„: í–‰ë ¬ ë°©ì‹ CNN í•™ìŠµ í…ŒìŠ¤íŠ¸ ---")
    X_train_matrix, X_test_matrix = train_test_split(mosaics_matrix, test_size=0.2, random_state=42)
    print(f"  - í–‰ë ¬ í•™ìŠµ ë°ì´í„°: {X_train_matrix.shape}")
    print(f"  - í–‰ë ¬ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test_matrix.shape}")
    
    # í–‰ë ¬ CNN í•™ìŠµ
    matrix_cnn = MatrixCNN(input_shape=(32, 128, 1))
    history_matrix = matrix_cnn.train(X_train_matrix, X_test_matrix, epochs=10)
    
    # 6. ê¸°ì¡´ ë°©ì‹ê³¼ ì„±ëŠ¥ ë¹„êµ
    print("\n--- 6ë‹¨ê³„: ì§ì ‘ ë§¤í•‘ ë°©ì‹ í•™ìŠµ (ë¹„êµìš©) ---")
    X_train_direct, X_test_direct = train_test_split(mosaics_direct, test_size=0.2, random_state=42)
    
    direct_cnn = SimpleCNN(image_size=16)
    history_direct = direct_cnn.train(X_train_direct, X_test_direct, epochs=10)
    
    # 7. ê²°ê³¼ ë¹„êµ
    print("\n--- 7ë‹¨ê³„: í•™ìŠµ ê²°ê³¼ ë¹„êµ ---")
    
    # í–‰ë ¬ ë°©ì‹ ê²°ê³¼
    predictions_matrix = matrix_cnn.model.predict(X_test_matrix[:5], verbose=0)
    print("\nğŸ” í–‰ë ¬ ë°©ì‹ (Yoon Kim ìŠ¤íƒ€ì¼) í•™ìŠµ í’ˆì§ˆ:")
    analyze_learning_quality(X_test_matrix, matrix_cnn.model.predict(X_test_matrix, verbose=0))
    
    # ì§ì ‘ ë§¤í•‘ ë°©ì‹ ê²°ê³¼
    predictions_direct = direct_cnn.model.predict(X_test_direct[:5], verbose=0)
    print("\nğŸ” ì§ì ‘ ë§¤í•‘ ë°©ì‹ í•™ìŠµ í’ˆì§ˆ:")
    analyze_learning_quality(X_test_direct, direct_cnn.model.predict(X_test_direct, verbose=0))
    
    # 8. ë³µì› ê²°ê³¼ ì‹œê°í™”
    print("\n--- 8ë‹¨ê³„: ë³µì› ê²°ê³¼ ì‹œê°í™” ---")
    
    # í–‰ë ¬ ë°©ì‹ ë³µì› ê²°ê³¼
    print("í–‰ë ¬ ë°©ì‹ ë³µì› ê²°ê³¼:")
    visualize_reconstruction(X_test_matrix[:3], predictions_matrix[:3], num_samples=3)
    
    # ì§ì ‘ ë§¤í•‘ ë°©ì‹ ë³µì› ê²°ê³¼
    print("ì§ì ‘ ë§¤í•‘ ë°©ì‹ ë³µì› ê²°ê³¼:")
    visualize_reconstruction(X_test_direct[:3], predictions_direct[:3], num_samples=3)
    
    # 9. í•™ìŠµ ê³¡ì„  ë¹„êµ
    print("\n--- 9ë‹¨ê³„: í•™ìŠµ ê³¡ì„  ë¹„êµ ---")
    plt.figure(figsize=(15, 5))
    
    plt.subplot(1, 3, 1)
    plt.plot(history_matrix.history['loss'], label='Matrix Method Training', color='blue')
    plt.plot(history_matrix.history['val_loss'], label='Matrix Method Validation', color='lightblue')
    plt.plot(history_direct.history['loss'], label='Direct Method Training', color='red')
    plt.plot(history_direct.history['val_loss'], label='Direct Method Validation', color='pink')
    plt.title('Loss Comparison')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.subplot(1, 3, 2)
    plt.plot(history_matrix.history['mae'], label='Matrix Method Training', color='blue')
    plt.plot(history_matrix.history['val_mae'], label='Matrix Method Validation', color='lightblue')
    plt.plot(history_direct.history['mae'], label='Direct Method Training', color='red')
    plt.plot(history_direct.history['val_mae'], label='Direct Method Validation', color='pink')
    plt.title('MAE Comparison')
    plt.xlabel('Epoch')
    plt.ylabel('MAE')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.subplot(1, 3, 3)
    methods = ['Matrix\n(Yoon Kim)', 'Direct\nMapping']
    final_mae = [history_matrix.history['val_mae'][-1], history_direct.history['val_mae'][-1]]
    colors = ['blue', 'red']
    plt.bar(methods, final_mae, color=colors, alpha=0.7)
    plt.title('Final Validation MAE')
    plt.ylabel('MAE')
    for i, v in enumerate(final_mae):
        plt.text(i, v + 0.001, f'{v:.4f}', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.show()
    
    print("\n=== ìµœì¢… ê²°ë¡  ===")
    print("ğŸ‰ ë‹¤ì–‘í•œ Word2Vec â†’ ëª¨ìì´í¬ ë§¤í•‘ ë°©ë²• ë¹„êµ ì™„ë£Œ!")
    print(f"ğŸ“Š í–‰ë ¬ ë°©ì‹ (Yoon Kim) ìµœì¢… MAE: {history_matrix.history['val_mae'][-1]:.6f}")
    print(f"ğŸ“Š ì§ì ‘ ë§¤í•‘ ë°©ì‹ ìµœì¢… MAE: {history_direct.history['val_mae'][-1]:.6f}")
    
    if history_matrix.history['val_mae'][-1] < history_direct.history['val_mae'][-1]:
        print("âœ… ê²°ë¡ : í–‰ë ¬ ë°©ì‹(Yoon Kim ìŠ¤íƒ€ì¼)ì´ ë” ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤!")
        print("   ğŸ“ ì´ìœ : ë‹¨ì–´ ìœ„ì¹˜ ì •ë³´ì™€ ë¬¸ë§¥ ì •ë³´ê°€ ë” ì˜ ë³´ì¡´ë¨")
    else:
        print("âœ… ê²°ë¡ : ì§ì ‘ ë§¤í•‘ ë°©ì‹ì´ ë” ìš°ìˆ˜í•˜ê±°ë‚˜ ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤!")
        print("   ğŸ“ ì´ìœ : ê°„ë‹¨í•œ êµ¬ì¡°ë¡œë„ ì¶©ë¶„í•œ ì •ë³´ ë³´ì¡´ ê°€ëŠ¥")

if __name__ == "__main__":
    main()
