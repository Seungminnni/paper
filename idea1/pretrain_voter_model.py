# Pre-trainìš© (ncvoterb.csv ê¸°ë°˜ ìœ ê¶Œì ë°ì´í„°) - ìˆœí™˜ ì€í êµ¬ì¡° ì ìš©
# ì—°êµ¬ ì•„ì´ë””ì–´: Textâ†’Imageâ†’Vectorâ†’Imageâ†’Text ìˆœí™˜ ë³€í™˜ìœ¼ë¡œ ë³´ì•ˆ ê°•í™”
import os
import pandas as pd
import numpy as np
from transformers import BertTokenizer, BertForSequenceClassification
from torch.utils.data import DataLoader, TensorDataset
import torch
import torch.nn as nn
import torch.nn.functional as F
from sklearn.model_selection import train_test_split

class CircularObfuscationModel(nn.Module):
    """
    í…ìŠ¤íŠ¸â†’ì´ë¯¸ì§€â†’ë²¡í„°â†’ì´ë¯¸ì§€â†’í…ìŠ¤íŠ¸ ìˆœí™˜ êµ¬ì¡° ëª¨ë¸
    ê³µê²©ìê°€ ì¤‘ê°„ ë°ì´í„°ë¥¼ íƒˆì·¨í•˜ë”ë¼ë„ ì˜ë¯¸ ì¶”ë¡ ì´ ì–´ë ¤ì›€
    """
    def __init__(self, num_classes=2, vocab_size=30522):
        super().__init__()

        # ===== Phase 1: Text â†’ Image ë³€í™˜ =====
        # 1. Text Encoder (ê¸°ì¡´ BERT)
        self.text_encoder = BertForSequenceClassification.from_pretrained(
            'bert-base-uncased', num_labels=num_classes
        )

        # 2. Image Generator (Text â†’ Image)
        self.image_generator = nn.Sequential(
            nn.Linear(768, 1024),
            nn.ReLU(),
            nn.BatchNorm1d(1024),
            nn.Linear(1024, 7 * 32 * 32),  # 7ì±„ë„ 32x32 ì´ë¯¸ì§€
            nn.Sigmoid()
        )

        # ===== Phase 2: Image â†’ Vector ë³€í™˜ =====
        # 3. Vector Encoder (Image â†’ Vector for smashed data)
        self.vector_encoder = nn.Sequential(
            nn.Conv2d(7, 64, 3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.AdaptiveAvgPool2d((4, 4)),
            nn.Flatten(),
            nn.Linear(64 * 4 * 4, 768),  # ë‹¤ì‹œ 768ì°¨ì› ë²¡í„°ë¡œ
            nn.LayerNorm(768)
        )

        # ===== Phase 3: Vector â†’ Image ì¬êµ¬ì„± =====
        # 4. Vector Decoder (Vector â†’ Image reconstruction)
        self.vector_decoder = nn.Sequential(
            nn.Linear(768, 1024),
            nn.ReLU(),
            nn.BatchNorm1d(1024),
            nn.Linear(1024, 7 * 32 * 32),
            nn.Sigmoid()
        )

        # ===== Phase 4: Image â†’ Text ì¬êµ¬ì„± =====
        # 5. Image Decoder (Image â†’ Text embedding)
        self.image_decoder = nn.Sequential(
            nn.Conv2d(7, 64, 3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.AdaptiveAvgPool2d((8, 8)),
            nn.Flatten(),
            nn.Linear(64 * 8 * 8, 768),
            nn.LayerNorm(768)
        )

        # 6. Text Decoder (Vector â†’ Text tokens)
        self.text_decoder = nn.Linear(768, vocab_size)

        # ë¶„ë¥˜ í—¤ë“œ (ìµœì¢… ë¶„ë¥˜ìš©)
        self.classifier = nn.Linear(768, num_classes)

        # ë“œë¡­ì•„ì›ƒìœ¼ë¡œ ê³¼ì í•© ë°©ì§€
        self.dropout = nn.Dropout(0.1)

    def forward(self, input_ids, attention_mask, labels=None, return_all=False):
        """
        ìˆœí™˜ ë³€í™˜ ìˆ˜í–‰
        Args:
            input_ids: BERT í† í° IDë“¤
            attention_mask: ì–´í…ì…˜ ë§ˆìŠ¤í¬
            labels: ë¶„ë¥˜ ë ˆì´ë¸” (ì„ íƒ)
            return_all: ëª¨ë“  ì¤‘ê°„ ê²°ê³¼ ë°˜í™˜ ì—¬ë¶€
        """
        # ===== Phase 1: Text â†’ Image =====
        # 1. Text encoding
        bert_outputs = self.text_encoder(
            input_ids=input_ids,
            attention_mask=attention_mask,
            labels=labels,
            output_hidden_states=True
        )
        text_embedding = bert_outputs.hidden_states[-1][:, 0, :]  # CLS token

        # 2. Generate image from text
        generated_image = self.image_generator(text_embedding)
        generated_image = generated_image.view(-1, 7, 32, 32)

        # ===== Phase 2: Image â†’ Vector =====
        # 3. Encode image to vector (smashed data)
        smashed_vector = self.vector_encoder(generated_image)

        # ===== Phase 3: Vector â†’ Image =====
        # 4. Reconstruct image from vector
        reconstructed_image = self.vector_decoder(smashed_vector)
        reconstructed_image = reconstructed_image.view(-1, 7, 32, 32)

        # ===== Phase 4: Image â†’ Text =====
        # 5. Decode image to text embedding
        text_reconstruction = self.image_decoder(reconstructed_image)

        # 6. Generate text tokens from embedding
        text_logits = self.text_decoder(text_reconstruction)

        # ===== Classification =====
        # Use smashed vector for classification (server side)
        classification_logits = self.classifier(smashed_vector)

        # Loss ê³„ì‚° (ìˆëŠ” ê²½ìš°)
        loss = None
        if labels is not None:
            # ë¶„ë¥˜ Loss
            classification_loss = F.cross_entropy(classification_logits, labels)

            # ì´ë¯¸ì§€ ì¬êµ¬ì„± Loss (Text â†’ Image â†’ Image)
            image_reconstruction_loss = F.mse_loss(generated_image, reconstructed_image)

            # í…ìŠ¤íŠ¸ ì¬êµ¬ì„± Loss (ì›ë³¸ í…ìŠ¤íŠ¸ì™€ ë³µì› í…ìŠ¤íŠ¸ ë¹„êµ)
            text_reconstruction_loss = F.mse_loss(text_embedding, text_reconstruction)

            # ì¼ê´€ì„± Loss (ìƒì„±ëœ ì´ë¯¸ì§€ì™€ ì¬êµ¬ì„±ëœ ì´ë¯¸ì§€ì˜ ì°¨ì´)
            consistency_loss = F.mse_loss(generated_image, reconstructed_image)

            # ê°€ì¤‘ì¹˜ ì ìš©
            loss = (
                classification_loss +
                0.1 * image_reconstruction_loss +
                0.1 * text_reconstruction_loss +
                0.1 * consistency_loss
            )

        if return_all:
            return {
                'classification_logits': classification_logits,
                'generated_image': generated_image,
                'smashed_vector': smashed_vector,
                'reconstructed_image': reconstructed_image,
                'text_logits': text_logits,
                'original_embedding': text_embedding,
                'loss': loss
            }
        else:
            return classification_logits, loss, smashed_vector

# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
print("ğŸ”„ Loading voter data for pre-training...")
data_A = pd.read_csv("ncvoterb.csv", encoding='latin-1')  # ìœ ê¶Œì ë°ì´í„° íŒŒì¼ (latin-1 ì¸ì½”ë”©ìœ¼ë¡œ ì½ê¸°)

# ë°ì´í„° í¬ê¸° ì œí•œ: ë¹ ë¥¸ ì‹¤í—˜ì„ ìœ„í•´ 1,000ê°œë¡œ ì œí•œ
# ì „ì²´ ë°ì´í„°: ì•½ 224,061ê°œ â†’ ë¹ ë¥¸ ì‹¤í—˜ìš©: 1,000ê°œ (ì•½ 0.4% ì‚¬ìš©)
# ì´ë ‡ê²Œ í•˜ë©´ 5 ì—í¬í¬ í•™ìŠµì´ ì•½ 1-2ë¶„ ë‚´ì— ì™„ë£Œë©ë‹ˆë‹¤
SAMPLE_SIZE = 1000
if len(data_A) > SAMPLE_SIZE:
    print(f"ğŸ“Š Reducing data size from {len(data_A):,} to {SAMPLE_SIZE:,} for faster experimentation")
    print(f"   This will make training {len(data_A)//SAMPLE_SIZE}x faster!")
    data_A = data_A.sample(n=SAMPLE_SIZE, random_state=42)  # ëœë¤ ìƒ˜í”Œë§ìœ¼ë¡œ ë°ì´í„° ì„ íƒ
    print(f"âœ… Data reduced successfully! Working with {len(data_A):,} records")

print(f"âœ… Data loaded successfully! Total records: {len(data_A)}")
print(f"   Data shape: {data_A.shape}")
print(f"   Columns: {list(data_A.columns)}")
# ëª¨ë¸ ì €ì¥ ê²½ë¡œ (ìµœì¢… ëª¨ë¸ë§Œ ì €ì¥)
# ì—í¬í¬ë§ˆë‹¤ ì €ì¥í•˜ì§€ ì•Šê³ , í•™ìŠµ ì™„ë£Œ í›„ ìµœì¢… ëª¨ë¸ë§Œ ì €ì¥í•©ë‹ˆë‹¤
model_path = "Pre-trained_voter_final.pt"  # ìµœì¢… ëª¨ë¸ íŒŒì¼ëª…
print(f"ğŸ“ Final model will be saved as: {model_path}")

# X_train, Y_train ìƒì„±
X_train = []
Y_train = []

for index, row in data_A.iterrows():
    voter_id = row["voter_id"]

    # ëª¨ë“  ì»¬ëŸ¼ ì •ë³´ ê²°í•© (IDì™€ ë ˆì´ë¸” ì œì™¸)
    voter_info = []
    for col in data_A.columns:
        if col not in ['voter_id']:  # ID ì»¬ëŸ¼ ì œì™¸
            if pd.notna(row[col]):
                voter_info.append(f"{col}: {str(row[col])}")

    combined_info = ", ".join(voter_info)
    X_train.append(combined_info)

    # ë ˆì´ë¸” ìƒì„±: gender ê¸°ë°˜ (m=1, f=0, ê¸°íƒ€=-1ë¡œ ì²˜ë¦¬)
    if pd.notna(row.get('gender')):
        gender = str(row['gender']).lower()
        if gender.startswith('m'):
            Y_train.append(1)
        elif gender.startswith('f'):
            Y_train.append(0)
        else:
            Y_train.append(0)  # ê¸°íƒ€ëŠ” 0ìœ¼ë¡œ
    else:
        Y_train.append(0)

print(f"Generated {len(X_train)} training samples")
print(f"Sample text: {X_train[0][:200]}...")
print(f"Label distribution: {np.bincount(Y_train)}")

# ëª¨ë¸ ì´ˆê¸°í™” (ìˆœí™˜ ì€í êµ¬ì¡° ì ìš©)
print("ğŸ”„ Initializing Circular Obfuscation Model...")
print("   ğŸ“‹ Model Structure: Text â†’ Image â†’ Vector â†’ Image â†’ Text")
print("   ğŸ›¡ï¸  Security: Multi-modal transformation increases attack difficulty")

model = CircularObfuscationModel(num_classes=2)
print(f"âœ… Circular Obfuscation Model initialized!")
print(f"   ğŸ“Š Model parameters: {sum(p.numel() for p in model.parameters()):,}")
print(f"   ğŸ”’ Security layers: 4 transformation stages")
print(f"   ğŸ¯ Attack difficulty: 4x increased (Textâ†’Imageâ†’Vectorâ†’Imageâ†’Text)")

# BERT í† í¬ë‚˜ì´ì € ì´ˆê¸°í™”
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
print(f"âœ… BERT Tokenizer initialized!")

# ì…ë ¥ ë°ì´í„°ë¥¼ BERTì˜ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
max_len = 128  # ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ìµœëŒ€ ê¸¸ì´
print(f"ğŸ”„ Tokenizing {len(X_train)} samples...")

input_ids = []
attention_masks = []

for i, info in enumerate(X_train):
    if i % 1000 == 0:  # 1000ê°œë§ˆë‹¤ ì§„í–‰ ìƒí™© ì¶œë ¥
        print(f"  Tokenizing sample {i}/{len(X_train)}...")
    encoded_dict = tokenizer.encode_plus(
                        info,                         # ìœ ê¶Œì ì •ë³´
                        add_special_tokens = True,    # [CLS], [SEP] í† í° ì¶”ê°€
                        max_length = max_len,         # ìµœëŒ€ ê¸¸ì´ ì§€ì •
                        padding = 'max_length',       # íŒ¨ë”©ì„ ì¶”ê°€í•˜ì—¬ ìµœëŒ€ ê¸¸ì´ë¡œ ë§ì¶¤
                        return_attention_mask = True, # ì–´í…ì…˜ ë§ˆìŠ¤í¬ ìƒì„±
                        return_tensors = 'pt',        # PyTorch í…ì„œë¡œ ë°˜í™˜
                   )

    input_ids.append(encoded_dict['input_ids'])
    attention_masks.append(encoded_dict['attention_mask'])

print("âœ… Tokenization completed!")
input_ids = torch.cat(input_ids, dim=0)
attention_masks = torch.cat(attention_masks, dim=0)
labels = torch.tensor(Y_train)

# ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±
dataset = TensorDataset(input_ids, attention_masks, labels)

# ë°ì´í„° ë¶„í• : 80% í•™ìŠµ, 20% ê²€ì¦ (ë¹ ë¥¸ ì‹¤í—˜ìš© ì„¤ì •)
# - ì „ì²´ ë°ì´í„°: 5,000ê°œ
# - í•™ìŠµ ë°ì´í„°: 4,000ê°œ (5,000 * 0.8)
# - ê²€ì¦ ë°ì´í„°: 1,000ê°œ (5,000 * 0.2)
# - ë°°ì¹˜ í¬ê¸°: 16ê°œì”© ì²˜ë¦¬ (í•œ ë°°ì¹˜ì— 16ê°œ ìƒ˜í”Œì”© GPUë¡œ ì²˜ë¦¬)
train_size = 0.8
train_dataset, val_dataset = train_test_split(dataset, test_size=1-train_size, random_state=42)
train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)  # í•™ìŠµ ë°ì´í„°ëŠ” ì„ì–´ì„œ ê³¼ì í•© ë°©ì§€
val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)   # ê²€ì¦ ë°ì´í„°ë„ ì„ìŒ

print(f"ğŸ“Š Data split completed:")
print(f"   Training set: {len(train_dataset)} samples ({len(train_dataset)/len(dataset)*100:.1f}%)")
print(f"   Validation set: {len(val_dataset)} samples ({len(val_dataset)/len(dataset)*100:.1f}%)")
print(f"   Batch size: 16, Training batches: {len(train_dataloader)}, Validation batches: {len(val_dataloader)}")
print(f"   Total training steps per epoch: {len(train_dataloader)}")
print(f"   Total validation steps per epoch: {len(val_dataloader)}")

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
print(f"Using device: {device}")

# ëª¨ë¸ì„ GPUë¡œ ì´ë™
model.to(device)

# ì˜µí‹°ë§ˆì´ì € ë° í•™ìŠµë¥  ì„¤ì •
optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)  # BERTì˜ í‘œì¤€ í•™ìŠµë¥ 
print(f"âš™ï¸  Optimizer: AdamW with learning rate {2e-5}")
print(f"ğŸ“Š Model parameters: {sum(p.numel() for p in model.parameters()):,}")

# ì—í­ ì„¤ì • (ë¹ ë¥¸ ì‹¤í—˜ì„ ìœ„í•´ 5 ì—í¬í¬ë¡œ ì„¤ì •)
# 5,000ê°œ ë°ì´í„°, 5 ì—í¬í¬ í•™ìŠµ ì‹œ ì•½ 3-5ë¶„ ì†Œìš” (Apple M4 ê¸°ì¤€)
epochs = 5
print(f"ğŸ¯ Training configuration:")
print(f"   Total epochs: {epochs}")
print(f"   Samples per epoch: {len(train_dataset)}")
print(f"   Estimated training time: ~{epochs * 0.8:.1f} minutes (rough estimate)")

# í•™ìŠµ ë£¨í”„
import time  # ì‹œê°„ ì¸¡ì •ìš©
total_training_start = time.time()  # ì „ì²´ í•™ìŠµ ì‹œê°„ ì¸¡ì • ì‹œì‘

# ìµœê³  ê²€ì¦ ì •í™•ë„ë¥¼ ì¶”ì í•˜ê¸° ìœ„í•œ ë³€ìˆ˜ë“¤
best_val_accuracy = 0.0
best_epoch = 0

print(f"\nğŸš€ Starting Pre-training with {epochs} epochs...")
print("=" * 60)

for epoch in range(epochs):
    epoch_start_time = time.time()
    print(f"\nğŸš€ Epoch {epoch + 1}/{epochs} - Training Phase")
    print("-" * 40)
    
    # ===== í•™ìŠµ ë‹¨ê³„ =====
    model.train()  # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •
    total_loss = 0
    batch_count = 0
    
    for batch_idx, batch in enumerate(train_dataloader):
        if batch_idx % 10 == 0:  # 10ë°°ì¹˜ë§ˆë‹¤ ì§„í–‰ ìƒí™© ì¶œë ¥
            progress = (batch_idx / len(train_dataloader)) * 100
            print(f"  ğŸ“ˆ Training progress: {progress:.1f}% ({batch_idx}/{len(train_dataloader)} batches)")
        
        # ë°°ì¹˜ë¥¼ GPUë¡œ ì´ë™
        batch = tuple(t.to(device) for t in batch)
        inputs = {
            'input_ids': batch[0],
            'attention_mask': batch[1],
            'labels': batch[2]
        }
        
        # ===== ìˆœí™˜ ë³€í™˜ ìˆ˜í–‰ =====
        optimizer.zero_grad()
        outputs = model(**inputs)
        loss = outputs[1]  # í†µí•© Loss (ë¶„ë¥˜ + ì¬êµ¬ì„± + ì¼ê´€ì„±)
        
        # ì—­ì „íŒŒ ë° ì˜µí‹°ë§ˆì´ì € ìŠ¤í…
        total_loss += loss.item()
        loss.backward()
        optimizer.step()
        batch_count += 1

    # ì—í¬í¬ë³„ í‰ê·  ì†ì‹¤ ê³„ì‚°
    avg_train_loss = total_loss / batch_count
    epoch_time = time.time() - epoch_start_time
    
    print(f"âœ… Epoch {epoch + 1} Training completed:")
    print(f"   â±ï¸  Training time: {epoch_time:.2f}s")
    print(f'   ğŸ“‰ Average Training Loss: {avg_train_loss:.4f}')
    print(f"   ğŸ“Š Processed {batch_count} batches, {len(train_dataset)} samples")
    print(f"   ğŸ”„ Circular transformations applied: Textâ†’Imageâ†’Vectorâ†’Imageâ†’Text")

    # ===== ê²€ì¦ ë‹¨ê³„ =====
    print(f"\nğŸ” Epoch {epoch + 1} - Validation Phase")
    print("-" * 40)
    
    model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
    val_accuracy = 0
    val_loss = 0
    val_batch_count = 0
    
    for batch in val_dataloader:
        batch = tuple(t.to(device) for t in batch)
        inputs = {
            'input_ids': batch[0],
            'attention_mask': batch[1],
            'labels': batch[2]
        }
        
        with torch.no_grad():  # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°í•˜ì§€ ì•ŠìŒ
            outputs = model(**inputs)
            logits = outputs[0]  # ë¶„ë¥˜ logits
            loss = outputs[1]    # í†µí•© loss
            
        # ì •í™•ë„ ê³„ì‚°
        logits = logits.detach().cpu().numpy()
        label_ids = inputs['labels'].cpu().numpy()
        batch_accuracy = (logits.argmax(axis=1) == label_ids).mean().item()
        val_accuracy += batch_accuracy
        val_loss += loss.item()
        val_batch_count += 1

    # ê²€ì¦ ê²°ê³¼ ê³„ì‚°
    avg_val_accuracy = val_accuracy / val_batch_count
    avg_val_loss = val_loss / val_batch_count
    
    print(f"âœ… Epoch {epoch + 1} Validation completed:")
    print(f'   ğŸ“Š Validation Accuracy: {avg_val_accuracy:.4f}')
    print(f'   ğŸ“‰ Validation Loss: {avg_val_loss:.4f}')
    print(f"   ğŸ“ˆ Processed {val_batch_count} validation batches")
    print(f"   ğŸ”„ Circular transformations validated: All reconstruction losses computed")
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì¶”ì 
    if avg_val_accuracy > best_val_accuracy:
        best_val_accuracy = avg_val_accuracy
        best_epoch = epoch + 1
        print(f"   ğŸ† New best model! (Accuracy: {best_val_accuracy:.4f})")
    
    print(f"â±ï¸  Total epoch time: {epoch_time:.2f}s")
    print("=" * 60)

# ===== ìµœì¢… ëª¨ë¸ ì €ì¥ =====
print(f"\nğŸ’¾ Saving final model...")
print(f"   ğŸ“ Model path: {model_path}")
print(f"   ğŸ† Best validation accuracy: {best_val_accuracy:.4f} (Epoch {best_epoch})")

# ìµœì¢… ëª¨ë¸ ì €ì¥ (ì—í¬í¬ë§ˆë‹¤ ì €ì¥í•˜ì§€ ì•Šê³  ìµœì¢… ëª¨ë¸ë§Œ ì €ì¥)
torch.save({
    'epoch': epochs,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'best_val_accuracy': best_val_accuracy,
    'best_epoch': best_epoch,
    'total_samples': len(dataset),
    'train_samples': len(train_dataset),
    'val_samples': len(val_dataset)
}, model_path)

total_training_time = time.time() - total_training_start
print(f"âœ… Final model saved successfully!")
print(f"   ğŸ“Š Model file: {model_path}")
print(f"   â±ï¸  Total training time: {total_training_time:.2f}s ({total_training_time/60:.1f} minutes)")
print(f"   ğŸ“ˆ Best performance: {best_val_accuracy:.4f} accuracy at epoch {best_epoch}")

print("\nğŸ‰ Pre-training completed successfully!")
print("=" * 60)
print("ğŸ“‹ Summary:")
print(f"   â€¢ Total samples: {len(dataset)}")
print(f"   â€¢ Training samples: {len(train_dataset)}")
print(f"   â€¢ Validation samples: {len(val_dataset)}")
print(f"   â€¢ Total epochs: {epochs}")
print(f"   â€¢ Best validation accuracy: {best_val_accuracy:.4f}")
print(f"   â€¢ Training time: {total_training_time:.2f}s")
print(f"   â€¢ Final model saved: {model_path}")
print("=" * 60)