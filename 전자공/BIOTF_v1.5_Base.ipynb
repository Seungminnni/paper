{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "081c6c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      " ['7/29/1966, nan, 999-91-3709, S99988287, X5601074X, Mrs., Celia938, Roberts511, nan, Mayert710, M, white, hispanic, F, Agawam  Massachusetts  US, 362 Pacocha Gateway Apt 1, Northborough, Massachusetts, Worcester County, 1532.0, 42.27341123, -71.63243239, 1166971.45, 13416.2, 4/20/1989, nan, 5cfda74f-b462-4c73-aa96-d90da4002f8a, 40055000.0, Chronic sinusitis (disorder), Body mass index 30+ - obesity (finding), Miscarriage in first trimester, Prediabetes, Hyperlipidemia, Nasal congestion (finding), Cough (finding), Sore throat symptom (finding), Sputum finding (finding), Muscle pain (finding), Joint pain (finding), Fever (finding)', '12/19/1965, 3/1/2020, 999-70-4989, S99948277, X2560575X, Mrs., Kala987, Prohaska837, nan, Gleason633, M, white, nonhispanic, F, Boston  Massachusetts  US, 310 Effertz Promenade, Gloucester, Massachusetts, Essex County, 1930.0, 42.63072986, -70.6443488, 1229943.52, 20003.74, 2/12/1984, nan, 3fc7077f-903c-4601-8078-a016e9b5a630, 59621000.0, Hypertension, Chronic sinusitis (disorder), Body mass index 30+ - obesity (finding), Hyperlipidemia, Prediabetes, Dyspnea (finding), Wheezing (finding), Diarrhea symptom (finding), Fever (finding), Pneumonia (disorder), Hypoxemia (disorder), Respiratory distress (finding), Acute respiratory failure (disorder), Sepsis caused by virus (disorder), Acute pulmonary embolism (disorder), Injury of heart (disorder), Heart failure (disorder), Acute respiratory distress syndrome (disorder)', '6/10/1967, nan, 999-91-1294, S99999431, X11888547X, Mr., Deon400, Mante251, nan, nan, M, white, hispanic, M, Reading  Massachusetts  US, 479 Turcotte Byway Apt 47, Beverly, Massachusetts, Essex County, nan, 42.61134382, -70.87263385, 1216308.17, 5884.4, 7/5/1980, nan, e947863a-d0d9-4943-ac51-61b92f928cfa, 162864005.0, Body mass index 30+ - obesity (finding), Prediabetes, Anemia (disorder), Drug overdose, Opioid abuse (disorder), First degree burn, Cough (finding), Sputum finding (finding), Fever (finding), Loss of taste (finding)', '12/26/1995, nan, 999-11-8772, S99919263, X76708464X, Ms., María Cristina383, Laureano185, nan, nan, nan, white, hispanic, F, Santo Domingo  National District  DO, 506 Daugherty Neck Unit 41, Hampden, Massachusetts, Hampden County, nan, 42.11948085, -72.41484443, 515342.88, 6450.27, 2/18/2014, nan, 02d68d39-2195-4b7b-8a80-0412a32a88fe, 59621000.0, Hypertension, Nasal congestion (finding)', '5/3/1996, nan, 999-17-4976, S99924959, X58550607X, Ms., Shane235, Wunsch504, nan, nan, nan, white, nonhispanic, F, Nizhny Novgorod  Nizhny Novgorod Oblast  RU, 155 Spinka Key, Boston, Massachusetts, Suffolk County, 2109.0, 42.24382202, -71.19304971, 501015.88, 2846.4, 3/10/2020, 4/1/2020, 6ec793c5-14fd-408f-8982-05e1266fa67b, 49727002.0, Cough (finding), Sore throat symptom (finding), Fever (finding), Loss of taste (finding)', '1/10/1916, 8/31/1984, 999-90-2276, S99956796, X30521847X, Mr., Cristobal567, Osorio731, nan, nan, M, white, hispanic, M, Panama City  Panama  PA, 762 Schmidt Gateway, Stow, Massachusetts, Middlesex County, nan, 42.44215829, -71.49530302, 1680489.4, 25890.01, 3/14/1938, nan, d9fc9523-5754-4ffa-97ef-9fabaf65fd55, 44054006.0, Diabetes, Chronic kidney disease stage 1 (disorder), Diabetic renal disease (disorder), Hypertension, Hypertriglyceridemia (disorder), Metabolic syndrome X (disorder), Osteoarthritis of knee, Neoplasm of prostate, Metastasis from malignant tumor of prostate (disorder)', '3/9/1930, nan, 999-20-7431, S99921262, X68783451X, Mr., Mary779, Legros616, nan, nan, M, white, nonhispanic, M, Boston  Massachusetts  US, 710 Bailey Parade, Amesbury, Massachusetts, Essex County, nan, 42.8768494, -70.96107574, 1552037.01, 539700.96, 12/28/1948, nan, 83a219ef-6ee3-42a0-99bc-d22c0643e7ec, 40055000.0, Chronic sinusitis (disorder), Opioid abuse (disorder), Smokes tobacco daily, Prediabetes, Anemia (disorder), Hyperlipidemia, Diabetes, Neuropathy due to type 2 diabetes mellitus (disorder), Hypertriglyceridemia (disorder), Metabolic syndrome X (disorder), Chronic kidney disease stage 1 (disorder), Diabetic renal disease (disorder), Neoplasm of prostate, Carcinoma in situ of prostate (disorder), Chronic intractable migraine without aura, Sore throat symptom (finding), Sputum finding (finding), Fatigue (finding), Hemoptysis (finding), Dyspnea (finding), Wheezing (finding), Fever (finding), Loss of taste (finding)', '9/7/1992, nan, 999-56-7732, S99978179, X79244170X, Mrs., Libby988, Oberbrunner298, nan, Strosin214, M, white, nonhispanic, F, Quincy  Massachusetts  US, 880 Effertz Fort, New Bedford, Massachusetts, Bristol County, 2748.0, 41.62843647, -70.92306453, 482959.37, 3095.45, 12/10/2006, nan, 8fb4077f-4fa2-4c6d-bcb4-965e980852ba, 124000000000000.0, Chronic intractable migraine without aura, Impacted molars, Chronic pain, Drug overdose, Normal pregnancy, Cough (finding), Sputum finding (finding), Dyspnea (finding), Wheezing (finding), Fever (finding)', '1/25/2015, nan, 999-52-6460, nan, nan, nan, Lionel365, Dickinson688, nan, nan, nan, white, nonhispanic, M, Leominster  Massachusetts  US, 1074 Kulas Promenade Unit 28, Shirley, Massachusetts, Middlesex County, 1464.0, 42.60861738, -71.62818225, 134740.72, 2015.72, 8/3/2019, 8/11/2019, a789710b-e8c5-4655-b66d-820c644f5120, 43878008.0, Streptococcal sore throat (disorder), Cough (finding), Sputum finding (finding), Chill (finding), Fever (finding)', '3/11/2004, nan, 999-70-4190, S99919185, nan, nan, Pablo44, Klein929, nan, nan, nan, white, nonhispanic, M, Franklin  Massachusetts  US, 188 Hane Center, Chicopee, Massachusetts, Hampden County, nan, 42.2051048, -72.56331605, 352326.01, 3116.44, 3/7/2020, 3/26/2020, ab61e2ff-8315-4a69-b92f-84add51ae886, 49727002.0, Cough (finding), Fatigue (finding), Fever (finding)']\n",
      "Y_train\n",
      " [1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\MCC\\anaconda3\\envs\\biotf\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Epoch 1/10, Average Training Loss: 0.3671693565595038\n",
      "Model saved for epoch 1 at Pre_train_epoch1.pt\n",
      "Validation Accuracy for epoch 1: 0.884929906542056\n",
      "Epoch 2/10, Average Training Loss: 0.320084329764468\n",
      "Model saved for epoch 2 at Pre_train_epoch2.pt\n",
      "Validation Accuracy for epoch 2: 0.883427903871829\n",
      "Epoch 3/10, Average Training Loss: 0.31441075814791686\n",
      "Model saved for epoch 3 at Pre_train_epoch3.pt\n",
      "Validation Accuracy for epoch 3: 0.8841789052069426\n",
      "Epoch 4/10, Average Training Loss: 0.3108887806219954\n",
      "Model saved for epoch 4 at Pre_train_epoch4.pt\n",
      "Validation Accuracy for epoch 4: 0.8841789052069426\n",
      "Epoch 5/10, Average Training Loss: 0.3103741247539229\n",
      "Model saved for epoch 5 at Pre_train_epoch5.pt\n",
      "Validation Accuracy for epoch 5: 0.884929906542056\n",
      "Epoch 6/10, Average Training Loss: 0.30494501469700547\n",
      "Model saved for epoch 6 at Pre_train_epoch6.pt\n",
      "Validation Accuracy for epoch 6: 0.883427903871829\n",
      "Epoch 7/10, Average Training Loss: 0.2898066947018037\n",
      "Model saved for epoch 7 at Pre_train_epoch7.pt\n",
      "Validation Accuracy for epoch 7: 0.884929906542056\n",
      "Epoch 8/10, Average Training Loss: 0.2673591434946852\n",
      "Model saved for epoch 8 at Pre_train_epoch8.pt\n",
      "Validation Accuracy for epoch 8: 0.8875166889185581\n",
      "Epoch 9/10, Average Training Loss: 0.23463945173409204\n",
      "Model saved for epoch 9 at Pre_train_epoch9.pt\n",
      "Validation Accuracy for epoch 9: 0.8884345794392523\n",
      "Epoch 10/10, Average Training Loss: 0.18761887309303235\n",
      "Model saved for epoch 10 at Pre_train_epoch10.pt\n",
      "Validation Accuracy for epoch 10: 0.8789218958611482\n"
     ]
    }
   ],
   "source": [
    "# Pre-train용\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomBertForSequenceClassification(BertForSequenceClassification):\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        labels=None,\n",
    "        output_hidden_states=True\n",
    "    ):\n",
    "        outputs = super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            labels=labels,\n",
    "            output_hidden_states=output_hidden_states\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "        hidden_states = outputs.hidden_states[-8]  # n번째 레이어의 hidden states를 반환합니다.\n",
    "        loss = outputs.loss\n",
    "        return logits, loss, hidden_states\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "data_A = pd.read_csv(\"output1.csv\")  # data set A 파일명에 맞게 수정\n",
    "data_B = pd.read_csv(\"infected.csv\")  # data set B 파일명에 맞게 수정\n",
    "# 모델 저장 경로\n",
    "model_path = \"Pre-trained.pt\"\n",
    "\n",
    "# X_train, Y_train 생성\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for index, row in data_A.iterrows():  # 중복 제거를 하지 않고 원본 데이터 사용\n",
    "    patient_id = row[\"ID\"]\n",
    "    patient_info = [str(row[column]) for column in data_A.columns if column != \"ID\" and column != \"DESCRIPTION\"]\n",
    "    symptoms = \", \".join(data_A[data_A[\"ID\"] == patient_id][\"DESCRIPTION\"].tolist())\n",
    "    combined_info = \", \".join(patient_info) + \", \" + symptoms\n",
    "    X_train.append(combined_info)\n",
    "    if patient_id in data_B.values:\n",
    "        Y_train.append(1)\n",
    "    else:\n",
    "        Y_train.append(0)\n",
    "\n",
    "print(\"X_train\\n\", X_train[:10])\n",
    "print(\"Y_train\\n\", Y_train[:10])\n",
    "        \n",
    "# BERT 토크나이저 및 모델 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = CustomBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# 입력 데이터를 BERT의 입력 형식으로 변환\n",
    "max_len = 128  # 입력 시퀀스의 최대 길이\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for info in X_train:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        info,                         # 환자 정보 및 증상\n",
    "                        add_special_tokens = True,    # [CLS], [SEP] 토큰 추가\n",
    "                        max_length = max_len,         # 최대 길이 지정\n",
    "                        pad_to_max_length = True,     # 패딩을 추가하여 최대 길이로 맞춤\n",
    "                        return_attention_mask = True, # 어텐션 마스크 생성\n",
    "                        return_tensors = 'pt',        # PyTorch 텐서로 반환\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(Y_train)\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_size = 0.8\n",
    "train_dataset, val_dataset = train_test_split(dataset, test_size=1-train_size, random_state=42)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "model.to(device)\n",
    "\n",
    "# 옵티마이저 및 학습률 설정\n",
    "# 기본 학습률 : 2e-6\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# 에폭 설정\n",
    "epochs = 10\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[2]}\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[1]  # loss가 outputs의 두 번째 값입니다.\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}')\n",
    "\n",
    "    # 모델 저장 및 평가\n",
    "    model_save_path = f\"Pre_train_epoch{epoch + 1}_BERT_Based.pt\"\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved for epoch {epoch + 1} at {model_save_path}\")\n",
    "    \n",
    "    model.eval()\n",
    "    val_accuracy = 0\n",
    "    for batch in val_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[2]}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs[0]  # logits가 outputs의 첫 번째 값입니다.\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        val_accuracy += (logits.argmax(axis=1) == label_ids).mean().item()\n",
    "\n",
    "    print(f'Validation Accuracy for epoch {epoch + 1}: {val_accuracy / len(val_dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "06b3cf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 109483778\n",
      "Layer: bert.embeddings.word_embeddings.weight, Size: 23440896\n",
      "Layer: bert.embeddings.position_embeddings.weight, Size: 393216\n",
      "Layer: bert.embeddings.token_type_embeddings.weight, Size: 1536\n",
      "Layer: bert.embeddings.LayerNorm.weight, Size: 768\n",
      "Layer: bert.embeddings.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.0.attention.self.query.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.0.attention.self.query.bias, Size: 768\n",
      "Layer: bert.encoder.layer.0.attention.self.key.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.0.attention.self.key.bias, Size: 768\n",
      "Layer: bert.encoder.layer.0.attention.self.value.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.0.attention.self.value.bias, Size: 768\n",
      "Layer: bert.encoder.layer.0.attention.output.dense.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.0.attention.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.0.attention.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.0.attention.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.0.intermediate.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.0.intermediate.dense.bias, Size: 3072\n",
      "Layer: bert.encoder.layer.0.output.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.0.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.0.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.0.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.1.attention.self.query.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.1.attention.self.query.bias, Size: 768\n",
      "Layer: bert.encoder.layer.1.attention.self.key.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.1.attention.self.key.bias, Size: 768\n",
      "Layer: bert.encoder.layer.1.attention.self.value.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.1.attention.self.value.bias, Size: 768\n",
      "Layer: bert.encoder.layer.1.attention.output.dense.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.1.attention.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.1.attention.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.1.attention.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.1.intermediate.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.1.intermediate.dense.bias, Size: 3072\n",
      "Layer: bert.encoder.layer.1.output.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.1.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.1.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.1.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.2.attention.self.query.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.2.attention.self.query.bias, Size: 768\n",
      "Layer: bert.encoder.layer.2.attention.self.key.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.2.attention.self.key.bias, Size: 768\n",
      "Layer: bert.encoder.layer.2.attention.self.value.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.2.attention.self.value.bias, Size: 768\n",
      "Layer: bert.encoder.layer.2.attention.output.dense.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.2.attention.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.2.attention.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.2.attention.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.2.intermediate.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.2.intermediate.dense.bias, Size: 3072\n",
      "Layer: bert.encoder.layer.2.output.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.2.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.2.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.2.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.3.attention.self.query.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.3.attention.self.query.bias, Size: 768\n",
      "Layer: bert.encoder.layer.3.attention.self.key.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.3.attention.self.key.bias, Size: 768\n",
      "Layer: bert.encoder.layer.3.attention.self.value.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.3.attention.self.value.bias, Size: 768\n",
      "Layer: bert.encoder.layer.3.attention.output.dense.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.3.attention.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.3.attention.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.3.attention.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.3.intermediate.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.3.intermediate.dense.bias, Size: 3072\n",
      "Layer: bert.encoder.layer.3.output.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.3.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.3.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.3.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.4.attention.self.query.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.4.attention.self.query.bias, Size: 768\n",
      "Layer: bert.encoder.layer.4.attention.self.key.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.4.attention.self.key.bias, Size: 768\n",
      "Layer: bert.encoder.layer.4.attention.self.value.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.4.attention.self.value.bias, Size: 768\n",
      "Layer: bert.encoder.layer.4.attention.output.dense.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.4.attention.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.4.attention.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.4.attention.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.4.intermediate.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.4.intermediate.dense.bias, Size: 3072\n",
      "Layer: bert.encoder.layer.4.output.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.4.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.4.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.4.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.5.attention.self.query.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.5.attention.self.query.bias, Size: 768\n",
      "Layer: bert.encoder.layer.5.attention.self.key.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.5.attention.self.key.bias, Size: 768\n",
      "Layer: bert.encoder.layer.5.attention.self.value.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.5.attention.self.value.bias, Size: 768\n",
      "Layer: bert.encoder.layer.5.attention.output.dense.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.5.attention.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.5.attention.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.5.attention.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.5.intermediate.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.5.intermediate.dense.bias, Size: 3072\n",
      "Layer: bert.encoder.layer.5.output.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.5.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.5.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.5.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.6.attention.self.query.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.6.attention.self.query.bias, Size: 768\n",
      "Layer: bert.encoder.layer.6.attention.self.key.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.6.attention.self.key.bias, Size: 768\n",
      "Layer: bert.encoder.layer.6.attention.self.value.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.6.attention.self.value.bias, Size: 768\n",
      "Layer: bert.encoder.layer.6.attention.output.dense.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.6.attention.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.6.attention.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.6.attention.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.6.intermediate.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.6.intermediate.dense.bias, Size: 3072\n",
      "Layer: bert.encoder.layer.6.output.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.6.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.6.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.6.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.7.attention.self.query.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.7.attention.self.query.bias, Size: 768\n",
      "Layer: bert.encoder.layer.7.attention.self.key.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.7.attention.self.key.bias, Size: 768\n",
      "Layer: bert.encoder.layer.7.attention.self.value.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.7.attention.self.value.bias, Size: 768\n",
      "Layer: bert.encoder.layer.7.attention.output.dense.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.7.attention.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.7.attention.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.7.attention.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.7.intermediate.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.7.intermediate.dense.bias, Size: 3072\n",
      "Layer: bert.encoder.layer.7.output.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.7.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.7.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.7.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.8.attention.self.query.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.8.attention.self.query.bias, Size: 768\n",
      "Layer: bert.encoder.layer.8.attention.self.key.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.8.attention.self.key.bias, Size: 768\n",
      "Layer: bert.encoder.layer.8.attention.self.value.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.8.attention.self.value.bias, Size: 768\n",
      "Layer: bert.encoder.layer.8.attention.output.dense.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.8.attention.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.8.attention.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.8.attention.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.8.intermediate.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.8.intermediate.dense.bias, Size: 3072\n",
      "Layer: bert.encoder.layer.8.output.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.8.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.8.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.8.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.9.attention.self.query.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.9.attention.self.query.bias, Size: 768\n",
      "Layer: bert.encoder.layer.9.attention.self.key.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.9.attention.self.key.bias, Size: 768\n",
      "Layer: bert.encoder.layer.9.attention.self.value.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.9.attention.self.value.bias, Size: 768\n",
      "Layer: bert.encoder.layer.9.attention.output.dense.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.9.attention.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.9.attention.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.9.attention.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.9.intermediate.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.9.intermediate.dense.bias, Size: 3072\n",
      "Layer: bert.encoder.layer.9.output.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.9.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.9.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.9.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.10.attention.self.query.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.10.attention.self.query.bias, Size: 768\n",
      "Layer: bert.encoder.layer.10.attention.self.key.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.10.attention.self.key.bias, Size: 768\n",
      "Layer: bert.encoder.layer.10.attention.self.value.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.10.attention.self.value.bias, Size: 768\n",
      "Layer: bert.encoder.layer.10.attention.output.dense.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.10.attention.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.10.attention.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.10.attention.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.10.intermediate.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.10.intermediate.dense.bias, Size: 3072\n",
      "Layer: bert.encoder.layer.10.output.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.10.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.10.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.10.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.11.attention.self.query.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.11.attention.self.query.bias, Size: 768\n",
      "Layer: bert.encoder.layer.11.attention.self.key.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.11.attention.self.key.bias, Size: 768\n",
      "Layer: bert.encoder.layer.11.attention.self.value.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.11.attention.self.value.bias, Size: 768\n",
      "Layer: bert.encoder.layer.11.attention.output.dense.weight, Size: 589824\n",
      "Layer: bert.encoder.layer.11.attention.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.11.attention.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.11.attention.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.encoder.layer.11.intermediate.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.11.intermediate.dense.bias, Size: 3072\n",
      "Layer: bert.encoder.layer.11.output.dense.weight, Size: 2359296\n",
      "Layer: bert.encoder.layer.11.output.dense.bias, Size: 768\n",
      "Layer: bert.encoder.layer.11.output.LayerNorm.weight, Size: 768\n",
      "Layer: bert.encoder.layer.11.output.LayerNorm.bias, Size: 768\n",
      "Layer: bert.pooler.dense.weight, Size: 589824\n",
      "Layer: bert.pooler.dense.bias, Size: 768\n",
      "Layer: classifier.weight, Size: 1536\n",
      "Layer: classifier.bias, Size: 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def print_parameter_sizes(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"Layer: {name}, Size: {param.numel()}\")\n",
    "\n",
    "\n",
    "model = CustomBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "print(\"Total number of parameters:\", count_parameters(model))\n",
    "print_parameter_sizes(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d715e452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      " ['11/6/2011, nan, 999-81-9641, nan, nan, nan, Mack300, Halvorson124, nan, nan, nan, asian, nonhispanic, M, Avon  Massachusetts  US, 617 Hane Corner Unit 24, New Bedford, Massachusetts, Bristol County, 2743.0, 41.5103414, -70.9350167, 26475.3, 2679.84, 12/29/2019, 1/12/2020, 566f4d11-728e-49c2-8954-d17fedd7037b, 444814009.0, Viral sinusitis (disorder), Nasal congestion (finding), Cough (finding), Fever (finding), Loss of taste (finding)', '3/3/2000, nan, 999-39-4367, S99951818, X24980388X, Ms., Renee555, Blanda868, nan, nan, nan, white, nonhispanic, F, Natick  Massachusetts  US, 176 Dicki Highlands, Salisbury, Massachusetts, Essex County, nan, 42.80175139, -70.84150456, 538129.79, 2975.64, 4/27/2018, nan, c6f413a4-eb4a-4d1f-ad1a-61585fad9b2e, 59621000.0, Hypertension, Sputum finding (finding), Fever (finding), Normal pregnancy', '7/27/1951, 8/16/2018, 999-92-8207, S99933636, X43360252X, Mrs., Kristin64, Mann644, JD, Price929, M, white, nonhispanic, F, Worcester  Massachusetts  US, 509 Mueller Terrace, Weymouth, Massachusetts, Norfolk County, 2189.0, 42.20259477, -70.98242938, 1598069.11, 11444.13, 2/15/1963, nan, d092b678-5492-4158-a4e1-069b1367d78f, 40055000.0, Chronic sinusitis (disorder), Body mass index 30+ - obesity (finding), Hyperlipidemia, Stroke, Chronic congestive heart failure (disorder)', '7/11/1988, nan, 999-79-7595, S99950320, X36863170X, Mrs., Margret280, Orn563, nan, Swift555, M, asian, nonhispanic, F, Quincy  Massachusetts  US, 757 Kling Walk, Newton, Massachusetts, Middlesex County, nan, 42.3015182, -71.23202754, 654892.71, 9627.95, 9/4/2006, nan, 6ad72601-1d8c-439f-86df-6fedd8e5158c, 59621000.0, Hypertension, Cough (finding), Nausea (finding), Vomiting symptom (finding), Fever (finding), Loss of taste (finding)', '11/12/2013, nan, 999-96-9038, nan, nan, nan, Jewell855, Rogahn59, nan, nan, nan, white, nonhispanic, F, Whitman  Massachusetts  US, 749 McCullough Haven, Scituate, Massachusetts, Plymouth County, 2066.0, 42.23128626, -70.74126649, 142360.93, 2045.72, 2/29/2020, 3/25/2020, 2b8ac8a6-b2c6-4a60-a666-a04365f6815a, 49727002.0, Cough (finding), Dyspnea (finding), Wheezing (finding), Diarrhea symptom (finding), Fever (finding)', '1/23/1973, nan, 999-71-6176, S99936713, X67522812X, Ms., Olinda137, Price929, nan, nan, S, asian, hispanic, F, Marlborough  Massachusetts  US, 456 Beer Meadow Suite 57, Lawrence, Massachusetts, Essex County, nan, 42.72599632, -71.20616789, 125031.19, 8992.56, 3/28/1995, nan, 1d2dffc3-d2f9-4e02-8092-62d75bd6ab8b, 15777000.0, Prediabetes, Anemia (disorder), Viral sinusitis (disorder), Cough (finding), Fatigue (finding), Fever (finding)', '6/18/1916, 2/10/2002, 999-50-8868, S99952467, X74309188X, Mr., Lauren941, Bartell116, nan, nan, S, black, nonhispanic, M, Hingham  Massachusetts  US, 673 Ferry Meadow Apt 40, Dedham, Massachusetts, Norfolk County, nan, 42.29579173, -71.21534964, 1887028.81, 396114.89, 6/22/1958, nan, 28781692-ea28-40ab-a2d2-cdc2e88c9fdf, 44054006.0, Diabetes, Chronic kidney disease stage 1 (disorder), Diabetic renal disease (disorder), Hypertriglyceridemia (disorder), Metabolic syndrome X (disorder), Atrial Fibrillation, Osteoporosis (disorder), Stroke, Chronic sinusitis (disorder), Neoplasm of prostate, Carcinoma in situ of prostate (disorder)', '1/11/1967, nan, 999-84-5643, S99929369, X11626259X, Ms., Eloisa55, Benavides239, nan, nan, S, black, hispanic, F, Puebla  Puebla  MX, 851 Hegmann Mission, Carver, Massachusetts, Plymouth County, nan, 41.90402557, -70.71519819, 1136108.37, 12688.98, 4/13/1977, nan, ef79c31d-1661-422f-b4b3-44f0ef8c237d, 410429000.0, Cardiac Arrest, History of cardiac arrest (situation), Hypertension, Miscarriage in first trimester, Tubal pregnancy, Tubal pregnancy, Prediabetes, Anemia (disorder), Cough (finding), Fever (finding)', '6/21/1916, 6/27/2014, 999-25-8699, S99932304, X83260871X, Mr., Marion502, Schinner682, nan, nan, S, white, nonhispanic, M, Methuen  Massachusetts  US, 957 Kreiger Mall, Dennis, Massachusetts, Barnstable County, 2638.0, 41.74773953, -70.17706599, 1843702.42, 31052.46, 8/27/1944, nan, cc720fc1-bb56-472a-bc68-27b3d16b1e00, 40055000.0, Chronic sinusitis (disorder), Body mass index 30+ - obesity (finding), Hyperlipidemia, Neoplasm of prostate, Carcinoma in situ of prostate (disorder), Osteoporosis (disorder), Atrial Fibrillation, Stroke, Coronary Heart Disease, Chronic congestive heart failure (disorder), Acute bronchitis (disorder)', '9/26/1953, nan, 999-10-4564, S99934299, X28221847X, Mr., Emory494, Nolan344, nan, nan, M, asian, nonhispanic, M, Winthrop  Massachusetts  US, 293 Mertz Harbor, New Bedford, Massachusetts, Bristol County, 2746.0, 41.7017427, -70.94444646, 1425359.14, 20978.79, 11/20/1971, nan, 35ef04f0-2aaf-4799-b018-b2b72aa300af, 59621000.0, Hypertension, Prediabetes, Anemia (disorder), Chronic sinusitis (disorder), Otitis media, Cough (finding), Sputum finding (finding), Fatigue (finding), Fever (finding), Loss of taste (finding), Pneumonia (disorder), Hypoxemia (disorder), Respiratory distress (finding), Acute respiratory failure (disorder), Sepsis caused by virus (disorder), Acute deep venous thrombosis (disorder), Acquired coagulation disorder (disorder)']\n",
      "Y_train\n",
      " [1, 1, 0, 1, 1, 1, 0, 1, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-train model loaded.\n",
      "True\n",
      "Epoch 1/20, Average Training Loss: 0.3677359550464444\n",
      "Model saved for epoch 1 at Fine_tuned_epoch1_BERT_Based.pt\n",
      "Validation Accuracy for epoch 1: 0.8814964157706093\n",
      "Epoch 2/20, Average Training Loss: 0.3173808402767995\n",
      "Model saved for epoch 2 at Fine_tuned_epoch2_BERT_Based.pt\n",
      "Validation Accuracy for epoch 2: 0.8911290322580645\n",
      "Epoch 3/20, Average Training Loss: 0.3079563873873009\n",
      "Model saved for epoch 3 at Fine_tuned_epoch3_BERT_Based.pt\n",
      "Validation Accuracy for epoch 3: 0.8911290322580645\n",
      "Epoch 4/20, Average Training Loss: 0.30472496527481857\n",
      "Model saved for epoch 4 at Fine_tuned_epoch4_BERT_Based.pt\n",
      "Validation Accuracy for epoch 4: 0.8879928315412187\n",
      "Epoch 5/20, Average Training Loss: 0.296230930017262\n",
      "Model saved for epoch 5 at Fine_tuned_epoch5_BERT_Based.pt\n",
      "Validation Accuracy for epoch 5: 0.8879928315412187\n",
      "Epoch 6/20, Average Training Loss: 0.29320921779163484\n",
      "Model saved for epoch 6 at Fine_tuned_epoch6_BERT_Based.pt\n",
      "Validation Accuracy for epoch 6: 0.8895609318996416\n",
      "Epoch 7/20, Average Training Loss: 0.29155653073051113\n",
      "Model saved for epoch 7 at Fine_tuned_epoch7_BERT_Based.pt\n",
      "Validation Accuracy for epoch 7: 0.8895609318996416\n",
      "Epoch 8/20, Average Training Loss: 0.28284212033741357\n",
      "Model saved for epoch 8 at Fine_tuned_epoch8_BERT_Based.pt\n",
      "Validation Accuracy for epoch 8: 0.8879928315412187\n",
      "Epoch 9/20, Average Training Loss: 0.2738537366494415\n",
      "Model saved for epoch 9 at Fine_tuned_epoch9_BERT_Based.pt\n",
      "Validation Accuracy for epoch 9: 0.8875448028673836\n",
      "Epoch 10/20, Average Training Loss: 0.2657075777528732\n",
      "Model saved for epoch 10 at Fine_tuned_epoch10_BERT_Based.pt\n",
      "Validation Accuracy for epoch 10: 0.8891129032258065\n",
      "Epoch 11/20, Average Training Loss: 0.25472706530576317\n",
      "Model saved for epoch 11 at Fine_tuned_epoch11_BERT_Based.pt\n",
      "Validation Accuracy for epoch 11: 0.8891129032258065\n",
      "Epoch 12/20, Average Training Loss: 0.2351553510056763\n",
      "Model saved for epoch 12 at Fine_tuned_epoch12_BERT_Based.pt\n",
      "Validation Accuracy for epoch 12: 0.8850806451612904\n",
      "Epoch 13/20, Average Training Loss: 0.21916652058925085\n",
      "Model saved for epoch 13 at Fine_tuned_epoch13_BERT_Based.pt\n",
      "Validation Accuracy for epoch 13: 0.8835125448028674\n",
      "Epoch 14/20, Average Training Loss: 0.19909172441537787\n",
      "Model saved for epoch 14 at Fine_tuned_epoch14_BERT_Based.pt\n",
      "Validation Accuracy for epoch 14: 0.875\n",
      "Epoch 15/20, Average Training Loss: 0.1732716806747807\n",
      "Model saved for epoch 15 at Fine_tuned_epoch15_BERT_Based.pt\n",
      "Validation Accuracy for epoch 15: 0.8633512544802867\n",
      "Epoch 16/20, Average Training Loss: 0.15240309302642094\n",
      "Model saved for epoch 16 at Fine_tuned_epoch16_BERT_Based.pt\n",
      "Validation Accuracy for epoch 16: 0.8552867383512545\n",
      "Epoch 17/20, Average Training Loss: 0.12825933974841988\n",
      "Model saved for epoch 17 at Fine_tuned_epoch17_BERT_Based.pt\n",
      "Validation Accuracy for epoch 17: 0.8521505376344086\n",
      "Epoch 18/20, Average Training Loss: 0.1121981134032452\n",
      "Model saved for epoch 18 at Fine_tuned_epoch18_BERT_Based.pt\n",
      "Validation Accuracy for epoch 18: 0.8573028673835126\n",
      "Epoch 19/20, Average Training Loss: 0.10379043202544373\n",
      "Model saved for epoch 19 at Fine_tuned_epoch19_BERT_Based.pt\n",
      "Validation Accuracy for epoch 19: 0.8476702508960574\n",
      "Epoch 20/20, Average Training Loss: 0.08581582276620031\n",
      "Model saved for epoch 20 at Fine_tuned_epoch20_BERT_Based.pt\n",
      "Validation Accuracy for epoch 20: 0.8557347670250897\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune용\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomBertForSequenceClassification(BertForSequenceClassification):\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        labels=None,\n",
    "        output_hidden_states=True\n",
    "    ):\n",
    "        outputs = super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            labels=labels,\n",
    "            output_hidden_states=output_hidden_states\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "        hidden_states = outputs.hidden_states[-8]  # n번째 레이어의 hidden states를 반환합니다.\n",
    "        loss = outputs.loss\n",
    "        return logits, loss, hidden_states\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "data_A = pd.read_csv(\"output3.csv\")  # data set A 파일명에 맞게 수정\n",
    "data_B = pd.read_csv(\"infected.csv\")  # data set B 파일명에 맞게 수정\n",
    "# 모델 불러오는 경로\n",
    "model_path = \"Pre_train_epoch10.pt\"\n",
    "# 모델 저장경로\n",
    "model_path2 = \"Fine-tuned.pt\"\n",
    "\n",
    "# X_train, Y_train 생성\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for index, row in data_A.iterrows():  # 중복 제거를 하지 않고 원본 데이터 사용\n",
    "    patient_id = row[\"ID\"]\n",
    "    patient_info = [str(row[column]) for column in data_A.columns if column != \"ID\" and column != \"DESCRIPTION\"]\n",
    "    symptoms = \", \".join(data_A[data_A[\"ID\"] == patient_id][\"DESCRIPTION\"].tolist())\n",
    "    combined_info = \", \".join(patient_info) + \", \" + symptoms\n",
    "    X_train.append(combined_info)\n",
    "    if patient_id in data_B.values:\n",
    "        Y_train.append(1)\n",
    "    else:\n",
    "        Y_train.append(0)\n",
    "\n",
    "print(\"X_train\\n\", X_train[:10])\n",
    "print(\"Y_train\\n\", Y_train[:10])\n",
    "        \n",
    "# BERT 토크나이저 및 모델 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# 모델이 이미 저장되어 있는지 확인하고, 저장된 모델이 있으면 불러오고 없으면 새로운 모델 생성\n",
    "if os.path.exists(model_path):\n",
    "    # 저장된 모델이 있을 경우 불러오기\n",
    "    model = CustomBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Pre-train model loaded.\")\n",
    "else:\n",
    "    # 저장된 모델이 없을 경우 새로운 모델 생성\n",
    "    model = CustomBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    print(\"New model generated.\")\n",
    "\n",
    "# 입력 데이터를 BERT의 입력 형식으로 변환\n",
    "max_len = 128  # 입력 시퀀스의 최대 길이\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for info in X_train:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        info,                         # 환자 정보 및 증상\n",
    "                        add_special_tokens = True,    # [CLS], [SEP] 토큰 추가\n",
    "                        max_length = max_len,         # 최대 길이 지정\n",
    "                        pad_to_max_length = True,     # 패딩을 추가하여 최대 길이로 맞춤\n",
    "                        return_attention_mask = True, # 어텐션 마스크 생성\n",
    "                        return_tensors = 'pt',        # PyTorch 텐서로 반환\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(Y_train)\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_size = 0.8\n",
    "train_dataset, val_dataset = train_test_split(dataset, test_size=1-train_size, random_state=42)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "model.to(device)\n",
    "\n",
    "# 옵티마이저 및 학습률 설정\n",
    "# 기본 학습률 : 2e-6\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-6)\n",
    "\n",
    "# 에폭 설정\n",
    "epochs = 20\n",
    "\n",
    "# 학습 루프\n",
    "hidden_states_list = []  # 모든 에폭에 대한 hidden state를 저장할 리스트\n",
    "# 학습 루프\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[2]}\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[1]  # loss가 outputs의 두 번째 값입니다.\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}')\n",
    "\n",
    "    # 모델 저장 및 평가\n",
    "    model_save_path = f\"Fine_tuned_epoch{epoch + 1}_BERT_Based.pt\"\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved for epoch {epoch + 1} at {model_save_path}\")\n",
    "    \n",
    "    model.eval()\n",
    "    val_accuracy = 0\n",
    "    for batch in val_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[2]}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs[0]  # logits가 outputs의 첫 번째 값입니다.\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        val_accuracy += (logits.argmax(axis=1) == label_ids).mean().item()\n",
    "\n",
    "    print(f'Validation Accuracy for epoch {epoch + 1}: {val_accuracy / len(val_dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb1611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 랜덤분할(500/500/250)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def sample_csv_and_additional(input_file, output_file_500, output_file_100, n_500):\n",
    "    # CSV 파일을 읽어옵니다.\n",
    "    data = pd.read_csv(input_file)\n",
    "    \n",
    "    # 데이터를 랜덤하게 샘플링합니다.\n",
    "    sampled_data_750 = data.sample(n=n_500, random_state=42)\n",
    "    \n",
    "    # 첫 250개 데이터를 output_file_500과 output_file_100에 순서대로 삽입합니다.\n",
    "    first_250 = sampled_data_750[:250]\n",
    "    first_250.to_csv(output_file_500, index=False)\n",
    "    first_250.to_csv(output_file_100, index=False)\n",
    "    \n",
    "    # 나머지 500개 데이터를 절반으로 나누어 각각 output_file_500과 output_file_100에 추가합니다.\n",
    "    remaining_500 = sampled_data_750[250:]\n",
    "    split_idx = len(remaining_500) // 2\n",
    "    second_250_500 = remaining_500[:split_idx]\n",
    "    second_250_100 = remaining_500[split_idx:]\n",
    "    \n",
    "    # 파일에 추가합니다.\n",
    "    second_250_500.to_csv(output_file_500, mode='a', header=False, index=False)\n",
    "    second_250_100.to_csv(output_file_100, mode='a', header=False, index=False)\n",
    "\n",
    "# 입력 CSV 파일 경로\n",
    "input_file = \"output6.csv\"\n",
    "\n",
    "# 출력 CSV 파일 경로\n",
    "output_file_500 = \"random_500_D.csv\"\n",
    "output_file_100 = \"random_500_C.csv\"\n",
    "\n",
    "# 랜덤하게 추출할 데이터 개수\n",
    "n_500 = 750\n",
    "\n",
    "# 함수 호출\n",
    "sample_csv_and_additional(input_file, output_file_500, output_file_100, n_500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97fe8245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 랜덤분할(300/500)\n",
    "import pandas as pd\n",
    "\n",
    "def sample_csv_and_additional(input_file, output_file_500, output_file_100, n_500):\n",
    "    # CSV 파일을 읽어옵니다.\n",
    "    data = pd.read_csv(input_file)\n",
    "    \n",
    "    # 데이터를 랜덤하게 샘플링합니다.\n",
    "    sampled_data_500 = data.sample(n=n_500, random_state=42)\n",
    "    \n",
    "    # 샘플링된 500개의 데이터를 CSV 파일로 내보냅니다.\n",
    "    sampled_data_500.to_csv(output_file_500, index=False)\n",
    "    \n",
    "    # sampled_data_500에서 첫 100개의 데이터를 선택합니다.\n",
    "    sampled_data_100 = sampled_data_500.head(500)\n",
    "    \n",
    "    # 선택된 첫 100개의 데이터를 CSV 파일로 내보냅니다.\n",
    "    sampled_data_100.to_csv(output_file_100, index=False)\n",
    "\n",
    "# 입력 CSV 파일 경로\n",
    "input_file = \"output6.csv\"\n",
    "\n",
    "# 출력 CSV 파일 경로\n",
    "output_file_500 = \"random_500.csv\"\n",
    "output_file_100 = \"random_300.csv\"\n",
    "\n",
    "# 랜덤하게 추출할 데이터 개수\n",
    "n_500 = 1000\n",
    "\n",
    "# 함수 호출\n",
    "sample_csv_and_additional(input_file, output_file_500, output_file_100, n_500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3936463d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_full_repo_name' from 'huggingface_hub' (C:\\Users\\MCC\\anaconda3\\envs\\ieie\\lib\\site-packages\\huggingface_hub\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertForSequenceClassification\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, TensorDataset\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ieie\\lib\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     logging,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     52\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ieie\\lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ieie\\lib\\site-packages\\transformers\\utils\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/env python\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# coding=utf-8\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_full_repo_name  \u001b[38;5;66;03m# for backward compatibility\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HF_HUB_DISABLE_TELEMETRY \u001b[38;5;28;01mas\u001b[39;00m DISABLE_TELEMETRY  \u001b[38;5;66;03m# for backward compatibility\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_full_repo_name' from 'huggingface_hub' (C:\\Users\\MCC\\anaconda3\\envs\\ieie\\lib\\site-packages\\huggingface_hub\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# smashed data 생성 (500/server side)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomBertForSequenceClassification(BertForSequenceClassification):\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        labels=None,\n",
    "        output_hidden_states=True\n",
    "    ):\n",
    "        outputs = super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            labels=labels,\n",
    "            output_hidden_states=output_hidden_states\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "        hidden_states = outputs.hidden_states[9]  # n번째 레이어의 hidden states를 반환합니다.\n",
    "        loss = outputs.loss\n",
    "        return logits, loss, hidden_states\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "data_A = pd.read_csv(\"random_500.csv\")  # data set A 파일명에 맞게 수정\n",
    "data_B = pd.read_csv(\"infected.csv\")  # data set B 파일명에 맞게 수정\n",
    "# 모델 저장 경로\n",
    "model_path = \"Pre_train_epoch10.pt\"\n",
    "\n",
    "# X_train, Y_train 생성\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for index, row in data_A.iterrows():  # 중복 제거를 하지 않고 원본 데이터 사용\n",
    "    patient_id = row[\"ID\"]\n",
    "    patient_info = [str(row[column]) for column in data_A.columns if column != \"ID\" and column != \"DESCRIPTION\"]\n",
    "    symptoms = \", \".join(data_A[data_A[\"ID\"] == patient_id][\"DESCRIPTION\"].tolist())\n",
    "    combined_info = \", \".join(patient_info) + \", \" + symptoms\n",
    "    X_train.append(combined_info)\n",
    "    if patient_id in data_B.values:\n",
    "        Y_train.append(1)\n",
    "    else:\n",
    "        Y_train.append(0)\n",
    "\n",
    "#print(\"X_train\\n\", X_train[:10])\n",
    "#print(\"Y_train\\n\", Y_train[:10])\n",
    "        \n",
    "# BERT 토크나이저 및 모델 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# 모델이 이미 저장되어 있는지 확인하고, 저장된 모델이 있으면 불러오고 없으면 새로운 모델 생성\n",
    "if os.path.exists(model_path):\n",
    "    # 저장된 모델이 있을 경우 불러오기\n",
    "    model = CustomBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Pre-train model loaded.\")\n",
    "else:\n",
    "    # 저장된 모델이 없을 경우 새로운 모델 생성\n",
    "    model = CustomBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    print(\"New model generated.\")\n",
    "\n",
    "# 입력 데이터를 BERT의 입력 형식으로 변환\n",
    "max_len = 128  # 입력 시퀀스의 최대 길이\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for info in X_train:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        info,                         # 환자 정보 및 증상\n",
    "                        add_special_tokens = True,    # [CLS], [SEP] 토큰 추가\n",
    "                        max_length = max_len,         # 최대 길이 지정\n",
    "                        pad_to_max_length = True,     # 패딩을 추가하여 최대 길이로 맞춤\n",
    "                        return_attention_mask = True, # 어텐션 마스크 생성\n",
    "                        return_tensors = 'pt',        # PyTorch 텐서로 반환\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(Y_train)\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# 데이터로더 생성\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "model.to(device)\n",
    "\n",
    "# 모델 평가\n",
    "model.eval()\n",
    "val_accuracy = 0\n",
    "hidden_states_list = []  # 평가할 때 hidden state를 저장할 리스트\n",
    "for batch in dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    inputs = {'input_ids': batch[0],\n",
    "              'attention_mask': batch[1],\n",
    "              'labels': batch[2]}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs[0]  # logits가 outputs의 첫 번째 값입니다.\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = inputs['labels'].cpu().numpy()\n",
    "    val_accuracy += (logits.argmax(axis=1) == label_ids).mean().item()\n",
    "    # hidden state를 저장합니다.\n",
    "    hidden_states = outputs[2]\n",
    "    hidden_states_list.append(hidden_states)\n",
    "hidden_states_concat = torch.cat(hidden_states_list, dim=0)\n",
    "hidden_states_concat = hidden_states_concat[:, 0, :].cpu().detach().numpy()\n",
    "hidden_states_df = pd.DataFrame(hidden_states_concat)\n",
    "hidden_states_df.to_csv(\"Dictionary_smashed_data_layer2.csv\", index=False)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy / len(dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef0b701f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing CustomBertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing CustomBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CustomBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22048\\2444811346.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# 저장된 모델이 있을 경우 불러오기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCustomBertForSequenceClassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bert-base-uncased'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pre-train model loaded.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mcc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    787\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mcc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1131\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mcc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1099\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1101\u001b[1;33m             \u001b[0mload_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mcc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1081\u001b[0m         \u001b[1;31m# stop wrapping with TypedStorage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         loaded_storages[key] = torch.storage.TypedStorage(\n\u001b[1;32m-> 1083\u001b[1;33m             \u001b[0mwrap_storage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m             dtype=dtype)\n\u001b[0;32m   1085\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mcc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mcc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mcc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[0;32m    167\u001b[0m                            \u001b[1;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                            \u001b[1;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# smashed data 생성 (100/client side) #라이브러리 개변\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomBertForSequenceClassification(BertForSequenceClassification):\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        labels=None,\n",
    "        output_hidden_states=True\n",
    "    ):\n",
    "        outputs = super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            labels=labels,\n",
    "            output_hidden_states=output_hidden_states\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "        hidden_states = outputs.hidden_states[9]  # n번째 레이어의 hidden states를 반환합니다.\n",
    "        #for j in range(len(hidden_states)):  # hidden_states는 768차원으로 구성되어있음\n",
    "        #    noise = np.random.normal(0, 10.0)  # 표준 정규 분포에서 적절한 분산값을 사용하여 랜덤한 노이즈 생성\n",
    "        #    hidden_states[j] += noise  # hidden_states의 값에 노이즈 추가\n",
    "        loss = outputs.loss\n",
    "        return logits, loss, hidden_states\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "data_A = pd.read_csv(\"random_300.csv\")  # data set A 파일명에 맞게 수정\n",
    "data_B = pd.read_csv(\"infected.csv\")  # data set B 파일명에 맞게 수정\n",
    "# 모델 저장 경로\n",
    "model_path = \"Fine_tuned_epoch20_BERT_Based.pt\"\n",
    "\n",
    "# X_train, Y_train 생성\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for index, row in data_A.iterrows():  # 중복 제거를 하지 않고 원본 데이터 사용\n",
    "    patient_id = row[\"ID\"]\n",
    "    patient_info = [str(row[column]) for column in data_A.columns if column != \"ID\" and column != \"DESCRIPTION\"]\n",
    "    symptoms = \", \".join(data_A[data_A[\"ID\"] == patient_id][\"DESCRIPTION\"].tolist())\n",
    "    combined_info = \", \".join(patient_info) + \", \" + symptoms\n",
    "    X_train.append(combined_info)\n",
    "    if patient_id in data_B.values:\n",
    "        Y_train.append(1)\n",
    "    else:\n",
    "        Y_train.append(0)\n",
    "\n",
    "#print(\"X_train\\n\", X_train[:10])\n",
    "#print(\"Y_train\\n\", Y_train[:10])\n",
    "        \n",
    "# BERT 토크나이저 및 모델 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# 모델이 이미 저장되어 있는지 확인하고, 저장된 모델이 있으면 불러오고 없으면 새로운 모델 생성\n",
    "if os.path.exists(model_path):\n",
    "    # 저장된 모델이 있을 경우 불러오기\n",
    "    model = CustomBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    model.load_state_dict(torch.load(model_path), strict=False)\n",
    "    print(\"Pre-train model loaded.\")\n",
    "else:\n",
    "    # 저장된 모델이 없을 경우 새로운 모델 생성\n",
    "    model = CustomBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    print(\"New model generated.\")\n",
    "\n",
    "# 입력 데이터를 BERT의 입력 형식으로 변환\n",
    "max_len = 128  # 입력 시퀀스의 최대 길이\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for info in X_train:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        info,                         # 환자 정보 및 증상\n",
    "                        add_special_tokens = True,    # [CLS], [SEP] 토큰 추가\n",
    "                        max_length = max_len,         # 최대 길이 지정\n",
    "                        pad_to_max_length = True,     # 패딩을 추가하여 최대 길이로 맞춤\n",
    "                        return_attention_mask = True, # 어텐션 마스크 생성\n",
    "                        return_tensors = 'pt',        # PyTorch 텐서로 반환\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(Y_train)\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# 데이터로더 생성\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "model.to(device)\n",
    "\n",
    "# 모델 평가\n",
    "model.eval()\n",
    "val_accuracy = 0\n",
    "hidden_states_list = []  # 평가할 때 hidden state를 저장할 리스트\n",
    "for batch in dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    inputs = {'input_ids': batch[0],\n",
    "              'attention_mask': batch[1],\n",
    "              'labels': batch[2]}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs[0]  # logits가 outputs의 첫 번째 값입니다.\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = inputs['labels'].cpu().numpy()\n",
    "    val_accuracy += (logits.argmax(axis=1) == label_ids).mean().item()\n",
    "    # hidden state를 저장합니다.\n",
    "    hidden_states = outputs[2]\n",
    "    hidden_states_list.append(hidden_states)\n",
    "hidden_states_concat = torch.cat(hidden_states_list, dim=0)\n",
    "hidden_states_concat = hidden_states_concat[:, 0, :].cpu().detach().numpy()\n",
    "hidden_states_df = pd.DataFrame(hidden_states_concat)\n",
    "hidden_states_df.to_csv(\"Client_smashed_data_layer2.csv\", index=False)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy / len(dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "423f678a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For file: Client_smashed_data_layer2.csv\n",
      "Accuracy: 0.814\n",
      "Successful Mean Distance: 5.3697518820718395\n",
      "Unsuccessful Mean Distance: 6.7175118786942205\n",
      "Successful Distance Variance: 4.062777508728015\n",
      "Unsuccessful Distance Variance: 4.5765845795294195\n",
      "Success Indices: [(1, 1), (2, 1), (3, 1), (4, 1), (6, 1), (7, 1), (8, 3), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (15, 2), (16, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (24, 1), (25, 1), (26, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 5), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (47, 1), (48, 1), (49, 1), (52, 2), (53, 1), (54, 1), (55, 3), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (64, 1), (65, 1), (66, 1), (67, 1), (69, 1), (70, 1), (71, 3), (72, 1), (73, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 3), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 3), (87, 1), (89, 3), (91, 1), (92, 1), (93, 1), (94, 1), (96, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (106, 5), (107, 1), (109, 1), (111, 1), (112, 1), (113, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (122, 1), (123, 1), (125, 1), (126, 1), (127, 1), (128, 1), (130, 1), (131, 1), (133, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 2), (142, 1), (143, 1), (144, 2), (146, 3), (147, 1), (148, 1), (149, 2), (150, 2), (152, 1), (153, 1), (155, 1), (159, 1), (160, 1), (161, 1), (164, 1), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 3), (171, 1), (172, 1), (173, 1), (174, 1), (176, 1), (177, 1), (178, 1), (179, 4), (180, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 1), (189, 1), (190, 1), (191, 1), (192, 1), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (199, 3), (200, 1), (201, 1), (202, 1), (203, 2), (205, 1), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 2), (214, 1), (215, 1), (216, 1), (217, 1), (218, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (227, 1), (228, 1), (229, 1), (231, 3), (232, 1), (233, 1), (234, 1), (235, 1), (236, 1), (237, 1), (239, 1), (240, 1), (242, 1), (243, 1), (244, 1), (246, 1), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (259, 4), (260, 1), (261, 1), (264, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 2), (275, 1), (276, 1), (277, 1), (278, 1), (279, 1), (280, 3), (282, 1), (283, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (297, 1), (298, 1), (299, 1), (300, 1), (301, 1), (302, 1), (303, 4), (304, 1), (305, 2), (306, 1), (307, 1), (308, 1), (311, 1), (312, 1), (313, 1), (315, 1), (316, 1), (317, 1), (318, 1), (319, 1), (320, 1), (321, 1), (323, 1), (325, 1), (326, 1), (328, 2), (329, 1), (330, 1), (331, 1), (332, 1), (334, 1), (336, 1), (337, 1), (338, 1), (339, 1), (340, 1), (342, 1), (343, 1), (344, 1), (345, 1), (346, 1), (348, 1), (350, 1), (352, 1), (353, 1), (355, 2), (356, 1), (358, 1), (359, 1), (362, 1), (363, 1), (364, 1), (366, 1), (368, 1), (369, 1), (370, 1), (371, 1), (372, 1), (375, 1), (376, 1), (377, 1), (378, 1), (379, 1), (381, 1), (382, 1), (383, 1), (384, 1), (385, 1), (387, 1), (388, 1), (389, 1), (390, 1), (391, 1), (392, 1), (394, 1), (396, 1), (397, 1), (398, 1), (399, 1), (400, 1), (402, 1), (403, 1), (404, 1), (405, 1), (407, 1), (409, 4), (410, 1), (411, 2), (412, 1), (413, 1), (414, 1), (415, 1), (416, 5), (417, 1), (418, 1), (419, 4), (420, 1), (421, 2), (422, 1), (423, 1), (424, 1), (425, 1), (426, 1), (427, 2), (428, 1), (430, 1), (431, 1), (433, 1), (434, 1), (435, 1), (436, 1), (437, 1), (438, 1), (439, 1), (440, 1), (442, 1), (443, 1), (444, 2), (445, 1), (446, 1), (447, 1), (448, 1), (450, 1), (451, 1), (452, 1), (453, 1), (454, 1), (456, 1), (457, 1), (458, 1), (459, 1), (460, 1), (461, 1), (462, 1), (463, 1), (464, 1), (465, 1), (467, 1), (468, 1), (469, 1), (471, 1), (473, 1), (474, 1), (475, 1), (477, 1), (478, 1), (479, 1), (480, 1), (481, 1), (482, 1), (483, 1), (484, 1), (486, 1), (487, 5), (488, 1), (490, 1), (492, 1), (493, 1), (495, 1), (497, 1), (498, 1), (499, 2), (500, 1)]\n",
      "Success Ranks Count:\n",
      "Rank 1: 369 successes\n",
      "Rank 2: 18 successes\n",
      "Rank 3: 11 successes\n",
      "Rank 4: 5 successes\n",
      "Rank 5: 4 successes\n"
     ]
    }
   ],
   "source": [
    "# 유클리드 거리 유사도\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def calculate_accuracy_and_distance(client_file, dictionary_file, original_file_client, original_file_dictionary, n=5):\n",
    "    # 변환된 파일을 읽어옵니다.\n",
    "    client_data = pd.read_csv(client_file)\n",
    "    dictionary_data = pd.read_csv(dictionary_file)\n",
    "    \n",
    "    # 원본 파일을 읽어옵니다.\n",
    "    original_client_data = pd.read_csv(original_file_client)\n",
    "    original_dictionary_data = pd.read_csv(original_file_dictionary)\n",
    "    \n",
    "    # 데이터 포인트 간의 유클리드 거리를 계산합니다.\n",
    "    distances = euclidean_distances(client_data.values, dictionary_data.values)\n",
    "    \n",
    "    # Top@n 유사도를 찾습니다.\n",
    "    topn_similarities = np.argsort(distances, axis=1)[:, :n]\n",
    "    topn_values = np.sort(distances, axis=1)[:, :n]\n",
    "    \n",
    "    # 모든 결과를 출력하고 정확도를 계산합니다.\n",
    "    successful_distances = []\n",
    "    unsuccessful_distances = []\n",
    "    successes = 0\n",
    "    success_indices = []  # 성공한 인덱스를 저장할 리스트\n",
    "    success_ranks_count = {rank: 0 for rank in range(1, n+1)}  # 각 성공한 서버 측 랭크의 수를 저장할 딕셔너리\n",
    "    for i, (indices, scores) in enumerate(zip(topn_similarities, topn_values)):\n",
    "        \"\"\"print(f\"\\nTop {n} inferences for client {i + 1}:\")\"\"\"\n",
    "        for rank, (idx, score) in enumerate(zip(indices, scores), 1):\n",
    "            \"\"\"print(f\"Server {idx + 1} with distance {score}\")\"\"\"\n",
    "            if original_client_data.iloc[i].equals(original_dictionary_data.iloc[idx]):\n",
    "                successes += 1\n",
    "                successful_distances.append(score)\n",
    "                success_indices.append((i + 1, rank))  # 성공한 인덱스를 추가\n",
    "                success_ranks_count[rank] += 1  # 해당 랭크의 수를 증가시킴\n",
    "            else:\n",
    "                unsuccessful_distances.append(score)\n",
    "        if successes == 0:\n",
    "            print(\"No successful match found.\")\n",
    "    \n",
    "    # 정확도 계산\n",
    "    accuracy = successes / len(client_data)\n",
    "    \n",
    "    # 성공적으로 일치하는 데이터 포인트와 클라이언트 데이터 포인트, 그리고 일치하지 않는 데이터 포인트와 클라이언트 데이터 포인트 간의 평균 거리를 계산합니다.\n",
    "    successful_mean_distance = np.mean(successful_distances)\n",
    "    unsuccessful_mean_distance = np.mean(unsuccessful_distances)\n",
    "    \n",
    "    # 평균 거리의 분산 계산\n",
    "    successful_distance_variance = np.var(successful_distances)\n",
    "    unsuccessful_distance_variance = np.var(unsuccessful_distances)\n",
    "    \n",
    "    return accuracy, successful_mean_distance, unsuccessful_mean_distance, success_indices, successful_distance_variance, unsuccessful_distance_variance, success_ranks_count\n",
    "\n",
    "# 변환된 파일 경로\n",
    "dictionary_file = \"Dictionary_smashed_data_layer2.csv\"\n",
    "\n",
    "# 원본 파일 경로\n",
    "original_file_client = \"random_300.csv\"\n",
    "original_file_dictionary = \"random_500.csv\"\n",
    "\n",
    "# Top n 설정\n",
    "n = 5\n",
    "\n",
    "# 정확도 계산 및 평균 거리 계산\n",
    "\n",
    "client_file = f'Client_smashed_data_layer2.csv'\n",
    "accuracy, successful_mean_distance, unsuccessful_mean_distance, success_indices, successful_distance_variance, unsuccessful_distance_variance, success_ranks_count = calculate_accuracy_and_distance(client_file, dictionary_file, original_file_client, original_file_dictionary, n)\n",
    "\n",
    "print(\"\\nFor file:\", client_file)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Successful Mean Distance:\", successful_mean_distance)\n",
    "print(\"Unsuccessful Mean Distance:\", unsuccessful_mean_distance)\n",
    "\n",
    "# 분산 출력\n",
    "print(\"Successful Distance Variance:\", successful_distance_variance)\n",
    "print(\"Unsuccessful Distance Variance:\", unsuccessful_distance_variance)\n",
    "\n",
    "# 성공한 인덱스들을 출력합니다.\n",
    "print(\"Success Indices:\", success_indices)\n",
    "\n",
    "# 각 성공한 서버 측 랭크의 수를 출력합니다.\n",
    "print(\"Success Ranks Count:\")\n",
    "for rank, count in success_ranks_count.items():\n",
    "    print(f\"Rank {rank}: {count} successes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e11c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코사인 유사도\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_accuracy_and_similarity(client_file, dictionary_file, original_file_client, original_file_dictionary, n=5):\n",
    "    # 변환된 파일을 읽어옵니다.\n",
    "    client_data = pd.read_csv(client_file)\n",
    "    dictionary_data = pd.read_csv(dictionary_file)\n",
    "    \n",
    "    # 원본 파일을 읽어옵니다.\n",
    "    original_client_data = pd.read_csv(original_file_client)\n",
    "    original_dictionary_data = pd.read_csv(original_file_dictionary)\n",
    "    \n",
    "    # 데이터 포인트 간의 코사인 유사도를 계산합니다.\n",
    "    similarities = cosine_similarity(client_data.values, dictionary_data.values)\n",
    "    \n",
    "    # Top@n 유사도를 찾습니다.\n",
    "    topn_similarities = np.argsort(similarities, axis=1)[:, :-n-1:-1]  # 역순으로 정렬하여 상위 n개를 얻습니다.\n",
    "    topn_values = -np.sort(-similarities, axis=1)[:, :-n-1:-1]  # 역순으로 정렬하여 상위 n개의 값만 얻습니다.\n",
    "    \n",
    "    # 모든 결과를 출력하고 정확도를 계산합니다.\n",
    "    successful_distances = []\n",
    "    unsuccessful_distances = []\n",
    "    successes = 0\n",
    "    success_indices = []  # 성공한 인덱스를 저장할 리스트\n",
    "    for i, (indices, scores) in enumerate(zip(topn_similarities, topn_values)):\n",
    "        \"\"\"print(f\"\\nTop {n} inferences for client {i + 1}:\")\"\"\"\n",
    "        for rank, (idx, score) in enumerate(zip(indices, scores), 1):\n",
    "            \"\"\"print(f\"Server {idx + 1} with similarity score {score}\")\"\"\"\n",
    "            if original_client_data.iloc[i].equals(original_dictionary_data.iloc[idx]):\n",
    "                successes += 1\n",
    "                successful_distances.append(score)\n",
    "                success_indices.append((i + 1, rank))  # 성공한 인덱스를 추가\n",
    "            else:\n",
    "                unsuccessful_distances.append(score)\n",
    "        if successes == 0:\n",
    "            print(\"No successful match found.\")\n",
    "    \n",
    "    # 정확도 계산\n",
    "    accuracy = successes / len(client_data)\n",
    "    \n",
    "    # 성공적으로 일치하는 데이터 포인트와 클라이언트 데이터 포인트, 그리고 일치하지 않는 데이터 포인트와 클라이언트 데이터 포인트 간의 평균 유사도를 계산합니다.\n",
    "    successful_mean_similarity = np.mean(successful_distances)\n",
    "    unsuccessful_mean_similarity = np.mean(unsuccessful_distances)\n",
    "    \n",
    "    # 유사도의 분산 계산\n",
    "    successful_similarity_variance = np.var(successful_distances)\n",
    "    unsuccessful_similarity_variance = np.var(unsuccessful_distances)\n",
    "    \n",
    "    return accuracy, successful_mean_similarity, unsuccessful_mean_similarity, success_indices, successful_similarity_variance, unsuccessful_similarity_variance\n",
    "\n",
    "# 변환된 파일 경로\n",
    "#client_file = \"Client_smashed_data_epoch10.csv\"\n",
    "dictionary_file = \"Dictionary_smashed_data.csv\"\n",
    "\n",
    "# 원본 파일 경로\n",
    "original_file_client = \"random_300.csv\"\n",
    "original_file_dictionary = \"random_500.csv\"\n",
    "\n",
    "# Top n 설정\n",
    "n = 5\n",
    "\n",
    "# 정확도 계산 및 평균 유사도 계산\n",
    "for i in range(10, 11):\n",
    "    client_file = f'Client_smashed_data_epoch{i}.csv'\n",
    "    accuracy, successful_mean_similarity, unsuccessful_mean_similarity, success_indices, successful_similarity_variance, unsuccessful_similarity_variance = calculate_accuracy_and_similarity(client_file, dictionary_file, original_file_client, original_file_dictionary, n)\n",
    "\n",
    "    print(\"\\nAccuracy:\", accuracy)\n",
    "    print(\"Successful Mean Similarity:\", successful_mean_similarity)\n",
    "    print(\"Unsuccessful Mean Similarity:\", unsuccessful_mean_similarity)\n",
    "\n",
    "    # 분산 출력\n",
    "    print(\"Successful Similarity Variance:\", successful_similarity_variance)\n",
    "    print(\"Unsuccessful Similarity Variance:\", unsuccessful_similarity_variance)\n",
    "\n",
    "    # 성공한 인덱스들을 출력합니다.\n",
    "    print(\"Success Indices:\", success_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "98947347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 리그리션 데이터 추출용\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def calculate_accuracy_and_distance(client_file, dictionary_file, original_file_client, original_file_dictionary, n=5):\n",
    "    # 변환된 파일을 읽어옵니다.\n",
    "    client_data = pd.read_csv(client_file)\n",
    "    dictionary_data = pd.read_csv(dictionary_file)\n",
    "    \n",
    "    # 원본 파일을 읽어옵니다.\n",
    "    original_client_data = pd.read_csv(original_file_client)\n",
    "    original_dictionary_data = pd.read_csv(original_file_dictionary)\n",
    "    \n",
    "    # 데이터 포인트 간의 유클리드 거리를 계산합니다.\n",
    "    distances = euclidean_distances(client_data.values, dictionary_data.values)\n",
    "    \n",
    "    # Top@n 유사도를 찾습니다.\n",
    "    topn_similarities = np.argsort(distances, axis=1)[:, :n]\n",
    "    topn_values = np.sort(distances, axis=1)[:, :n]\n",
    "    \n",
    "    # 결과를 저장할 데이터프레임 생성\n",
    "    results_df = pd.DataFrame(columns=[f\"Rank_{i+1}\" for i in range(n)])  # 각 클라이언트의 서버 랭크별 점수를 저장할 데이터프레임\n",
    "\n",
    "    for i, (indices, scores) in enumerate(zip(topn_similarities, topn_values)):\n",
    "        result_row = pd.Series(scores, index=[f\"Rank_{j+1}\" for j in range(n)])  # 클라이언트의 서버 랭크별 점수 저장\n",
    "        results_df = results_df.append(result_row, ignore_index=True)\n",
    "    \n",
    "    # 결과를 CSV 파일로 내보냅니다.\n",
    "    results_df.to_csv(f\"client_scores_{client_file.split('_')[-1]}\", index=False, header=False)  # 첫 번째 행과 열의 이름을 빼고 저장\n",
    "\n",
    "# 변환된 파일 경로\n",
    "dictionary_file = \"Dictionary_smashed_data.csv\"\n",
    "\n",
    "# 원본 파일 경로\n",
    "original_file_client = \"random_500_C.csv\"\n",
    "original_file_dictionary = \"random_500_D.csv\"\n",
    "\n",
    "# Top n 설정\n",
    "n = 5\n",
    "\n",
    "# 정확도 계산 및 평균 거리 계산\n",
    "for i in range(1, 11):\n",
    "    client_file = f'Client_smashed_data_epoch{i}.csv'\n",
    "    calculate_accuracy_and_distance(client_file, dictionary_file, original_file_client, original_file_dictionary, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b2f9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Accuracy: 0.68\n",
      "SVM Accuracy: 0.7\n",
      "AUROC - Logistic: 0.7749597423510466\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "# CSV 파일 로드\n",
    "df = pd.read_csv(\"client_scores_epoch5.csv\", header=None)\n",
    "\n",
    "# 열 이름 변경\n",
    "new_columns = [f\"Rank_{i+1}\" for i in range(len(df.columns))]\n",
    "df.columns = new_columns\n",
    "\n",
    "# 데이터와 라벨 분리\n",
    "X = df  # 첫 번째 열은 라벨이 아니므로 제외\n",
    "y = [1] * 250 + [0] * 250  # 라벨 할당\n",
    "\n",
    "# 데이터를 학습용과 테스트용으로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 로지스틱 회귀 모델 초기화 및 학습\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# SVM 모델 초기화 및 학습\n",
    "svmreg = SVC()\n",
    "svmreg.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측 수행\n",
    "y_pred = model.predict(X_test)\n",
    "svm_pred = svmreg.predict(X_test)\n",
    "\n",
    "# 정확도 출력\n",
    "print(\"Logistic Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
    "\n",
    "# Confusion Matrix 계산\n",
    "logistic_cm = confusion_matrix(y_test, y_pred)\n",
    "svm_cm = confusion_matrix(y_test, svm_pred)\n",
    "\n",
    "# Confusion Matrix 시각화 (Logistic Regression)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(logistic_cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix - Logistic')\n",
    "\n",
    "# AUROC를 계산하고 시각화\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUROC - Logistic:\", auroc)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % auroc)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Logistic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# 결과를 파일로 저장\n",
    "logistic_predictions = np.array(y_pred)\n",
    "true_labels = np.array(y_test)\n",
    "np.save(\"logistic_predictions.npy\", logistic_predictions)\n",
    "np.save(\"true_labels.npy\", true_labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcf36159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ad5981c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.26070608e-04 -4.04867359e-05  0.00000000e+00  6.96918635e-05\n",
      "   7.10917037e-05]\n",
      " [-3.65110690e-02 -2.17233020e-02 -2.14779529e-02 -2.05076073e-02\n",
      "  -2.03553848e-02]\n",
      " [-9.94220609e-03 -6.48276689e-03 -6.47673398e-03 -6.30848709e-03\n",
      "  -6.30641785e-03]\n",
      " ...\n",
      " [-7.88783638e-02 -5.03078187e-02 -4.98850010e-02 -4.94956607e-02\n",
      "  -4.80239362e-02]\n",
      " [-7.63828342e-03 -7.00919689e-03 -6.17601627e-03 -6.11348449e-03\n",
      "  -5.77557173e-03]\n",
      " [-6.94824905e-02 -4.05499602e-02 -3.88855219e-02 -3.79706695e-02\n",
      "  -3.67463374e-02]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# t_SNE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 유클리드 거리 계산 함수 정의\n",
    "def calculate_euclidean_distances(client_file, dictionary_file):\n",
    "    # 변환된 파일을 읽어옵니다.\n",
    "    client_data = pd.read_csv(client_file)\n",
    "    dictionary_data = pd.read_csv(dictionary_file)\n",
    "    \n",
    "    # 데이터 포인트 간의 유클리드 거리를 계산합니다.\n",
    "    distances = euclidean_distances(client_data.values, dictionary_data.values)\n",
    "    \n",
    "    # top@1 score를 뺀 후 4차원 벡터화\n",
    "    top1_scores = distances[:, 0]\n",
    "    top5_scores = np.sort(distances, axis=1)[:, :5]\n",
    "    top5_minus_top1 = top5_scores - top1_scores[:, np.newaxis]\n",
    "    \n",
    "    return top5_minus_top1\n",
    "\n",
    "# 변환된 파일 경로\n",
    "dictionary_file = \"Dictionary_smashed_data_layer2.csv\"\n",
    "\n",
    "# t-SNE를 위한 4차원 벡터 계산\n",
    "vectors_list = []\n",
    "for i in range(2, 3):\n",
    "    client_file = f'Client_smashed_data_epoch{i}.csv'\n",
    "    vectors = calculate_euclidean_distances(client_file, dictionary_file)\n",
    "    print(vectors)\n",
    "    vectors_list.append(vectors)\n",
    "\n",
    "# 리스트를 배열로 변환\n",
    "vectors_array = np.concatenate(vectors_list, axis=0)\n",
    "\n",
    "# t-SNE를 적용하여 2차원으로 축소\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "transformed_vectors = tsne.fit_transform(vectors_array)\n",
    "\n",
    "# 첫 번째부터 250번째 벡터까지 빨간색, 이후는 파란색으로 점을 찍어 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(transformed_vectors[:250, 0], transformed_vectors[:250, 1], color='red', label='Leaked')\n",
    "plt.scatter(transformed_vectors[250:, 0], transformed_vectors[250:, 1], color='blue', label='Not leaked')\n",
    "plt.title('t-SNE Visualization of 4-Dimensional Vectors')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d26b838f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertLayer(\n",
      "  (attention): BertAttention(\n",
      "    (self): BertSelfAttention(\n",
      "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (output): BertSelfOutput(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (intermediate): BertIntermediate(\n",
      "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (intermediate_act_fn): GELUActivation()\n",
      "  )\n",
      "  (output): BertOutput(\n",
      "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "def main():\n",
    "    # BertModel 인스턴스 생성\n",
    "    bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    \n",
    "    # 7번째 레이어에 접근\n",
    "    seventh_layer = bert_model.encoder.layer[-4]\n",
    "\n",
    "    # 7번째 레이어 출력\n",
    "    print(seventh_layer)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8feb84ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data in Client_smashed_data_layer0.csv: (768,)\n",
      "L2norm of data in Client_smashed_data_layer0.csv: 14.491442262257587\n",
      "\n",
      "Shape of data in Client_smashed_data_layer1.csv: (768,)\n",
      "L2norm of data in Client_smashed_data_layer1.csv: 11.842984372695128\n",
      "\n",
      "Shape of data in Client_smashed_data_layer2.csv: (768,)\n",
      "L2norm of data in Client_smashed_data_layer2.csv: 12.648394121654427\n",
      "\n",
      "Shape of data in Client_smashed_data_layer3.csv: (768,)\n",
      "L2norm of data in Client_smashed_data_layer3.csv: 12.65642610967556\n",
      "\n",
      "Shape of data in Client_smashed_data_layer4.csv: (768,)\n",
      "L2norm of data in Client_smashed_data_layer4.csv: 17.455627849734213\n",
      "\n",
      "Shape of data in Client_smashed_data_layer5.csv: (768,)\n",
      "L2norm of data in Client_smashed_data_layer5.csv: 19.394996531031193\n",
      "\n",
      "Shape of data in Client_smashed_data_layer6.csv: (768,)\n",
      "L2norm of data in Client_smashed_data_layer6.csv: 20.697082216115405\n",
      "\n",
      "Shape of data in Client_smashed_data_layer7.csv: (768,)\n",
      "L2norm of data in Client_smashed_data_layer7.csv: 20.575648962667895\n",
      "\n",
      "Shape of data in Client_smashed_data_layer8.csv: (768,)\n",
      "L2norm of data in Client_smashed_data_layer8.csv: 20.533665064597468\n",
      "\n",
      "Shape of data in Client_smashed_data_layer9.csv: (768,)\n",
      "L2norm of data in Client_smashed_data_layer9.csv: 20.818436652680504\n",
      "\n",
      "Shape of data in Client_smashed_data_layer10.csv: (768,)\n",
      "L2norm of data in Client_smashed_data_layer10.csv: 21.159224340196275\n",
      "\n",
      "Shape of data in Client_smashed_data_layer11.csv: (768,)\n",
      "L2norm of data in Client_smashed_data_layer11.csv: 22.3552876190038\n",
      "\n",
      "Shape of data in Client_smashed_data_layer12.csv: (768,)\n",
      "L2norm of data in Client_smashed_data_layer12.csv: 15.84000042125757\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 파일 순회\n",
    "for i in range(13):  # 0부터 12까지의 파일을 처리\n",
    "    file_name = f'Client_smashed_data_layer{i}.csv'\n",
    "    try:\n",
    "        # CSV 파일 읽기\n",
    "        df = pd.read_csv(file_name, header=None, skiprows=1)\n",
    "        \n",
    "        # 벡터 데이터 추출\n",
    "        vector_data = df.values.flatten()\n",
    "        \n",
    "        # 모양(shape) 출력\n",
    "        print(f'Shape of data in {file_name}: {vector_data.shape}')\n",
    "        \n",
    "        # L2norm 계산\n",
    "        l2_norm = np.linalg.norm(vector_data, ord=2)\n",
    "        \n",
    "        # L2norm 출력\n",
    "        print(f'L2norm of data in {file_name}: {l2_norm}\\n')\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f'File {file_name} not found.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcbde76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
