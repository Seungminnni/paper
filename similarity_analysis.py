#!/usr/bin/env python3
"""
Smashed Data Similarity Analysis
í´ë¼ì´ì–¸íŠ¸ì™€ ì„œë²„ smashed dataì˜ ìœ ì‚¬ë„ ë¶„ì„
"""

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from scipy.spatial.distance import euclidean
import matplotlib.pyplot as plt

def load_smashed_data(file_path):
    """Smashed data CSV íŒŒì¼ ë¡œë“œ"""
    df = pd.read_csv(file_path)
    # ê° í–‰ì´ í•˜ë‚˜ì˜ ë²¡í„°
    vectors = df.values
    print(f"ðŸ“Š Loaded {vectors.shape[0]} vectors of dimension {vectors.shape[1]} from {file_path}")
    return vectors

def calculate_similarity_stats(client_vectors, server_vectors):
    """ë‘ ë°ì´í„°ì…‹ ê°„ ìœ ì‚¬ë„ í†µê³„ ê³„ì‚°"""
    print("\nðŸ” Calculating similarity statistics...")

    similarities = []

    # ê° í´ë¼ì´ì–¸íŠ¸ ë²¡í„°ì— ëŒ€í•´ ê°€ìž¥ ìœ ì‚¬í•œ ì„œë²„ ë²¡í„° ì°¾ê¸°
    for client_vec in client_vectors:
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        sim_scores = cosine_similarity([client_vec], server_vectors)[0]
        max_sim = np.max(sim_scores)
        similarities.append(max_sim)

    similarities = np.array(similarities)

    print("ðŸ“ˆ Similarity Statistics:")
    print(f"   â€¢ Mean similarity: {np.mean(similarities):.4f}")
    print(f"   â€¢ Median similarity: {np.median(similarities):.4f}")
    print(f"   â€¢ Std similarity: {np.std(similarities):.4f}")
    print(f"   â€¢ Min similarity: {np.min(similarities):.4f}")
    print(f"   â€¢ Max similarity: {np.max(similarities):.4f}")

    return similarities

def plot_similarity_distribution(similarities):
    """ìœ ì‚¬ë„ ë¶„í¬ ì‹œê°í™”"""
    try:
        plt.figure(figsize=(10, 6))

        # ëª¨ë“  ê°’ì´ ê°™ìœ¼ë©´ íŠ¹ë³„ ì²˜ë¦¬
        if np.std(similarities) == 0:
            plt.bar([0.5], [len(similarities)], width=0.1, alpha=0.7, color='blue')
            plt.title('All Similarities are Identical (Value = 1.0)')
            plt.xlabel('Cosine Similarity')
            plt.ylabel('Count')
            plt.xticks([0.5], ['1.0'])
        else:
            plt.hist(similarities, bins=30, alpha=0.7, color='blue', edgecolor='black')
            plt.title('Distribution of Cosine Similarities between Client and Server Vectors')
            plt.xlabel('Cosine Similarity')
            plt.ylabel('Frequency')

        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig('similarity_distribution.png', dpi=300, bbox_inches='tight')
        print("âœ… Plot saved as 'similarity_distribution.png'")
    except Exception as e:
        print(f"âš ï¸ Plotting failed: {e}")
    finally:
        plt.close('all')  # ëª¨ë“  í”Œë¡¯ ë‹«ê¸°

def analyze_vector_clusters(client_vectors, server_vectors):
    """ë²¡í„° í´ëŸ¬ìŠ¤í„° ë¶„ì„"""
    print("\nðŸŽ¯ Analyzing vector clusters...")

    # ê° ë°ì´í„°ì…‹ì˜ í‰ê·  ë²¡í„° ê³„ì‚°
    client_mean = np.mean(client_vectors, axis=0)
    server_mean = np.mean(server_vectors, axis=0)

    # í‰ê·  ë²¡í„° ê°„ ìœ ì‚¬ë„
    mean_similarity = cosine_similarity([client_mean], [server_mean])[0][0]
    print(f"ðŸ“Š Mean vector similarity: {mean_similarity:.4f}")

    # ê° ë°ì´í„°ì…‹ ë‚´ ë¶„ì‚°
    client_variance = np.var(client_vectors, axis=0).mean()
    server_variance = np.var(server_vectors, axis=0).mean()

    print(f"ðŸ“Š Client data variance: {client_variance:.6f}")
    print(f"ðŸ“Š Server data variance: {server_variance:.6f}")

    return mean_similarity, client_variance, server_variance

def main():
    print("ðŸ”¬ Smashed Data Similarity Analysis")
    print("=" * 60)

    # ë°ì´í„° ë¡œë“œ
    client_file = "Client_smashed_data_layer2.csv"
    server_file = "Dictionary_smashed_data_layer2.csv"

    try:
        client_vectors = load_smashed_data(client_file)
        server_vectors = load_smashed_data(server_file)
    except FileNotFoundError as e:
        print(f"âŒ Error: {e}")
        return

    # ìœ ì‚¬ë„ ë¶„ì„
    similarities = calculate_similarity_stats(client_vectors, server_vectors)

    # í´ëŸ¬ìŠ¤í„° ë¶„ì„
    mean_sim, client_var, server_var = analyze_vector_clusters(client_vectors, server_vectors)

    # ì‹œê°í™” (ëª¨ë“  ê°’ì´ ê°™ìœ¼ë©´ ìƒëžµ)
    if np.std(similarities) > 0:
        print("\nðŸ“Š Generating similarity distribution plot...")
        plot_similarity_distribution(similarities)
    else:
        print("\nðŸ“Š All similarities are identical (1.0) - skipping plot")

    # ê²°ê³¼ ìš”ì•½
    print("\nðŸŽ‰ Analysis Complete!")
    print("=" * 60)
    print("ðŸ“‹ Summary:")
    print(f"   â€¢ Client samples: {client_vectors.shape[0]}")
    print(f"   â€¢ Server samples: {server_vectors.shape[0]}")
    print(f"   â€¢ Average similarity: {np.mean(similarities):.4f}")
    print(f"   â€¢ Mean vector similarity: {mean_sim:.4f}")
    print(f"   â€¢ Client variance: {client_var:.6f}")
    print(f"   â€¢ Server variance: {server_var:.6f}")

    # í•´ì„
    print("\nðŸ’¡ Interpretation:")
    if np.mean(similarities) > 0.8:
        print("   â€¢ High similarity: Data distributions are very similar")
    elif np.mean(similarities) > 0.6:
        print("   â€¢ Moderate similarity: Some overlap in data distributions")
    else:
        print("   â€¢ Low similarity: Data distributions are quite different")

    if abs(client_var - server_var) < 0.01:
        print("   â€¢ Similar variance: Data spread is comparable")
    else:
        print("   â€¢ Different variance: Data spread differs between client and server")

if __name__ == "__main__":
    main()
