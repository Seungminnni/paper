# ìœ ê¶Œì ë°ì´í„° smashed data ìœ ì‚¬ë„ ê³„ì‚° - ìˆœí™˜ ì€í êµ¬ì¡° ì ìš©
# ì—°êµ¬ ì•„ì´ë””ì–´: ì€íëœ ë²¡í„° ê°„ ìœ ì‚¬ë„ ë¶„ì„ìœ¼ë¡œ ë³´ì•ˆ íš¨ê³¼ ê²€ì¦
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import euclidean_distances
import torch
import torch.nn as nn
import torch.nn.functional as F

class SimilarityAnalyzer:
    """
    ìˆœí™˜ ì€í êµ¬ì¡°ì˜ smashed data ìœ ì‚¬ë„ ë¶„ì„
    ê³µê²©ìê°€ ë²¡í„°ë¥¼ íƒˆì·¨í•˜ë”ë¼ë„ ì˜ë¯¸ ìˆëŠ” íŒ¨í„´ì„ ì°¾ê¸° ì–´ë ¤ì›€ ê²€ì¦
    """
    def __init__(self):
        self.device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
        
    def analyze_obfuscation_effectiveness(self, client_vectors, server_vectors):
        """
        ì€í íš¨ê³¼ ë¶„ì„: ì›ë³¸ vs ì€íëœ ë²¡í„°ì˜ ì°¨ì´ ë¶„ì„
        """
        # ë²¡í„° ê°„ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = 1 / (1 + euclidean_distances(client_vectors, server_vectors))
        
        # í†µê³„ ë¶„ì„
        mean_similarity = np.mean(similarities)
        std_similarity = np.std(similarities)
        max_similarity = np.max(similarities)
        min_similarity = np.min(similarities)
        
        return {
            'mean_similarity': mean_similarity,
            'std_similarity': std_similarity,
            'max_similarity': max_similarity,
            'min_similarity': min_similarity,
            'similarity_distribution': similarities
        }
    
    def detect_anomalies(self, vectors, threshold=0.1):
        """
        ì´ìƒì¹˜ íƒì§€: ì€íëœ ë²¡í„°ì˜ ë¹„ì •ìƒ íŒ¨í„´ íƒì§€
        ê³µê²©ìê°€ íŒ¨í„´ì„ í•™ìŠµí•˜ê¸° ì–´ë ¤ìš´ì§€ ê²€ì¦
        """
        # ë²¡í„° ì •ê·œí™”
        normalized_vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        cosine_sim = np.dot(normalized_vectors, normalized_vectors.T)
        
        # ìê¸° ìì‹ ê³¼ì˜ ìœ ì‚¬ë„ëŠ” 1ì´ë¯€ë¡œ ì œì™¸
        np.fill_diagonal(cosine_sim, 0)
        
        # ì„ê³„ê°’ ì´ìƒì˜ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ì´ìƒì¹˜ íƒì§€
        anomalies = []
        for i in range(len(cosine_sim)):
            max_sim = np.max(cosine_sim[i])
            if max_sim > threshold:
                anomalies.append((i, max_sim))
        
        return anomalies, cosine_sim

def calculate_circular_obfuscation_similarity(client_file, dictionary_file, n=5):
    """
    ìˆœí™˜ ì€í êµ¬ì¡°ì˜ smashed data ê°„ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    ê¸°ì¡´ ìœ ì‚¬ë„ ê³„ì‚°ì— ì€í íš¨ê³¼ ë¶„ì„ ì¶”ê°€
    """
    # ë³€í™˜ëœ íŒŒì¼ì„ ì½ì–´ì˜µë‹ˆë‹¤.
    client_data = pd.read_csv(client_file)
    dictionary_data = pd.read_csv(dictionary_file)
    
    # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ voter_idë¡œ ì´ë¦„ ë³€ê²½
    client_data.columns = ['voter_id'] + [f'vec_{i}' for i in range(len(client_data.columns) - 1)]
    dictionary_data.columns = ['voter_id'] + [f'vec_{i}' for i in range(len(dictionary_data.columns) - 1)]
    
    # voter_id ì¶”ì¶œ (ë¹„êµìš©)
    client_voter_ids = client_data['voter_id'].tolist()
    dictionary_voter_ids = dictionary_data['voter_id'].tolist()
    
    # ë²¡í„° ë°ì´í„°ë§Œ ì¶”ì¶œ (voter_id ì œì™¸)
    client_vectors = client_data.drop('voter_id', axis=1).values
    dictionary_vectors = dictionary_data.drop('voter_id', axis=1).values

    # ìˆœí™˜ ì€í ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = SimilarityAnalyzer()
    
    # ê¸°ë³¸ ìœ ì‚¬ë„ ê³„ì‚° (ê¸°ì¡´ ë°©ì‹)
    distances = euclidean_distances(client_vectors, dictionary_vectors)
    topn_similarities = np.argsort(distances, axis=1)[:, :n]
    topn_values = np.sort(distances, axis=1)[:, :n]
    
    # ì€í íš¨ê³¼ ë¶„ì„
    obfuscation_analysis = analyzer.analyze_obfuscation_effectiveness(
        client_vectors, dictionary_vectors
    )
    
    # ì´ìƒì¹˜ íƒì§€
    client_anomalies, client_similarity_matrix = analyzer.detect_anomalies(
        client_vectors, threshold=0.1
    )
    server_anomalies, server_similarity_matrix = analyzer.detect_anomalies(
        dictionary_vectors, threshold=0.1
    )
    
    # ëª¨ë“  ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ê³  ì •í™•ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    successful_distances = []
    unsuccessful_distances = []
    successes = 0
    success_indices = []  # ì„±ê³µí•œ ì¸ë±ìŠ¤ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    success_ranks_count = {rank: 0 for rank in range(1, n+1)}  # ê° ì„±ê³µí•œ ì„œë²„ ì¸¡ ë­í¬ì˜ ìˆ˜ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬

    # ìˆœí™˜ ì€í êµ¬ì¡°ì˜ ìœ ì‚¬ë„ ë¶„ì„ (voter_id ë§¤ì¹­ ëŒ€ì‹  í†µê³„ì  ë¶„ì„)
    # Clientì™€ ServerëŠ” ì„œë¡œ ë‹¤ë¥¸ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ë¯€ë¡œ voter_id ë§¤ì¹­ì€ ì˜ë¯¸ ì—†ìŒ
    
    # ê¸°ë³¸ í†µê³„ ê³„ì‚°
    mean_distance = np.mean(distances)
    std_distance = np.std(distances)
    min_distance = np.min(distances)
    max_distance = np.max(distances)
    
    # Top-N ë¶„ì„
    top1_distances = np.sort(distances, axis=1)[:, :1].flatten()
    top5_distances = np.sort(distances, axis=1)[:, :5].flatten()
    
    print(f"ğŸ“Š Distance Statistics:")
    print(f"   Mean Distance: {mean_distance:.4f}")
    print(f"   Std Distance: {std_distance:.4f}")
    print(f"   Min Distance: {min_distance:.4f}")
    print(f"   Max Distance: {max_distance:.4f}")
    print(f"   Top-1 Mean Distance: {np.mean(top1_distances):.4f}")
    print(f"   Top-5 Mean Distance: {np.mean(top5_distances):.4f}")
    
    # ì€í íš¨ê³¼ ë¶„ì„ ê²°ê³¼ ë°˜í™˜
    return {
        'mean_distance': mean_distance,
        'std_distance': std_distance,
        'min_distance': min_distance,
        'max_distance': max_distance,
        'top1_mean_distance': np.mean(top1_distances),
        'top5_mean_distance': np.mean(top5_distances),
        'obfuscation_analysis': obfuscation_analysis,
        'client_anomalies': client_anomalies,
        'server_anomalies': server_anomalies,
        'client_similarity_matrix': client_similarity_matrix,
        'server_similarity_matrix': server_similarity_matrix
    }

# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
if __name__ == "__main__":
    print("Loading voter data for similarity calculation...")

    # ì›ë³¸ ë°ì´í„° ë¡œë“œ
    full_data = pd.read_csv("ncvoterb.csv", encoding='latin-1')

    # ë°ì´í„° í¬ê¸° ì œí•œ: ì‹¤í—˜ì„ ìœ„í•´ 1,000ê°œë¡œ ì œí•œ (smashed dataì™€ ë™ì¼í•˜ê²Œ)
    # ì „ì²´ ë°ì´í„°: ì•½ 224,061ê°œ â†’ ì‹¤í—˜ìš©: 1,000ê°œ (ì•½ 0.4% ì‚¬ìš©)
    SAMPLE_SIZE = 1000
    if len(full_data) > SAMPLE_SIZE:
        print(f"ğŸ“Š Reducing data size from {len(full_data):,} to {SAMPLE_SIZE:,} for faster experimentation")
        full_data = full_data.sample(n=SAMPLE_SIZE, random_state=42)  # smashed dataì™€ ë™ì¼í•œ random_state
        print(f"âœ… Data reduced successfully! Working with {len(full_data):,} records")

    print(f"âœ… Data loaded successfully! Total records: {len(full_data)}")

    # ì„œë²„ì¸¡ê³¼ í´ë¼ì´ì–¸íŠ¸ ì¸¡ ë°ì´í„° ë¶„ë¦¬ (smashed data ìƒì„±ê³¼ ë™ì¼í•œ ë°©ì‹)
    # ì‹¤í—˜ìš© ë°ì´í„°ì—ì„œ 70% ì„œë²„, 30% í´ë¼ì´ì–¸íŠ¸ë¡œ ë¶„ë¦¬
    server_sample_size = int(len(full_data) * 0.7)
    server_data = full_data.sample(n=server_sample_size, random_state=42)  # smashed dataì™€ ë™ì¼í•œ ë°©ì‹
    client_data = full_data.drop(server_data.index).sample(frac=1.0, random_state=123)  # ë‚˜ë¨¸ì§€ ë°ì´í„°

    print(f"ğŸ“Š Server data size: {len(server_data)} (70% of {len(full_data)} = {len(server_data):,})")
    print(f"ğŸ“Š Client data size: {len(client_data)} (30% of {len(full_data)} = {len(client_data):,})")

    # ë³€í™˜ëœ íŒŒì¼ ê²½ë¡œ
    dictionary_file = "Dictionary_smashed_data.csv"
    client_file = "Client_smashed_data.csv"

    # Top n ì„¤ì •
    n = 5

    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    import os
    if not os.path.exists(client_file) or not os.path.exists(dictionary_file):
        print(f"Error: Required files not found!")
        print(f"Client file: {client_file} - {'Found' if os.path.exists(client_file) else 'Not found'}")
        print(f"Dictionary file: {dictionary_file} - {'Found' if os.path.exists(dictionary_file) else 'Not found'}")
        exit(1)

    # ìœ ì‚¬ë„ ê³„ì‚° (ìˆœí™˜ ì€í êµ¬ì¡° ì ìš©)
    print("ğŸ”„ Calculating similarity with circular obfuscation analysis...")
    print("   ğŸ“‹ Analysis includes: Basic similarity + Obfuscation effectiveness + Anomaly detection")
    
    results = calculate_circular_obfuscation_similarity(
        client_file, dictionary_file, n
    )

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*70)
    print("CIRCULAR OBFUSCATION SMASHED DATA SIMILARITY ANALYSIS")
    print("="*70)
    print(f"ğŸ“Š Mean Distance: {results['mean_distance']:.4f}")
    print(f"ğŸ“Š Std Distance: {results['std_distance']:.4f}")
    print(f"ğŸ“Š Min Distance: {results['min_distance']:.4f}")
    print(f"ï¿½ Max Distance: {results['max_distance']:.4f}")
    print(f"ğŸ¯ Top-1 Mean Distance: {results['top1_mean_distance']:.4f}")
    print(f"ğŸ¯ Top-5 Mean Distance: {results['top5_mean_distance']:.4f}")
    
    # ì€í íš¨ê³¼ ë¶„ì„ ê²°ê³¼
    print(f"\nğŸ›¡ï¸ OBFUSCATION EFFECTIVENESS ANALYSIS")
    print("-" * 40)
    obf = results['obfuscation_analysis']
    print(f"ğŸ“Š Mean Similarity: {obf['mean_similarity']:.4f}")
    print(f"ğŸ“Š Similarity Std Dev: {obf['std_similarity']:.4f}")
    print(f"ğŸ“Š Max Similarity: {obf['max_similarity']:.4f}")
    print(f"ğŸ“Š Min Similarity: {obf['min_similarity']:.4f}")
    
    # ì´ìƒì¹˜ ë¶„ì„ ê²°ê³¼
    print(f"\nğŸš¨ ANOMALY DETECTION RESULTS")
    print("-" * 40)
    print(f"ğŸ“Š Client Anomalies: {len(results['client_anomalies'])} detected")
    print(f"ğŸ“Š Server Anomalies: {len(results['server_anomalies'])} detected")
    
    if results['client_anomalies']:
        print("   Top client anomalies:")
        for idx, sim in results['client_anomalies'][:5]:
            print(f"     Sample {idx}: similarity {sim:.4f}")
    
    print("\nğŸ‰ Circular obfuscation similarity analysis completed!")
    print("="*70)
    
    # ë³´ì•ˆ íš¨ê³¼ ìš”ì•½
    print("\nğŸ”’ SECURITY EFFECTIVENESS SUMMARY")
    print("-" * 40)
    print(f"   â€¢ Obfuscation Strength: {'Strong' if results['std_distance'] > 10 else 'Moderate'}")
    print(f"   â€¢ Anomaly Detection: {len(results['client_anomalies'] + results['server_anomalies'])} patterns found")
    print(f"   â€¢ Distance Distribution: {results['min_distance']:.3f} - {results['max_distance']:.3f}")
    print(f"   â€¢ Similarity Distribution: {obf['min_similarity']:.3f} - {obf['max_similarity']:.3f}")
    print(f"   â€¢ Attack Difficulty: {'High' if results['mean_distance'] > 20 else 'Medium'}")
    print("="*70)
