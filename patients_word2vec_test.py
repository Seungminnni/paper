#!/usr/bin/env python3
"""
Patients.csv ë°ì´í„°ë¡œ Word2Vec ëª¨ìì´í¬ í…ŒìŠ¤íŠ¸
- í™˜ì ì •ë³´ í…ìŠ¤íŠ¸ë¥¼ Word2Vecìœ¼ë¡œ ë²¡í„°í™”
- ì„¸ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ëª¨ìì´í¬ ìƒì„± ë° í•™ìŠµ í…ŒìŠ¤íŠ¸
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from simple_word2vec_mosaic import *
import pandas as pd

def load_patients_data():
    """patients.csv ë°ì´í„° ë¡œë“œ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    print("ğŸ“Š Patients ë°ì´í„° ë¡œë”©...")
    
    # CSV íŒŒì¼ ì½ê¸°
    df = pd.read_csv('patients.csv')
    
    # ë¹ˆ í–‰ ì œê±°
    df = df.dropna(subset=['FIRST', 'LAST'])
    
    print(f"âœ… ì´ {len(df)}ê°œ í™˜ì ë°ì´í„° ë¡œë“œ")
    print(f"ğŸ“‹ ì»¬ëŸ¼: {list(df.columns)}")
    
    # í…ìŠ¤íŠ¸ ë°ì´í„° ì¡°í•© (ì´ë¦„, ì£¼ì†Œ, ì¸ì¢…, ì„±ë³„ ë“±)
    texts = []
    for _, row in df.iterrows():
        # ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ í•„ë“œë“¤ì„ ì¡°í•©
        text_parts = []
        
        # ì´ë¦„
        if pd.notna(row['PREFIX']): text_parts.append(str(row['PREFIX']))
        if pd.notna(row['FIRST']): text_parts.append(str(row['FIRST']))
        if pd.notna(row['LAST']): text_parts.append(str(row['LAST']))
        if pd.notna(row['SUFFIX']): text_parts.append(str(row['SUFFIX']))
        
        # ìœ„ì¹˜ ì •ë³´
        if pd.notna(row['CITY']): text_parts.append(str(row['CITY']))
        if pd.notna(row['STATE']): text_parts.append(str(row['STATE']))
        if pd.notna(row['COUNTY']): text_parts.append(str(row['COUNTY']))
        
        # ì¸êµ¬í†µê³„í•™ì  ì •ë³´
        if pd.notna(row['RACE']): text_parts.append(str(row['RACE']))
        if pd.notna(row['ETHNICITY']): text_parts.append(str(row['ETHNICITY']))
        if pd.notna(row['GENDER']): text_parts.append(str(row['GENDER']))
        if pd.notna(row['MARITAL']): text_parts.append(str(row['MARITAL']))
        
        # ì¶œìƒì§€
        if pd.notna(row['BIRTHPLACE']): 
            # ì¶œìƒì§€ ì •ë³´ ë¶„í•  ì¶”ê°€
            birthplace_parts = str(row['BIRTHPLACE']).split()
            text_parts.extend(birthplace_parts)
        
        # í…ìŠ¤íŠ¸ ì¡°í•©
        combined_text = ' '.join(text_parts).lower()
        texts.append(combined_text)
    
    # ì²˜ìŒ 5ê°œ ìƒ˜í”Œ í™•ì¸
    print("\nğŸ“ í…ìŠ¤íŠ¸ ìƒ˜í”Œ:")
    for i, text in enumerate(texts[:5]):
        print(f"  {i+1}: {text}")
    
    # í…ìŠ¤íŠ¸ ê¸¸ì´ í†µê³„
    text_lengths = [len(text.split()) for text in texts]
    print(f"\nğŸ“Š í…ìŠ¤íŠ¸ í†µê³„:")
    print(f"  í‰ê·  ë‹¨ì–´ ìˆ˜: {np.mean(text_lengths):.1f}")
    print(f"  ìµœì†Œ/ìµœëŒ€ ë‹¨ì–´ ìˆ˜: {min(text_lengths)}/{max(text_lengths)}")
    print(f"  ì¤‘ì•™ê°’ ë‹¨ì–´ ìˆ˜: {np.median(text_lengths):.1f}")
    
    return texts

def test_all_methods_with_patients():
    """í™˜ì ë°ì´í„°ë¡œ ì„¸ ê°€ì§€ ë°©ë²• ëª¨ë‘ í…ŒìŠ¤íŠ¸"""
    
    # ë°ì´í„° ë¡œë“œ
    texts = load_patients_data()
    
    # ìƒ˜í”Œ ìˆ˜ ì œí•œ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´)
    sample_size = min(500, len(texts))
    texts = texts[:sample_size]
    print(f"\nğŸ¯ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(texts)}ê°œ")
    
    print("\n" + "="*60)
    print("ğŸ§ª PATIENTS ë°ì´í„° Word2Vec ëª¨ìì´í¬ ë¹„êµ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    # ì„¸ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    results = {}
    
    # 1. ì§ì ‘ ë§¤í•‘ ë°©ì‹
    print("\nğŸ”¹ 1. ì§ì ‘ ë§¤í•‘ ë°©ì‹ í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    try:
        direct_processor = SimpleWord2VecProcessor(vector_size=256)
        direct_generator = DirectMosaicGenerator(vector_size=256)
        
        vectors = direct_processor.train_and_vectorize(texts)
        mosaics = direct_generator.vectors_to_mosaics(vectors)
        
        # í•™ìŠµ í…ŒìŠ¤íŠ¸ (ì˜¤í† ì¸ì½”ë” ë°©ì‹)
        X_train, X_test = train_test_split(mosaics, test_size=0.2, random_state=42)
        cnn = SimpleCNN(image_size=16)
        history = cnn.train(X_train, X_test, epochs=20)
        
        # ì˜ˆì¸¡ ë° í‰ê°€
        predictions = cnn.model.predict(X_test, verbose=0)
        mae = np.mean(np.abs(X_test - predictions))
        correlation = np.corrcoef(X_test.flatten(), predictions.flatten())[0, 1]
        
        results['direct'] = {
            'mae': mae,
            'correlation': correlation,
            'mosaics': mosaics,
            'vectors': vectors,
            'history': history
        }
        print(f"âœ… ì§ì ‘ ë§¤í•‘ ì™„ë£Œ - MAE: {mae:.4f}, ìƒê´€ê´€ê³„: {correlation:.4f}")
        
    except Exception as e:
        print(f"âŒ ì§ì ‘ ë§¤í•‘ ì˜¤ë¥˜: {e}")
        results['direct'] = None
    
    # 2. ì»¨ë³¼ë£¨ì…˜ ë°©ì‹
    print("\nğŸ”¹ 2. ì»¨ë³¼ë£¨ì…˜ ë°©ì‹ í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    try:
        conv_processor = SimpleWord2VecProcessor(vector_size=256)
        conv_generator = ConvolutionalMosaicGenerator(vector_size=256, final_image_size=32)
        
        vectors = conv_processor.train_and_vectorize(texts)
        mosaics = conv_generator.vectors_to_mosaics(vectors)
        
        # í•™ìŠµ í…ŒìŠ¤íŠ¸ (ì˜¤í† ì¸ì½”ë” ë°©ì‹)
        X_train, X_test = train_test_split(mosaics, test_size=0.2, random_state=42)
        cnn = SimpleCNN(image_size=32)
        history = cnn.train(X_train, X_test, epochs=20)
        
        # ì˜ˆì¸¡ ë° í‰ê°€
        predictions = cnn.model.predict(X_test, verbose=0)
        mae = np.mean(np.abs(X_test - predictions))
        correlation = np.corrcoef(X_test.flatten(), predictions.flatten())[0, 1]
        
        results['convolutional'] = {
            'mae': mae,
            'correlation': correlation,
            'mosaics': mosaics,
            'vectors': vectors,
            'history': history
        }
        print(f"âœ… ì»¨ë³¼ë£¨ì…˜ ë°©ì‹ ì™„ë£Œ - MAE: {mae:.4f}, ìƒê´€ê´€ê³„: {correlation:.4f}")
        
    except Exception as e:
        print(f"âŒ ì»¨ë³¼ë£¨ì…˜ ë°©ì‹ ì˜¤ë¥˜: {e}")
        results['convolutional'] = None
    
    # 3. í–‰ë ¬ ë°©ì‹ (Yoon Kim ìŠ¤íƒ€ì¼)
    print("\nğŸ”¹ 3. í–‰ë ¬ ë°©ì‹ (Yoon Kim ìŠ¤íƒ€ì¼) í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    try:
        matrix_processor = SentenceMatrixProcessor(vector_size=128, max_words=32)
        matrix_generator = MatrixMosaicGenerator(matrix_shape=(32, 128))
        
        sentence_matrices = matrix_processor.train_and_vectorize(texts)
        mosaics = matrix_generator.matrices_to_mosaics(sentence_matrices)
        
        # ë²¡í„°í™” (í‰ê· )
        flattened_matrices = sentence_matrices.reshape(len(sentence_matrices), -1)
        
        # í•™ìŠµ í…ŒìŠ¤íŠ¸ (ì˜¤í† ì¸ì½”ë” ë°©ì‹)
        X_train, X_test = train_test_split(mosaics, test_size=0.2, random_state=42)
        cnn = MatrixCNN(input_shape=(32, 128, 1))
        history = cnn.train(X_train, X_test, epochs=20)
        
        # ì˜ˆì¸¡ ë° í‰ê°€
        predictions = cnn.model.predict(X_test, verbose=0)
        mae = np.mean(np.abs(X_test - predictions))
        correlation = np.corrcoef(X_test.flatten(), predictions.flatten())[0, 1]
        
        results['matrix'] = {
            'mae': mae,
            'correlation': correlation,
            'mosaics': mosaics,
            'vectors': flattened_matrices,
            'history': history
        }
        print(f"âœ… í–‰ë ¬ ë°©ì‹ ì™„ë£Œ - MAE: {mae:.4f}, ìƒê´€ê´€ê³„: {correlation:.4f}")
        
    except Exception as e:
        print(f"âŒ í–‰ë ¬ ë°©ì‹ ì˜¤ë¥˜: {e}")
        results['matrix'] = None
    
    # ê²°ê³¼ ë¹„êµ ë° ì‹œê°í™”
    print("\n" + "="*60)
    print("ğŸ“Š PATIENTS ë°ì´í„° ìµœì¢… ê²°ê³¼ ë¹„êµ")
    print("="*60)
    
    # ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸”
    print("\nğŸ† ì„±ëŠ¥ ë¹„êµ:")
    print(f"{'ë°©ë²•':<15} {'MAE':<10} {'ìƒê´€ê´€ê³„':<10} {'ì´ë¯¸ì§€ í¬ê¸°':<15}")
    print("-" * 50)
    
    if results['direct']:
        print(f"{'ì§ì ‘ ë§¤í•‘':<15} {results['direct']['mae']:<10.4f} {results['direct']['correlation']:<10.4f} {'16x16':<15}")
    
    if results['convolutional']:
        print(f"{'ì»¨ë³¼ë£¨ì…˜':<15} {results['convolutional']['mae']:<10.4f} {results['convolutional']['correlation']:<10.4f} {'32x32':<15}")
    
    if results['matrix']:
        print(f"{'í–‰ë ¬(Yoon Kim)':<15} {results['matrix']['mae']:<10.4f} {results['matrix']['correlation']:<10.4f} {'32x128':<15}")
    
    # ì‹œê°í™”
    visualize_patients_comparison(results, sample_texts=texts[:3])
    
    return results

def visualize_patients_comparison(results, sample_texts):
    """í™˜ì ë°ì´í„° ê²°ê³¼ ì‹œê°í™”"""
    
    # ìœ íš¨í•œ ê²°ê³¼ë§Œ ì¶”ì¶œ
    valid_results = {k: v for k, v in results.items() if v is not None}
    
    if not valid_results:
        print("âŒ ì‹œê°í™”í•  ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê·¸ë˜í”„ ì„¤ì •
    n_methods = len(valid_results)
    n_samples = min(3, len(sample_texts))
    
    fig, axes = plt.subplots(n_samples * 2, n_methods, figsize=(4*n_methods, 3*n_samples*2))
    if n_methods == 1:
        axes = axes.reshape(-1, 1)
    if n_samples == 1:
        axes = axes.reshape(2, -1)
    
    fig.suptitle('Patients ë°ì´í„° Word2Vec ëª¨ìì´í¬ ë¹„êµ', fontsize=16, fontweight='bold')
    
    method_names = {'direct': 'ì§ì ‘ ë§¤í•‘', 'convolutional': 'ì»¨ë³¼ë£¨ì…˜', 'matrix': 'í–‰ë ¬(Yoon Kim)'}
    
    for j, (method_key, result) in enumerate(valid_results.items()):
        method_name = method_names.get(method_key, method_key)
        
        for i in range(n_samples):
            # ì›ë³¸ ëª¨ìì´í¬
            axes[i*2, j].imshow(result['mosaics'][i].squeeze(), cmap='viridis', aspect='auto')
            axes[i*2, j].set_title(f'{method_name}\nOriginal {i+1}', fontsize=10)
            axes[i*2, j].axis('off')
            
            # í…ìŠ¤íŠ¸ ì •ë³´ (ë³µì›ëœ ì´ë¯¸ì§€ ëŒ€ì‹ )
            axes[i*2+1, j].text(0.1, 0.7, f"Text: {sample_texts[i][:50]}...", 
                               fontsize=8, wrap=True, transform=axes[i*2+1, j].transAxes)
            axes[i*2+1, j].text(0.1, 0.5, f"MAE: {result['mae']:.4f}", 
                               fontsize=10, fontweight='bold', transform=axes[i*2+1, j].transAxes)
            axes[i*2+1, j].text(0.1, 0.3, f"Correlation: {result['correlation']:.4f}", 
                               fontsize=10, fontweight='bold', transform=axes[i*2+1, j].transAxes)
            axes[i*2+1, j].text(0.1, 0.1, f"Shape: {result['mosaics'].shape[1:]}", 
                               fontsize=8, transform=axes[i*2+1, j].transAxes)
            axes[i*2+1, j].set_title(f'Info {i+1}', fontsize=10)
            axes[i*2+1, j].axis('off')
    
    plt.tight_layout()
    plt.savefig('patients_word2vec_mosaic_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"âœ… ì‹œê°í™” ì™„ë£Œ: patients_word2vec_mosaic_comparison.png ì €ì¥")

if __name__ == "__main__":
    # í™˜ì ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = test_all_methods_with_patients()
    
    print("\nğŸ‰ Patients ë°ì´í„° Word2Vec ëª¨ìì´í¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("ê° ë°©ë²•ì€ í™˜ì ì •ë³´ í…ìŠ¤íŠ¸ë§ˆë‹¤ ê³ ìœ í•œ ëª¨ìì´í¬ë¥¼ ìƒì„±í•˜ë©°,")
    print("ì»¨ë³¼ë£¨ì…˜ì„ í†µí•œ ì°¨ì› ì••ì¶•ìœ¼ë¡œ ë²¡í„°â†’ì´ë¯¸ì§€ ë§¤í•‘ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
